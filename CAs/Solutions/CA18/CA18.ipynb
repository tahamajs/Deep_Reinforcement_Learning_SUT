{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72e3b80",
   "metadata": {},
   "source": [
    "# CA18: Advanced Deep Reinforcement Learning - Comprehensive Exercise\n",
    "\n",
    "## Course: Deep Reinforcement Learning\n",
    "## Assignment: CA18 - Advanced RL Paradigms Implementation and Analysis\n",
    "## Date: July 2025\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By the end of this comprehensive exercise, you will:\n",
    "\n",
    "1. **Master Advanced RL Paradigms**: Understand and implement 5 cutting-edge RL approaches\n",
    "2. **Theoretical Foundations**: Grasp the mathematical principles underlying each method\n",
    "3. **Practical Implementation**: Build working systems from scratch using PyTorch\n",
    "4. **Performance Analysis**: Compare and evaluate different approaches scientifically\n",
    "5. **Integration Skills**: Combine multiple paradigms for enhanced performance\n",
    "6. **Real-world Applications**: Apply techniques to practical scenarios\n",
    "\n",
    "## ðŸŽ¯ Exercise Structure\n",
    "\n",
    "This exercise covers **5 major advanced RL paradigms**:\n",
    "\n",
    "### **Part I: World Models and Imagination-Augmented Agents**\n",
    "- Theory: Model-based RL, recurrent state space models, planning\n",
    "- Implementation: RSSM, world model, MPC planner, imagination-augmented agent\n",
    "- Exercise: Build and evaluate a planning-based RL agent\n",
    "\n",
    "### **Part II: Multi-Agent Deep Reinforcement Learning**\n",
    "- Theory: Game theory, coordination, communication, MARL algorithms\n",
    "- Implementation: MADDPG, communication networks, multi-agent environments\n",
    "- Exercise: Create cooperative and competitive multi-agent systems\n",
    "\n",
    "### **Part III: Causal Reinforcement Learning**\n",
    "- Theory: Causality, interventions, counterfactual reasoning, causal discovery\n",
    "- Implementation: Causal graphs, PC algorithm, causal mechanisms\n",
    "- Exercise: Build causally-aware RL agents for robust decision making\n",
    "\n",
    "### **Part IV: Quantum-Enhanced Reinforcement Learning**\n",
    "- Theory: Quantum computing, variational quantum circuits, quantum advantage\n",
    "- Implementation: Quantum gates, VQC, quantum policy networks\n",
    "- Exercise: Explore quantum speedups in RL problems\n",
    "\n",
    "### **Part V: Federated Reinforcement Learning**\n",
    "- Theory: Distributed learning, privacy preservation, communication efficiency\n",
    "- Implementation: FedAvg-RL, differential privacy, secure aggregation\n",
    "- Exercise: Build privacy-preserving collaborative RL systems\n",
    "\n",
    "### **Part VI: Integration and Analysis**\n",
    "- Comparative analysis of all methods\n",
    "- Hybrid approaches combining multiple paradigms\n",
    "- Real-world application scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Prerequisites\n",
    "\n",
    "- **Mathematical Background**: Linear algebra, probability theory, calculus\n",
    "- **Programming Skills**: Python, PyTorch, NumPy, Matplotlib\n",
    "- **RL Knowledge**: Basic RL concepts (MDP, policy gradient, value functions)\n",
    "- **Deep Learning**: Neural networks, backpropagation, optimization\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Let's Begin!\n",
    "\n",
    "This comprehensive exercise will take you through the most advanced techniques in modern Deep Reinforcement Learning. Each section builds upon previous knowledge while introducing cutting-edge concepts that represent the future of AI.\n",
    "\n",
    "**Ready to explore the frontiers of artificial intelligence? Let's dive in!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7298315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Setup Complete!\n",
      "Device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 2.2.6\n",
      "Ready to explore advanced Deep Reinforcement Learning! ðŸ¤–\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import deque, defaultdict\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple, Optional, Union, Any\n",
    "from abc import ABC, abstractmethod\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "import gym\n",
    "import math\n",
    "import cmath\n",
    "from scipy.linalg import expm\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Setup Complete!\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"Ready to explore advanced Deep Reinforcement Learning! ðŸ¤–\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9ef2a",
   "metadata": {},
   "source": [
    "# Part I: World Models and Imagination-Augmented Agents\n",
    "\n",
    "## ðŸŒ Theoretical Foundation\n",
    "\n",
    "### Introduction to World Models\n",
    "\n",
    "**World Models** represent a paradigm shift in reinforcement learning, moving from model-free to model-based approaches that learn internal representations of the environment. This approach was popularized by Ha and Schmidhuber (2018) and has revolutionized how we think about sample efficiency and planning in RL.\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "#### 1. Model-Based Reinforcement Learning\n",
    "\n",
    "Traditional model-free RL learns policies directly from experience:\n",
    "- **Pro**: No need to model environment dynamics\n",
    "- **Con**: Sample inefficient, cannot plan ahead\n",
    "\n",
    "Model-based RL learns a model of the environment:\n",
    "- **Pro**: Can plan using learned model, more sample efficient  \n",
    "- **Con**: Model errors can compound, more complex\n",
    "\n",
    "#### 2. Recurrent State Space Models (RSSM)\n",
    "\n",
    "The RSSM is the heart of world models, consisting of:\n",
    "\n",
    "**Deterministic Path**: $h_t = f_\\theta(h_{t-1}, a_{t-1})$\n",
    "- Encodes deterministic aspects of state evolution\n",
    "- Uses RNN/LSTM/GRU to maintain temporal consistency\n",
    "\n",
    "**Stochastic Path**: $s_t \\sim p(s_t | h_t)$  \n",
    "- Models stochastic aspects and uncertainty\n",
    "- Typically Gaussian: $s_t \\sim \\mathcal{N}(\\mu_\\phi(h_t), \\sigma_\\phi(h_t))$\n",
    "\n",
    "**Combined State**: $z_t = [h_t, s_t]$\n",
    "- Combines deterministic and stochastic components\n",
    "- Provides rich representation for planning\n",
    "\n",
    "#### 3. Three-Component Architecture\n",
    "\n",
    "**1. Representation Model (Encoder)**\n",
    "$$h_t = f_\\theta(h_{t-1}, a_{t-1}, o_t)$$\n",
    "- Encodes observations into internal state\n",
    "- Maintains temporal consistency\n",
    "\n",
    "**2. Transition Model**  \n",
    "$$\\hat{s}_{t+1}, \\hat{h}_{t+1} = g_\\phi(s_t, h_t, a_t)$$\n",
    "- Predicts next state from current state and action\n",
    "- Enables forward simulation\n",
    "\n",
    "**3. Observation Model (Decoder)**\n",
    "$$\\hat{o}_t = d_\\psi(s_t, h_t)$$\n",
    "- Reconstructs observations from internal state\n",
    "- Ensures representation quality\n",
    "\n",
    "#### 4. Imagination-Augmented Agents (I2A)\n",
    "\n",
    "I2A extends world models by using \"imagination\" for policy learning:\n",
    "\n",
    "**Imagination Rollouts**:\n",
    "- Use world model to simulate future trajectories\n",
    "- Generate imagined experiences: $\\tau^{imagine} = \\{(s_t^i, a_t^i, r_t^i)\\}_{t=0}^H$\n",
    "\n",
    "**Imagination Encoder**:\n",
    "- Process imagined trajectories into useful features\n",
    "- Extract planning-relevant information\n",
    "\n",
    "**Policy Network**:\n",
    "- Combines real observations with imagination features  \n",
    "- Makes decisions using both current state and future projections\n",
    "\n",
    "### Mathematical Framework\n",
    "\n",
    "#### State Space Model\n",
    "\n",
    "The world model learns a latent state space representation:\n",
    "\n",
    "$$p(s_{1:T}, o_{1:T} | a_{1:T}) = \\prod_{t=1}^T p(s_t | s_{t-1}, a_{t-1}) p(o_t | s_t)$$\n",
    "\n",
    "Where:\n",
    "- $s_t$: latent state at time $t$\n",
    "- $o_t$: observation at time $t$  \n",
    "- $a_t$: action at time $t$\n",
    "\n",
    "#### Training Objectives\n",
    "\n",
    "**1. Reconstruction Loss**:\n",
    "$$\\mathcal{L}_{recon} = \\mathbb{E}_{(o,a) \\sim \\mathcal{D}}[||o - \\hat{o}||^2]$$\n",
    "\n",
    "**2. KL Regularization**:\n",
    "$$\\mathcal{L}_{KL} = \\mathbb{E}_{s \\sim q_\\phi}[D_{KL}(q_\\phi(s|o,h) || p(s|h))]$$\n",
    "\n",
    "**3. Prediction Loss**:\n",
    "$$\\mathcal{L}_{pred} = \\mathbb{E}_{(s,a,s') \\sim \\mathcal{D}}[||s' - \\hat{s}'||^2]$$\n",
    "\n",
    "**Total Loss**:\n",
    "$$\\mathcal{L}_{world} = \\mathcal{L}_{recon} + \\beta \\mathcal{L}_{KL} + \\lambda \\mathcal{L}_{pred}$$\n",
    "\n",
    "### Planning Algorithms\n",
    "\n",
    "#### 1. Model Predictive Control (MPC)\n",
    "\n",
    "MPC uses the world model for online planning:\n",
    "\n",
    "1. **Rollout**: Simulate $H$-step trajectories using world model\n",
    "2. **Evaluate**: Score trajectories using reward predictions  \n",
    "3. **Execute**: Take first action of best trajectory\n",
    "4. **Replan**: Repeat process at next timestep\n",
    "\n",
    "**MPC Objective**:\n",
    "$$a^* = \\arg\\max_a \\sum_{h=1}^H \\gamma^h r(s_h, a_h)$$\n",
    "\n",
    "where $(s_h, a_h)$ come from world model rollouts.\n",
    "\n",
    "#### 2. Cross Entropy Method (CEM)\n",
    "\n",
    "CEM is a population-based optimization method:\n",
    "\n",
    "1. **Sample**: Generate action sequence population\n",
    "2. **Evaluate**: Score sequences using world model\n",
    "3. **Select**: Keep top-performing sequences\n",
    "4. **Update**: Fit distribution to elite sequences\n",
    "5. **Repeat**: Iterate until convergence\n",
    "\n",
    "### Advantages and Applications\n",
    "\n",
    "**Advantages**:\n",
    "- **Sample Efficiency**: Learn from imagined experiences\n",
    "- **Planning Capability**: Look ahead before acting\n",
    "- **Transfer Learning**: World models can transfer across tasks\n",
    "- **Interpretability**: Can visualize agent's internal world understanding\n",
    "\n",
    "**Applications**:\n",
    "- **Robotics**: Sample-efficient robot learning\n",
    "- **Game Playing**: Strategic planning in complex games  \n",
    "- **Autonomous Driving**: Safe planning with uncertainty\n",
    "- **Finance**: Portfolio optimization with market models\n",
    "\n",
    "### Key Research Papers\n",
    "\n",
    "1. **World Models** (Ha & Schmidhuber, 2018)\n",
    "2. **PlaNet** (Hafner et al., 2019)  \n",
    "3. **DreamerV1** (Hafner et al., 2020)\n",
    "4. **DreamerV2** (Hafner et al., 2021)\n",
    "5. **I2A** (Weber et al., 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113977f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… World Models Implementation Complete!\n",
      "Components implemented:\n",
      "- RSSMCore: Recurrent state space model with deterministic/stochastic components\n",
      "- WorldModel: Complete world model with encoder/decoder and predictors\n",
      "- MPCPlanner: Cross-entropy method planner for action sequence optimization\n",
      "- ImaginationAugmentedAgent: I2A-style agent combining model-free and imagination\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class RSSMCore(nn.Module):\n",
    "    \"\"\"\n",
    "    Recurrent State Space Model Core\n",
    "    Combines deterministic and stochastic state evolution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim: int = 30, hidden_dim: int = 200, \n",
    "                 action_dim: int = 2, embed_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.rnn = nn.GRUCell(state_dim + action_dim, hidden_dim)\n",
    "        \n",
    "        self.prior_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, state_dim * 2),  # mean and logstd\n",
    "        )\n",
    "        \n",
    "        self.posterior_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + embed_dim, state_dim * 2),\n",
    "        )\n",
    "        \n",
    "    def initial_state(self, batch_size: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Initialize hidden and stochastic states\"\"\"\n",
    "        return {\n",
    "            'hidden': torch.zeros(batch_size, self.hidden_dim, device=device),\n",
    "            'stoch': torch.zeros(batch_size, self.state_dim, device=device)\n",
    "        }\n",
    "    \n",
    "    def observe(self, embed: torch.Tensor, action: torch.Tensor, \n",
    "                state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Update state using observation (posterior update)\n",
    "        \"\"\"\n",
    "        hidden = self.rnn(\n",
    "            torch.cat([state['stoch'], action], dim=1), \n",
    "            state['hidden']\n",
    "        )\n",
    "        \n",
    "        posterior_input = torch.cat([hidden, embed], dim=1)\n",
    "        posterior_params = self.posterior_net(posterior_input)\n",
    "        posterior_mean, posterior_logstd = posterior_params.chunk(2, dim=1)\n",
    "        posterior_std = torch.exp(posterior_logstd)\n",
    "        \n",
    "        stoch = posterior_mean + posterior_std * torch.randn_like(posterior_std)\n",
    "        \n",
    "        prior_params = self.prior_net(hidden)\n",
    "        prior_mean, prior_logstd = prior_params.chunk(2, dim=1)\n",
    "        prior_std = torch.exp(prior_logstd)\n",
    "        \n",
    "        return {\n",
    "            'hidden': hidden,\n",
    "            'stoch': stoch,\n",
    "            'prior_mean': prior_mean,\n",
    "            'prior_std': prior_std,\n",
    "            'posterior_mean': posterior_mean,\n",
    "            'posterior_std': posterior_std\n",
    "        }\n",
    "    \n",
    "    def imagine(self, action: torch.Tensor, \n",
    "                state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Predict next state using action (prior update)  \n",
    "        \"\"\"\n",
    "        hidden = self.rnn(\n",
    "            torch.cat([state['stoch'], action], dim=1),\n",
    "            state['hidden']\n",
    "        )\n",
    "        \n",
    "        prior_params = self.prior_net(hidden)\n",
    "        prior_mean, prior_logstd = prior_params.chunk(2, dim=1)\n",
    "        prior_std = torch.exp(prior_logstd)\n",
    "        \n",
    "        stoch = prior_mean + prior_std * torch.randn_like(prior_std)\n",
    "        \n",
    "        return {\n",
    "            'hidden': hidden,\n",
    "            'stoch': stoch,\n",
    "            'prior_mean': prior_mean,\n",
    "            'prior_std': prior_std\n",
    "        }\n",
    "\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete World Model with encoder, RSSM core, and decoders\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, action_dim: int, state_dim: int = 30,\n",
    "                 hidden_dim: int = 200, embed_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, embed_dim),\n",
    "        )\n",
    "        \n",
    "        self.rssm = RSSMCore(state_dim, hidden_dim, action_dim, embed_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(state_dim + hidden_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, obs_dim),\n",
    "        )\n",
    "        \n",
    "        self.reward_model = nn.Sequential(\n",
    "            nn.Linear(state_dim + hidden_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "        \n",
    "        self.continue_model = nn.Sequential(\n",
    "            nn.Linear(state_dim + hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encode observation to embedding\"\"\"\n",
    "        return self.encoder(obs)\n",
    "    \n",
    "    def decode(self, state: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Decode state to observation\"\"\"\n",
    "        state_concat = torch.cat([state['stoch'], state['hidden']], dim=1)\n",
    "        return self.decoder(state_concat)\n",
    "    \n",
    "    def predict_reward(self, state: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Predict reward from state\"\"\"\n",
    "        state_concat = torch.cat([state['stoch'], state['hidden']], dim=1)\n",
    "        return self.reward_model(state_concat)\n",
    "    \n",
    "    def predict_continue(self, state: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Predict episode continuation probability\"\"\"\n",
    "        state_concat = torch.cat([state['stoch'], state['hidden']], dim=1)\n",
    "        return self.continue_model(state_concat)\n",
    "    \n",
    "    def observe_sequence(self, obs_seq: torch.Tensor, \n",
    "                        action_seq: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Process a sequence of observations and actions\n",
    "        Returns states, reconstructions, and losses\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = obs_seq.shape[:2]\n",
    "        \n",
    "        state = self.rssm.initial_state(batch_size)\n",
    "        \n",
    "        states = []\n",
    "        reconstructions = []\n",
    "        rewards = []\n",
    "        continues = []\n",
    "        kl_losses = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            embed = self.encode(obs_seq[:, t])\n",
    "            \n",
    "            if t == 0:\n",
    "                action = torch.zeros(batch_size, self.action_dim, device=device)\n",
    "            else:\n",
    "                action = action_seq[:, t-1]\n",
    "                \n",
    "            state = self.rssm.observe(embed, action, state)\n",
    "            states.append(state)\n",
    "            \n",
    "            reconstruction = self.decode(state)\n",
    "            reward = self.predict_reward(state)\n",
    "            continue_prob = self.predict_continue(state)\n",
    "            \n",
    "            reconstructions.append(reconstruction)\n",
    "            rewards.append(reward)\n",
    "            continues.append(continue_prob)\n",
    "            \n",
    "            if 'posterior_mean' in state:\n",
    "                kl = self._kl_divergence(\n",
    "                    state['posterior_mean'], state['posterior_std'],\n",
    "                    state['prior_mean'], state['prior_std']\n",
    "                )\n",
    "                kl_losses.append(kl)\n",
    "        \n",
    "        return {\n",
    "            'states': states,\n",
    "            'reconstructions': torch.stack(reconstructions, dim=1),\n",
    "            'rewards': torch.stack(rewards, dim=1),\n",
    "            'continues': torch.stack(continues, dim=1),\n",
    "            'kl_losses': torch.stack(kl_losses, dim=1) if kl_losses else None\n",
    "        }\n",
    "    \n",
    "    def imagine_sequence(self, initial_state: Dict[str, torch.Tensor],\n",
    "                        actions: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Imagine future sequence using world model\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = actions.shape[:2]\n",
    "        \n",
    "        state = {k: v.clone() for k, v in initial_state.items()}\n",
    "        \n",
    "        states = [state]\n",
    "        rewards = []\n",
    "        continues = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            state = self.rssm.imagine(actions[:, t], state)\n",
    "            states.append(state)\n",
    "            \n",
    "            reward = self.predict_reward(state)\n",
    "            continue_prob = self.predict_continue(state)\n",
    "            \n",
    "            rewards.append(reward)\n",
    "            continues.append(continue_prob)\n",
    "        \n",
    "        return {\n",
    "            'states': states[1:],  # Exclude initial state\n",
    "            'rewards': torch.stack(rewards, dim=1),\n",
    "            'continues': torch.stack(continues, dim=1)\n",
    "        }\n",
    "    \n",
    "    def _kl_divergence(self, mean1: torch.Tensor, std1: torch.Tensor,\n",
    "                      mean2: torch.Tensor, std2: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute KL divergence between two Gaussian distributions\"\"\"\n",
    "        var1 = std1.pow(2)\n",
    "        var2 = std2.pow(2)\n",
    "        \n",
    "        kl = (var1 / var2 + (mean2 - mean1).pow(2) / var2 + \n",
    "              torch.log(std2 / std1) - 1).sum(dim=1, keepdim=True)\n",
    "        \n",
    "        return 0.5 * kl\n",
    "\n",
    "\n",
    "class MPCPlanner:\n",
    "    \"\"\"\n",
    "    Model Predictive Control planner using Cross Entropy Method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, world_model: WorldModel, action_dim: int,\n",
    "                 horizon: int = 12, n_candidates: int = 1000, \n",
    "                 n_iterations: int = 10, n_elite: int = 100):\n",
    "        \n",
    "        self.world_model = world_model\n",
    "        self.action_dim = action_dim  \n",
    "        self.horizon = horizon\n",
    "        self.n_candidates = n_candidates\n",
    "        self.n_iterations = n_iterations\n",
    "        self.n_elite = n_elite\n",
    "        \n",
    "        self.action_min = -1.0\n",
    "        self.action_max = 1.0\n",
    "    \n",
    "    def plan(self, initial_state: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Plan action sequence using CEM\n",
    "        \"\"\"\n",
    "        batch_size = initial_state['hidden'].shape[0]\n",
    "        \n",
    "        mean = torch.zeros(batch_size, self.horizon, self.action_dim, device=device)\n",
    "        std = torch.ones(batch_size, self.horizon, self.action_dim, device=device)\n",
    "        \n",
    "        for iteration in range(self.n_iterations):\n",
    "            noise = torch.randn(batch_size, self.n_candidates, self.horizon, \n",
    "                              self.action_dim, device=device)\n",
    "            \n",
    "            mean_expanded = mean.unsqueeze(1).expand(-1, self.n_candidates, -1, -1)\n",
    "            std_expanded = std.unsqueeze(1).expand(-1, self.n_candidates, -1, -1)\n",
    "            \n",
    "            actions = mean_expanded + std_expanded * noise\n",
    "            actions = torch.clamp(actions, self.action_min, self.action_max)\n",
    "            \n",
    "            returns = self._evaluate_sequences(initial_state, actions)\n",
    "            \n",
    "            _, elite_indices = torch.topk(returns, self.n_elite, dim=1)\n",
    "            \n",
    "            for b in range(batch_size):\n",
    "                elite_actions = actions[b, elite_indices[b]]\n",
    "                mean[b] = elite_actions.mean(dim=0)\n",
    "                std[b] = elite_actions.std(dim=0) + 1e-6\n",
    "        \n",
    "        final_noise = torch.randn(batch_size, 1, self.horizon, \n",
    "                                self.action_dim, device=device)\n",
    "        final_actions = mean.unsqueeze(1) + std.unsqueeze(1) * final_noise\n",
    "        final_actions = torch.clamp(final_actions, self.action_min, self.action_max)\n",
    "        \n",
    "        return final_actions[:, 0, 0]  # First action\n",
    "    \n",
    "    def _evaluate_sequences(self, initial_state: Dict[str, torch.Tensor],\n",
    "                           actions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate action sequences using world model\n",
    "        \"\"\"\n",
    "        batch_size, n_candidates = actions.shape[:2]\n",
    "        \n",
    "        expanded_state = {}\n",
    "        for key, value in initial_state.items():\n",
    "            expanded_state[key] = value.unsqueeze(1).expand(\n",
    "                -1, n_candidates, -1\n",
    "            ).reshape(batch_size * n_candidates, -1)\n",
    "        \n",
    "        actions_flat = actions.reshape(batch_size * n_candidates, self.horizon, -1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            imagined = self.world_model.imagine_sequence(expanded_state, actions_flat)\n",
    "        \n",
    "        rewards = imagined['rewards']  # [batch*candidates, horizon, 1]\n",
    "        continues = imagined['continues']  # [batch*candidates, horizon, 1]\n",
    "        \n",
    "        gamma = 0.99\n",
    "        returns = torch.zeros(batch_size * n_candidates, device=device)\n",
    "        \n",
    "        for t in range(self.horizon):\n",
    "            discount = gamma ** t\n",
    "            continue_discount = torch.prod(continues[:, :t+1], dim=1) if t > 0 else continues[:, 0]\n",
    "            returns += discount * continue_discount.squeeze() * rewards[:, t].squeeze()\n",
    "        \n",
    "        returns = returns.reshape(batch_size, n_candidates)\n",
    "        \n",
    "        return returns\n",
    "\n",
    "\n",
    "class ImaginationAugmentedAgent(nn.Module):\n",
    "    \"\"\"\n",
    "    Agent that uses imagination for decision making (I2A style)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, action_dim: int, world_model: WorldModel,\n",
    "                 planner: MPCPlanner, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.world_model = world_model\n",
    "        self.planner = planner\n",
    "        \n",
    "        self.model_free_policy = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.value_function = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self.imagination_encoder = nn.Sequential(\n",
    "            nn.Linear(world_model.state_dim + world_model.hidden_dim + 1, 128), # state + reward\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.combined_policy = nn.Sequential(\n",
    "            nn.Linear(action_dim + 64, hidden_dim),  # MF action + imagination features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs: torch.Tensor, use_imagination: bool = True) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass combining model-free and model-based components\n",
    "        \"\"\"\n",
    "        batch_size = obs.shape[0]\n",
    "        \n",
    "        mf_action = self.model_free_policy(obs)\n",
    "        \n",
    "        value = self.value_function(obs)\n",
    "        \n",
    "        if not use_imagination:\n",
    "            return {\n",
    "                'action': mf_action,\n",
    "                'value': value,\n",
    "                'imagination_features': None\n",
    "            }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embed = self.world_model.encode(obs)\n",
    "            initial_state = self.world_model.rssm.initial_state(batch_size)\n",
    "            dummy_action = torch.zeros(batch_size, self.action_dim, device=device)\n",
    "            current_state = self.world_model.rssm.observe(embed, dummy_action, initial_state)\n",
    "        \n",
    "        imagination_features = self._generate_imagination_features(current_state)\n",
    "        \n",
    "        combined_input = torch.cat([mf_action, imagination_features], dim=1)\n",
    "        final_action = self.combined_policy(combined_input)\n",
    "        \n",
    "        return {\n",
    "            'action': final_action,\n",
    "            'value': value,\n",
    "            'imagination_features': imagination_features,\n",
    "            'mf_action': mf_action\n",
    "        }\n",
    "    \n",
    "    def _generate_imagination_features(self, state: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate features from imagined rollouts\n",
    "        \"\"\"\n",
    "        batch_size = state['hidden'].shape[0]\n",
    "        horizon = 5  # Short imagination horizon\n",
    "        \n",
    "        imagination_actions = torch.randn(batch_size, horizon, self.action_dim, device=device)\n",
    "        imagination_actions = torch.clamp(imagination_actions, -1, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            imagined = self.world_model.imagine_sequence(state, imagination_actions)\n",
    "        \n",
    "        features = []\n",
    "        for t in range(horizon):\n",
    "            state_t = imagined['states'][t]\n",
    "            reward_t = imagined['rewards'][:, t]\n",
    "            \n",
    "            state_concat = torch.cat([state_t['stoch'], state_t['hidden'], reward_t], dim=1)\n",
    "            \n",
    "            step_features = self.imagination_encoder(state_concat)\n",
    "            features.append(step_features)\n",
    "        \n",
    "        imagination_features = torch.stack(features, dim=1).mean(dim=1)\n",
    "        \n",
    "        return imagination_features\n",
    "\n",
    "print(\"âœ… World Models Implementation Complete!\")\n",
    "print(\"Components implemented:\")\n",
    "print(\"- RSSMCore: Recurrent state space model with deterministic/stochastic components\")\n",
    "print(\"- WorldModel: Complete world model with encoder/decoder and predictors\")  \n",
    "print(\"- MPCPlanner: Cross-entropy method planner for action sequence optimization\")\n",
    "print(\"- ImaginationAugmentedAgent: I2A-style agent combining model-free and imagination\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149e9348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Exercise 1: World Models Training and Evaluation\n",
      "======================================================================\n",
      "Environment: 4D state, 2D action\n",
      "Collecting 50 episodes of random data...\n",
      "Episode 0/50\n",
      "Episode 20/50\n",
      "Episode 40/50\n",
      "Collected 50 episodes\n",
      "Created 54 training batches\n",
      "World model parameters: 601,830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training world model for 30 epochs...\n",
      "Epoch 0: Total=2.8761, Recon=0.4948, KL=0.6107, Reward=2.3202\n",
      "Epoch 10: Total=0.2906, Recon=0.0966, KL=-0.7082, Reward=0.2648\n",
      "Epoch 20: Total=0.2545, Recon=0.0906, KL=-0.8518, Reward=0.2491\n",
      "Evaluating MPC planning for 10 episodes...\n",
      "Episode 0: Reward=-26.37, Length=200\n",
      "Episode 5: Reward=-33.39, Length=200\n",
      "Average reward: -31.52 Â± 6.46\n",
      "Average length: 200.0 Â± 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABcoAAAPXCAYAAAAbkngyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Qd4VGX2x/FzZ9JDEkpClSZNURSRouiiqKCIXSyrrqKurmtd+7K7Flxdu7uWv21dxbquYFdUsKAiiiKIIlWk1ySUJKTP3P9z3skdJskkJJDp38/zzE64096ZN3HvPXPu77Vs27YFAAAAAAAAAIAE5Yr0AAAAAAAAAAAAiCQK5QAAAAAAAACAhEahHAAAAAAAAACQ0CiUAwAAAAAAAAASGoVyAAAAAAAAAEBCo1AOAAAAAAAAAEhoFMoBAAAAAAAAAAmNQjkAAAAAAAAAIKFRKAcAAAAAAAAAJDQK5QBiTo8ePcylqVauXCmWZcn48eMlVk2aNMm8B73eE7fffrt5nhkzZkg0a6lx6uP1efT5AAAAgHg/bgAA7D4K5QBq+f77783O4bBhw4Le/t///tfcrpcVK1bUu72srEzS0tIkIyNDKioqJJZ3kPXSqlUrKS4uDno/27alV69e/vtGe/F5dwrVTb0054sLiBx55JFx9zsDAAAQyNlPDOaXX37x70f/5S9/8W/XfUrdpvvje9pgEnjRffq99tpLjjnmGLn11ltl2bJlu/38iDz9IqMlmogAoK6kelsAJLSDDjpI2rRpYwrmRUVFkp2dXev2Tz75xOyUaJH4008/lYsvvrjW7V999ZUpkI8aNUpSU1MlliUlJcmOHTvMlwOXXnppvdv1s/j111/N/aqrqyXeCrl1/fDDD/L222/LgQceKKecckqt21q3bt2ir3/llVfK2WefLd26dduj5xk6dKgsWrRIcnNzW2xsAAAA2H16nHH88cdLQUGBPProo2a/LxQC91m1mWfz5s0ye/Zs+fvf/y533XWXXHXVVfLAAw+YfXlHly5dzL5jTk5OSMYEAIhuFMoB1OJyuUyR9M0335TPP/9cTjzxxFq3a3Fcb//xxx+DFsp1mzr66KMl1h188MGyatUq+fe//x20UK7b9cuAo446Sj744AOJJzrHdYvl2rGhhfKBAweGPMpEC9stUdzWMxv22WefFhkTAAAA9sz06dPltNNOk8rKSnn11VfljDPOCNlrNbTP+tlnn5mO5IcffljKy8vlySef9N+WnJzMviMAJDCiVwDU4xS5naK3Q0+B1LgVvf2II44wO5l1BSuUb9++XSZMmCD9+vUzsSzasX7sscfKxx9/3Gim9Lfffitjx46Vtm3bNukUTI1Iue6668xplfo6upP70EMPidfr3a3PQbtLLrzwQpkzZ47Mnz+/1m3aAfPWW2/J6aefbsbXWMeM3qd9+/amqN69e3e5/PLLZcOGDQ2ehqoHDPoZZWZmyvDhw+X9999vdJxr1641nTh77723eY127drJSSedJN99952EQ1PmTH9X9MuG/v37m7MU0tPTZf/995eJEyeaA5SmZpTrNi3g6+evz9epUyfznvfbbz957rnnGh1bsOgTPRPgH//4h/Tp08c8T9euXeXmm282B2/BvPzyyzJo0CAzfp3T3/3ud7J+/Xr/84XKa6+9JiNGjDDdTfraAwYMkLvvvjtovJF+ifXb3/7WnLqs7ykvL8+M+U9/+pNUVVXV+nvRjiqdB52TrKwscwr0WWedZX5v69IOrHHjxknHjh0lJSXFfFZ/+MMfzPuvS8+00Pnp3bu3Ga/+PuiYL7vsMiksLAzBJwQAAKKdnqV5wgknmMacDz/8MKRF8saMHDlSPvroI7M/8/TTT8u8efMazSg/7rjjzLa6xwOO//3vf+b2G264odb2LVu2mGOgfffd1+wP6X6cHiNNmzat0fWI9LPRfUu9f+D+pR5T6f5c3WMd3e9qKFe9tLTU7DPqlwZ6bKERNIceeqiZi8b2m/VMUt2n17NGtfFEj/1mzZoV9P17PB7zZcNhhx3m31fVfcDf//739SJudN/78ccfl0MOOcTsf+pz6xnNjz322G4fszWFngms86j7pLp/3LdvX/nzn/9sPtPd3Y/V44VHHnnE7GfrsZu+F93/Pvnkk4Me5wKIDXSUA6hHO6SdHYpAzr/1dt0JeuONN2ThwoWm+Kk0qkWLyrqjoDsMatu2bWanSe83ZMgQs3OnRU4t/I0ePVqeeOIJU2yr6+uvvzY7dYcffrhcdNFF5jG6M9sQLRjqjqcWh/U0y3PPPde8thYCtTN+d+kO3j333GO6x3UHzvH888+bnaNLLrlEnnnmmaCPfe+990yRXGNqtMCoRXItQOp71s7smTNnSs+ePf331x1J3XHVHbAxY8aYHVotnOspo/rvYObOnWs+R90R1y8ftEPHKeLrZ6dnBuipreHQ2Jzde++9snjxYlP4151uLY5rTI/uiOtOue5Mut3uJr2O8zulz62fq8795MmTzWvqgdcFF1zQ5DGfc8458uWXX5rPV3fWp06dKvfdd585Nbdu4V23axFdf7/1NfRvQLuinIOCUNHcTv1ctcNex6sHOHoGg27Xgzw92HI+Zy2S6/oCepCjX5bo75f+XervkR6U3HnnnaZTSn8n9WBBD3j0d05/z/WLIf3SRb/U+M1vfmPOqHA8++yz5oBBDyz0ebVIrr+v+rv/7rvvyjfffOOPydEvgfRvXV9Xf/f0b0DnW79ke/HFF82XOvplDgAASBzavX3ttddKhw4dzH6M7udGkhaZzzzzTHnppZfklVdeMcXahuh+n+5zvfDCC/Lggw/Wu12PC1RgoVrPStVitxbedb9K97s00lGPD/Tnp556yhxH1DVlyhRTKNd9Uy3M6vMo3ZfSYzDd99ex6rGOFnk1Qkb3ZRvaZ9bH6BcBemym+8pajNb3ovuUP//8s9k3rEuP53S/19lHXL16tbz++uvmWEsL6Nr85NDjIf3yQ/eJdf9Qn1f3qfV963GIHhdoQ4rShg09W1lfX59D76sFf9331BgcbcrQfcWWpp/1H//4R/NFgX45o80uevyhxye6H6vHJE6MZHP2Y3W+9QsHbTo5//zzTVFdG0j0GE/nUPPwAcQgGwCC6NSpk21Zlr1582b/tnPOOcdu1aqVXVVVZS9YsMDW/4Q8+uij/tvfeecds+3UU0/1b7v00kvNNr32er3+7UuXLrWzs7PtlJQUe8WKFf7tn332mbm/Xp588smgY+vevbu5BLrrrrvMY0477TTb4/H4t//66692mzZtzG0XXHBBk967jkfvf9hhh5l/H3300Xbr1q3t0tJS/3322Wcfu0+fPubnc88919xfx+4oLi6227Zta7tcLvuLL76o9fz33HOPuf+oUaNqbdd/6/Z//etftba/9dZb/s/kueee82/XeejVq5edmppqz5gxo9Zj1q1bZ3fu3Nnu2LGjXV5e7t9+22231RtrU+lrB/scmzJny5cvrzX/jr/97W/mca+++mqt7Q2N03mdiy++2K6urvZv//nnn223223vu+++QcemzxfoiCOOMNsHDRpkFxYW+reXlJSYz1TnbcOGDbXGn5SUZOfm5tqrV6/2b9f3dPbZZ/vH1VTO6+9qHmbNmmXu17Vr11rj0bk/4YQTzG36u++47rrrzDb9nalry5Yt/r+NH3/80dzvlFNOqXc/vY/e17FkyRI7OTnZfC5r166tdd+PP/7YfFaBz/PII48E/T12Pt/AvyMAABC/nP2jm2++2VzrvrPumzdG9/H1voHHBy21z1rXM888Y+43YsSIescBgY8tKyuzc3Jy7A4dOph9sEC6f6b7oLpPWXdfT4+l/vvf/9bavnXrVvvAAw+009LS7I0bN9Ybsz7mgw8+qDfWO+64w9yu+52B+9S6X6r7p8Her/5bt9977721tuv7OfbYY81rzZs3L+g+feAxh9J9fN3+xz/+sdb2CRMmmO0nnnhirWMOpf8OPJZ09u+vvPLKWvvx+vNFF13U4D5sMM57qzvOulauXGmON7OysuxFixbVuk3fiz7HJZdc0uz92G3btpnP7+CDD671XhwFBQVNeh8Aog/RKwCC0o4B3b8NjFdxOk2181SjLvTb+MB4lrqxK9phoF0a2gGrHbGBpw5qZ8HVV19t7qPdGXVpl0mwTvOGaPevdhNr94NeO7SjVl9nT2i3h3ZkaNey0q4N7Y7WDouGaMe4dnlrjIV+ZoGuv/56c1qedl5oh4bSTl79t4637oJGevqenu5Yl0ayLF++3HRg1L29c+fOctNNN8nGjRvrnRkQKo3NmcbCBIsm0c4ipZ0lTaWnNepppoEd6HpWg3Z26+JLJSUlTX4u7SQJjM7RThPt0NFuG+2mcWinkZ4qqp+1dss49D3pGQdN7YZvLu3kVn/7299M5IlD/wa1o0l/14Od0aAdLXVpJ3zg30ZD99P76H0degaEdgBpJ5gucBVI/9a1w1y7cTTKZVfPrZ9vsO0AACB+6f6WntGmXbaBZ1NGmrNfk5+f3+j9tOtZu883bdpUb59Vj3U0eiTwjEaNaNEzWrUbWRenD6Sdy070oHZp16X7/dpxHqxrXffR6h5T6X6pnrFbl56hqmMbPHiwOSao+350TvRYT/dx69J96roxLtqNrvufGrPo0PetZyzqvp1Gr+iZh4GcCECl+9a6cKvuz/7zn/+ste+sP+t+rb4vjTlsSfoZ6PGmHl/VzZ7XbnyNHtRO8bpxhrvaj9Wx6uen77Hu/rXi7EkgdhG9AiAoPU1Pdyy0+K07hlqA1FPRnMKm0tMJtbirOz66g1C3UL5kyRKTi6c7W8FyvPU19HS/wFxAx9ChQ5s8Vi3QabSE7ihqxnJdOk7dId1dp556qom90PgVPa1Oswx1Zz9YDqBDT4sMjLEJpDuZmjetpyTqe9fICucz0NMTgxVd9T3UjZDRqBOlp2QGW6jIyQTUuQtH/Epjc6anmmqhVU/BXLp0qZkzX6ORz7p165r8Ovoli57SWZdTwN66dav5cqYp9OChsedxBM5PXRqpo4/ZVYb+7mjs90izFTWjUk8F1VNvNf5Fv5jRz1njejSWRk/51L+/un8X+sWCfrGhp4vq748elOl708+jbsSR83umv3/Bcu81pkYPlHReNa5FC+caC3PFFVeYg0mNBNIx6GuGMscdAABEJ90XcOI+tFjuxFxEmrMv2pT9E93v12MBLVhrjKBD/63HBfre6u476f5ZsH10pzCv++hN2Z/WGBBtjtH9TW22qSvY/qnus+n+WbC1epSzbk2wMQTbP9b3qLE5gfvH2jik71Fj/7RJpzG6n6hNRLofHyzuRWkROth4QrUvrY0hGmPzxRdfmPei8Z1N3Y/VYxGNkdFmEd2n1i9FtDlKPwtt6gEQuyiUAwjKKXY73ciB+eSBxVvNGneKvT/99JPpzHC+rXcWR9EFF4Nxtmu3dl2B3bO74ryO7rwF05znCkYLh1og1y5m3fHV7EDdidKO+l2NqanvfXfeg7OYjNPp3pDmdFjviYY+Z90R198b7UDRDD8t5mp3ie5wK/0SI9iilA1p6OBKv4BQelCwJ88V7Hl2NT+6PRSF8qb8HulZCfp7pIVyPbjSMx60Q0Z/T52cR82BvO2228win0q/jNEvtu644w5zP81eV9pVox1R2q3kfNng/J7df//9Tfo90y8OdK71oEwPhnUtA6UHd7rI1Z6e4QEAAGKLnmmpjTfvvPOO2SfURpto6Lh1FiR3up4bo+vsaJOCvgctFmuRVYuwCxYsMA0K2lTjcPad9H3qpTn76MH2p7VQvqv90LqcMWjBPFijQ2NjaGxfO3D/2DmOqXvGYTDOeLSRp7EGppY+bmnuMVlz9mN1EVftzNeufN3Pdrr1tVnlgQceaHC+AEQ3olcABKWFb+1C1U7tNWvWmKKa7jQFLnSjK8YrvU1jWbQrwymwK2eBQ43/CEY71APvF6g5nafO4/V0yGAaev3mcBbb0Z18PVVSFzZsypia+t535z04j9GDD/3sG7o4O26h1tCc6fh0h1M7cfTLFO3I10Ku7oA2J14nkpwO9obmp6Hte2p3/oZ04SVdKEoP4nRxoltuucWMTzuddNFUhx7g6amv+vftLMypX3LporW64FHdMeiBRmO/Z4HxP/vuu685eNCDIo2w0XgaPfPkmmuukf/85z8h+KQAAEC00ngKjRnR/WhtsNFmm1DtOzWHEzGpXcBNoY0z2tyh+ziBi3jWXUje2XfSs/wa23equ3B8Q/vTu7Mf6oxBzwZubAyBMZvN5RTUm3JmqDMePVO3sfHomZKR3pdu6n6sdsDr8Yx2y2vjip6Nrd39eq3FcgCxiUI5gAY5RW8trunK4FoIC8xg06Kadj1oobxu7IrTxaqnnmlOX7CucWfHTFdh3xPaBdu7d2+zk6anJdalY99T+l71dDrNEtdTHkeNGtXo/Z0vFIK9tmZdO6vTO+/dub+ukh6sIzrY8xxyyCHmuqGV7qOFftmiTjvttHq31Y2TiVaB81OXRpdosTmUrxts/vVz1d9HzfoM1vmjB6Xa/aRd44888oj/S4tg9O/n4osvNvOhneSB99uT3zPtPNI4Fu1Y15gX9dZbbzX7eQAAQGzTfQLtvNVis3Zhawyh7sdEikZt6FmZWpgOjE1pjI5dj4W0QK5nTOq+jXaSB0axhGIfXQvlut6PHusEO4Mx2P6pnmWoYw3lcYIeH+k+6I8//ujvzt/Vfb/55ht/7Es4NLYvrcenP/zwg+kC1+L4nuzHase5rnOkcS26X61z4nTRA4gtFMoBNMiJWdGuU+1OdTrIA+k23QGbNm1avUK5RpboDoPmUWtXayAtaGvxTuM3fve73+3xWC+88ELzTb/uyOi1Q7sSnCLhntJOaM3Y1lPwdtXxrqdgai677lTpDmGgf/3rX2Zcmh+tnftKs6a1+K7btaM3kBYtgxWUNVdau/7/7//+T6ZOnRp0HBoVoznxkeRkKdbdQf3111/9kR/RTg+gdGdZFyEKLIpr58uECROaFffSHLpwktIsx8CFpvT19PRP/V3XArdj1qxZUlZW1mCnkZOZqL9n+vnXpX/n2ikVuICRLn6kf6fakaQdM3XpAkmBB2Hff/+9/zTXxsYAAAASi0a/TZo0yZxRqPsUzpo94ab71bpgpu7D6Fl0mk3dFFoM1eMj3bfXbnHdN9N9RCdOMDDjWxts9JjBWZi9Lj3LUtd5aSot0ut+n+53Bq7zo/ulemxRl0ZE6nGYdkT//e9/D7qvqsdje9LBrfN5+eWXm33Pyy67rF6Uon6+zv6r7kdfddVVpoNb40uC7a/qbQsXLpSWdN5555n50X14p3nHocenGmuj93EWIm3qfqy+L53DYOsyaXyMvt+66/4AiA1klANokO4IakHY2QkItgiKFsq1GKw7WdpBXjejTk9V0yKaFn81H0/vX1BQYLLNtYCu27Ujdk9df/315ht+Pa1Tu7R14RXtEtDX0Z1wzRPcU9oJUXe19IZoV67uGJ9xxhmmE1+vtSiuO1/6pYJ24j/11FO1HqMFb43N0JXr9T660647dFqcdxaLCaQ7fboDru9VO1m0e1gXk9EdON1p1s9bi6G60xnJ4qSOXTsrNONdf5e0s0NPT9R4EB23/hzt9AsJ7czWxX10XjRnXU/R1NxJXZhIt2k3TXPp34ceMAajBxE6pzfddJPcd999Jt9dT+PMzMyUDz74wHRj6emdN954o/8xej89u0MPzvTvSn8Pf/75Z3N/jVpxIoP0LA/t8B8yZIjpoNEFmHSHX7+U0S6fwC8w9Hdef5e1aL/ffvuZA0vN6NT76dzp37dme2pnltJcdP3d1rHp56avqwdi+vurByH6+w0AABKTHls8+eST5kt5LfDqfrquhaSLPAbShoCGFmfXfTKn2aQx2i3sLGSpRVwtds6ePdsUY7Xb+rrrrjP7Ts2hMSt6tq3uEzr/Dka75/XYSRsatGlH4120o1q76HWfUffjtKGlsTWPAun+oB7rvPrqq7JkyRIZPXq0Keg6xzp6W+CZv0qPszRe79ZbbzX7Z7pvprnZ2v2ti2bqsYIex+3JsZhGPOpnqvt5un94wgknmLN99VhEj2d0jRuNX3QK07oPqvOv99fPR48d9QsDHadGBmo8oy6c2VQaHdjQ2cP6JYZ+Tvp7potz6jGixv/ofqt+WaKfv+7nas64o6n7sdrdr8c0AwYMkAMOOMB8iaJFdz2+0ZgX3Y/XzwFADLIBoBEHHHCAtizYubm5ttfrrXf7smXLzO16ufzyy4M+x9atW+2bbrrJ7t27t52SkmLn5OTYxxxzjP3RRx/Vu+9nn31mnuu2225rcEzdu3c3l7q2b99uX3vttXbnzp3t1NRUu1+/fvYDDzxgL1++3DznBRdc0KT3vGLFCnP/ww47rEn3P/fcc839dex1ffvtt/Ypp5xiPr/k5GS7a9eu9mWXXWavW7cu6HPp53n66aebzygjI8M+5JBD7Pfee89+7rnnzGvodV2bNm2yb775Znu//faz09PT7czMTPNZ6/O8+OKLdlVVlf+++rk2NNZdccZQ93NsypytXr3aPuecc8zcpKWl2f3797fvvfdeMzZ97BFHHFHr/g2NM9h9HTouvV3nb1dj0+do6P8CG/usX3jhBXvgwIHm90vnVOde51I/e52zpnJev7HLm2++6b//f//7X/P72KpVK/Pa+vndeeeddllZWa3n1b+p8ePH2/vuu6+dnZ1tfof69u1rX3XVVfbKlSv991uzZo09YcIEe/jw4XaHDh3M32WXLl3s4447zp46dWrQMf/444/mM+7WrZu5f5s2bcz7vvTSS+1PPvnEf79vvvnG/I7rfzv0PjrfvXr1MuP66aefmvwZAQCA2Obs0zTkL3/5i7m9Y8eO9oIFC8w23cff1T7SvHnzGn1dZ18u8KL7RLqvc/TRR9u33nqr2edu7DigoeOGHTt2mH0svc/+++/f6DiKiorsu+66yx40aJDZP9d9oh49etjHH3+8/dRTT9klJSVN2v8MPKbSfbpOnTqZfTHnWGf27Nnmsddcc029x1RUVNiPPvqofeihh5px6+P0eOSoo46y//nPf9oFBQVN3qdv6BhM9+f1NYYMGWLep37WeixyySWX1Puc9XhS96f19XU/UY+P9PhA93P1s9JjhqZw9vsbu+j7C9xHHjVqlN26dWvzGei+6Y033mg+00BN3Y/Vx02cONEeOXKkGb8+p/4e6z7+K6+8EvS4GUBssPR/Il2sBwAgVmn3iHbnaDe/dqYAAAAA4fLvf//bnDWondoaawMA2H1klAMA0AQaTVJ38SFdmFVjf8rLy+XUU0+N2NgAAAAQ34ItmKkxeJpBrpnYGncIANgzZJQDANAEmn+vGY+6CKvmEGo2+RdffGEWo9Jucl2gCAAAAAiF008/3TRtHHzwwSbvXBdC1Uzs0tJSufvuu82aMwCAPUP0CgAATTBv3jzTsfPtt99KYWGh2aaLH+mimLr4JQv2AAAAIFQef/xxs9ikLnypC3nqYqe6oOSVV15p9kcBAHuOQjkAAAAAAAAAIKHFVEb5zz//LGeccYbsvffekpGRIbm5uTJixAh59913m/T4bdu2mUUu8vLyJDMzU0aOHClz584N+bgBAAAAAAAAANErpjLKV61aJcXFxXLBBReY/C3N4tLM2JNOOkmeeuopUwRviNfrlbFjx8r8+fPlxhtvNEV2PXXpyCOPlO+//1769OnT5HHoc+lCGnqavWVZLfTuAAAAEMv0RE3dV9X9VJcrpvpRYh775wAAANjT/fOYj17xeDxmMYvy8nJZvHhxg/d77bXX5KyzzpLJkyfLuHHjzLb8/Hzp27evjBkzRl555ZUmv+batWvNQm4AAABAXWvWrJG99tor0sNIKOyfAwAAYE/3z2OqozwYt9ttdoq/++67Ru83ZcoU6dChQ61FLjSC5cwzz5SXXnpJKioqJDU1tUmv6SzYph9ydna2hIuucD1t2jQZPXq0JCcnh+110TDmJDoxL9GJeYlOzEv0YU5id16KiorMfimL+4ZfJPbP+VuNTsxLdGJeohPzEn2Yk+jEvCTO/nlMFsp37NghZWVlZqXnd955Rz744APTLd6YefPmyaBBg+q12Q8dOlSefvppWbp0qQwYMCDoY7WIrheHtuyr9PR0cwmXpKQkk82ur8kfZnRgTqIT8xKdmJfoxLxEH+YkdudFd9YV0R/h53zmWiQPZ6Fcfyf09fhbjR7MS3RiXqIT8xJ9mJPoxLzE/rw0df88Jgvl119/vckkV1r41i7xxx57rNHHbNiwwSz8WVenTp3MtWYaNlQov/vuu2XixIn1tuu3Fjoh4TZ9+vSwvyYax5xEJ+YlOjEv0Yl5iT7MSezNi66fAwAAACA2xWSh/E9/+pPJGdfitmaPa055ZWVlo4/RDvRg0SppaWn+2xsyYcIEue666+q17Wtrf7ijV/TgbNSoUXyDFSWYk+jEvEQn5iU6MS/RhzmJ3XnRfUQAAAAAsSkmC+X77LOPuajzzz/fFKxPPPFEmT17doOt9HqabGB8ikMXAXVub4gW2IMV2fUgKRIHsJF6XTSMOYlOzEt0Yl6iE/MSfZiT2JsX5gsAAACIXbUDu2OUdpfrYp6aM94QjVjR+JW6nG2dO3cO6RgBAAAAAAAAANEpLgrlTmyKLu7ZkIEDB8rcuXPF6/XW2q5d6Joz3rdv35CPEwAAAAAAAAAQfWIqemXz5s3Svn37enmRL7zwgolO6d+/v79LXIvmvXr18p8Cq13nU6ZMkTfeeMP8rAoKCmTy5MkmtiVYtAoAAPFI1/bQ//9Uep2UlGSiyHQ7Io85AQAAAIDwi6lC+R/+8AezSNKIESOkS5cusnHjRnn55Zdl8eLF8uCDD0qrVq38i28+//zzsmLFCunRo4fZpsXxQw45RC688EJZuHCh5ObmyuOPP24OQCdOnBjhdwYAQOjZtm3+v3Pbtm21tnXs2FHWrFnT4DofCC/mJHrnJSsry1wDAAAAiD8xVSg/66yz5D//+Y888cQTUlhYaA5WDj74YLn33nvlpJNOavSxbrdbpk6dKjfeeKM88sgjJq5lyJAhMmnSJOnXr1/Y3gMAAJHiFMn17CyNHdMirEaSlZSUmC+bXa64SGSLecxJ9NHiuM6JLgyvZzjutddekR4SAAAAgEQulJ999tnmsita/NZLXW3atJFnnnnGXAAASCR6BpVTJG/Xrl2tomxlZaWkpaVRlI0SzEl00pg+jcPRsxv170mbMAAAAADED46+AABIAE4muXaSA9g9KSkptf6eAAAAAMQPCuUAACQQMq+B3cffDwAAABC/KJQDAAAAAAAAABIahXIAAAAAAAAAQEKjUA4AANACZsyYYaI59BoAAAAAEFsolMcI7/p88b71qfRaWRDpoQAAEDW0MN2US1OK1//4xz/krbfeCvmYJ02aZMY0Z86ckL8WgMTmWbBMqr+aF+lhAAAAxISkSA8ATWOX7BD76/nSISMl0kMBACBqvPjii7X+/cILL8j06dPrbd93332bVCgfN26cnHLKKS0+TgAIN9trS9XL74lUVIlr373F1TYn0kMCAACIahTKY4SVlWmuUyurIz0UAACixnnnnVfr3998840plNfdDgAJZ3uxKZIre8t2EQrlAAAAjSJ6JUZY2a3MdUq1V+xqiuUAADTVjh075Prrr5euXbtKamqq9OvXTx544AGxbdt/H41C0fs9//zz/riW8ePHm9tWrVoll19+uXlcenq6tGvXTs444wxZuXJlSMc9b948GTNmjGRnZ0urVq3k6KOPNl8EBKqqqpKJEydKnz59JC0tzYzt8MMPN18WODZu3CgXXnih7LXXXub9d+rUSU4++eSQjx9AZHkLt+38x/aSSA4FAAAgJtBRHisy0kTcLhGPV6S4VCQ9PdIjAgAg6mkx/KSTTpLPPvtMLr74Yhk4cKB89NFHcuONN8q6devkn//8p7mfRrX8/ve/l6FDh8qll15qtvXq1ctcf/fddzJr1iw5++yzTbFZC8xPPPGEHHnkkbJw4ULJyMho8XEvWrRIRo0aZYrkN910kyQnJ8tTTz1lXvPzzz+XYcOGmfvdfvvtcvfdd/vHXlRUZLLP586dax6vTj/9dPn555/lqquukh49esjmzZtNIX316tXm3wDik12wdefP2l0OAACARlEojxHa2SatMn2nUJaUirRvF+khAQDigOmqrqwSu6JSbFcUnGiWkuz7/7wW8s4778inn34qd955p/z1r38126644grTEf7www/LlVdeaQriGtVy2WWXyd57710vtmXs2LEmuzzQiSeeKIceeqi8/vrr8rvf/U5a2l133WW6xWfOnGnGpM4//3zT1a6Fcy2Wq/fff1+OP/54efrpp4M+z7Zt20yR//7775cbbrjBv33ChAktPmYA0cUu2NlRbhfRUQ4AALArFMpjSXZNobxoR6RHAgCIF5VVknbPc+JLsY281Lv/JJLacgtXT506Vdxut1x99dW1tmsUy5QpU+SDDz4wxfLGaNyKQ4vX2rXdu3dvad26tencbulCucfjMR3wGo/iFMmVRqacc8458u9//9uMQbvNdQzaLb5s2TITvxJs7CkpKTJjxgzTUd+mTZsWHSuA6GUHRK/YRK8AAADsUhS0jqHJsnyndtvF7OgCANAUmi/euXNnycrKqrV933339d++K2VlZXLrrbf6M85zc3MlLy/PdGtv3769xcecn58vpaWlpnu8Lh231+uVNWvWmH/fcccdZhx9+/aVAQMGmEiZH3/80X9/He+9995rvhDo0KGDjBgxQu677z6TWw4ggaJX6CgHAADYJTrKY4iVlSlm2THNKAcAoCWkJEv5ny80hWRXlESvRBvN9n7uuefkT3/6k4lbycnJMfEwmlmuRetI0sL38uXL5e2335Zp06bJM888Y3LXn3zySZNbrnTcGhXz1ltvmXz2W265xeSaayTNQQcdFNHxAwhdrFZgoZzFPAEAAHaNQnksycr0XRO9AgBoISYPXHPBU1PEioZCeQvr3r27fPzxx1JcXFyrq3zx4sX+2x0NZaNrRMsFF1wgDz74oH9beXm56eQOBe1W1wVClyxZUu82Hbd+oaHd7Y62bdvKhRdeaC4lJSWmeK6LfDqFcqU57Bo3oxeNadFFTfX9vPTSSyF5DwAiTNc0qqiqFb2ixfOWXAMCAAAg3sTfEXECFMrtEgrlAAA0hS50qZnfjz32WK3t2nWtBaMxY8b4t2VmZgYtfmvGuVn0NMCjjz5qnjcU9PVGjhxpFiJduXKlf/umTZvklVdekcMPP9zkk6vCwsJaj23VqpXJT6+oqDD/1ggXLeoH0qK5fmng3AfYU/q7dPPNN5uYI83FHzZsmEyfPr3Jj//f//5nztbQv0HN3R8+fLg54wEtsJCn02ij/73aURbRMQEAAEQ7OspjMXqFjnIAAJpEI0e06PzXv/7VFJ0PPPBAE1GiUSUaSaJFY8fBBx9sus8feughU/Dr2bOnKfidcMIJ8uKLL5rIlf79+8vXX39t7teuXbs9Gtuzzz4rH374YdCoFx2vLsCpRfHLL79ckpKS5KmnnjIFSc0Yd+h4jjzySDN27SyfM2eO6YB3FihdunSpHH300XLmmWea++rzvPnmm6bortExQEsYP368+b3TvyldVHbSpEnmSypdlFZ/hxujZz9o1v64cePM8+iCuQsWLJB169ZJLHB5vGJXVYskJ0flQp6uju18EVE7ykxOudXKt+YRAAAA6qNQHkuyazpCyCgHAKBJNKZEO7N1MU7tWtWs8R49esj9999vYkgCaYH80ksvlb/97W9mAU+NW9FC+cMPP2y6vF9++WXTnX3YYYeZQvmxxx67R2N74okngm4///zzzaKdn3/+uSmYa564Frp0LBqVoteOq6++2rw/Lf5rEV2jZO68806zqKfSiJbf/va38sknn5hivxbK99lnH3nttdfk9NNP36PxA+rbb7+VV1991fxN3XDDDf7f4f33319uuukmmTVrVoOP/eabb0yRXGOArr32Wok13v9OlWN+WCZ2p54ihw6UaOKtySe32rUWq6RMbC2Ua0555/aRHhoAAEDUolAeS5xTJ0t2kDEIAEAQGrFSN2ZF40i0CK6XxvTr188Up+vSKAjt/q4rMBZFaWd33YiWYLRrVi8N0aJ4UVGRWWgzWMd5IC2k66Uh2vVe9/MAWpJ2kusXSfolkyMtLU0uvvhi+ctf/iJr1qyplakf6F//+pd07NhRrrnmGvO3s2PHDvP3GjPSUsXsjQcumhklnIU8rdw2Ym0rEXtDvq9QDgAAgAZRKI8lzqmSHt/pk/5/AwAAABEwb9486du3rz833zF06FBz/cMPPzRYKNczHTSP/JFHHjFnQmjmvhbO9csfJz6oIXoGRWDOvn65pDS6RS/h4GmbbRZ88m4qDNtrNpU331co97bJEjvLd8zg2bpd7CgbZyg4cxFtc5LomJfoxLxEH+YkOjEvsTsvzZ0zCuUxxEpyS2WSW1KqPWIX7yBjEAAAABG1YcMG6dSpU73tzrb169cHfdzWrVuloKBAvvrqK7Nw52233SbdunUz8Uia05+cnCx/+MMfGnxdjSSaOHFive0aQ5SREZ595NzCEjlYT/ZcuVZmTZ0q0WTkhnxJEZGZC3+S9gUl0ltEVi9YKAsrt0iiaM6Csggf5iU6MS/RhzmJTsxL7M1LaWnz4qsplMeYipSaQrku6NkpL9LDAQAAQALTPP/U1NR62zV+xbk9mJISXwyIdpFrxvlZZ51l/q2Leg4YMMB0mDdWKJ8wYYJcd911tTrKtXN99OjR9brbQ6VqU4HIghelVaVHxhx3nFgu7S+PPLusXLyfLzE/H37yCWLPWyz2qk+ka+u20uP44yXeaeeYHjCPGjXKfOGC6MC8RCfmJfowJ9GJeYndeXHOOmwqCuUxpiIlSbJKK0WKd0R6KAAAAEhw6enptSJQHLrwrXN7Q49TelCjxfHABXi1aK4d5qtXrzZd5sFocT5YgV6fL1wHsHZeW6m2LHFVeySppExc7VpLNPBuLJRK/SErU1JaZYqnbY7oScdWcWlCHdyH83cBTce8RCfmJfowJ9GJeYm9eWnufEVH2wOarDLF992GXcRiPAAAAIgsjVjR+JW6nG2dO3cO+ri2bduarnNdcFYXAw3Uvn17fzxLNNMO8tJ038GXvXlLFC7k6SvcWzm+BVJZzBMAAKBxFMpjMHpFaUY5AAAAEEkDBw6UpUuX1jutdfbs2f7bg9HOcb0tPz9fKitN/7Ofk2uelxf9MYM7MjQJXMTOj6ZC+TZzbeW28V3nZPluKNkhtscTyaEBAABENQrlMaYilY5yAAAARAeNTfF4PPL000/7t2kUiy7KOWzYMJMbrjRGZfHixbUeqxEr+tjnn3++VmTLyy+/LP3792+wGz2a7EhPib6O8kJfodxV01EumRn6zYSIrUGdNNsAAAA0hIzyGMwoV2YxTwAAACCCtBh+xhlnmMU1N2/eLL179zaF75UrV8p//vMf//3OP/98+fzzz8W2tVrro4t1PvPMM3LFFVeYrnTNI3/xxRdl1apV8u6770os2NlRHj0xMV4neqUmM91yWSLZmSLbik2zjdUmPIudAgAAxBoK5TFaKGcxTwAAAESDF154QW655RZT5NZc8QMOOEDee+89GTFiRKOP0wU9P/30U7npppvk2WeflR07dpg4lvfff1+OPfZYiQWlNR3l3vxozCj3Ra+Yn7Nbia2FcnLKAQAAGkShPMZUOhnlRK8AAAAgCuiinPfff7+5NGTGjBlBt+vCnZMmTZJY5XSUm27tikqxUmv+HSE6BidepVahPCdLbNlAoRwAAKARZJTHakd5eaXYlVWRHg4AAACQsKqS3SIZabU6uSPJLtzu+yE9TayacSkrp5Xv9u3FkRoaAABA1KNQHmOq3S6RpJqucuJXAAAAgMiq6dyOhgU9d8au1CzkWbdQzlmpAAAADaJQHmusmsV4FAt6AgCAKKLxGpZlNRizAcQjKy+KCuWF2+rFrph/Z/sK5UL0CgAAQIMolMeiLF+hnI4QAAB8NONYC7TOJSkpSbp06SLjx4+XdevWSTx5/PHHI57pHA1jAKJGTaE8Ghb0bKijXHKyfLdz/AAAANAgFvOM6UI5HeUAAAS64447pGfPnlJeXi7ffPONKebOnDlTFixYYBYcjAdapM7NzTVfAkTbGEaMGCFlZWWSkhLZBQ2BcLLy2oqt++b5UZBRXuDrKHfV7SgnoxwAAGCXKJTHICsr07czTkY5AAC1jBkzRgYPHmx+/v3vf2+Kuffee6+88847cuaZZ0qi2bFjh2Rm1kS2hYHL5YqbLySAJqvp3tboFdu2zVktkY9eCZ5RLuWVYldUipXKl1kAAAB1Eb0Swx3lwqmTAAA06je/+Y25Xr58uX/b4sWLZdy4cdK2bVtT1NXCuhbS69q2bZtce+210qNHD0lNTZW99tpLzj//fCkoKPDfZ/PmzXLxxRdLhw4dzHMdeOCB8vzzz9d6npUrV5rC2QMPPCBPP/209OrVyzzfkCFD5Lvvvqt1340bN8pFF10k++23n6Snp0unTp3k5JNPNs+hdCw///yzfP755/6YmSOPPLJW/Izedvnll0v79u3NmJV2futj67r99tuDFvVeeuklGTp0qGRkZEibNm1Mp/i0adN2OYaGMsonT54sBx98sHlP+uXFeeedVy8SR8fYqlUrs/2UU04xP+fl5ckNN9wgHo+nwTkGIk6L0vp3VFEpEsFGFru6WuytReZnq12d6BUtjKck++5HTjkAAEBQdJTHcvQKHeUAgD2k3Y+e6jLxVCWL7Yr89+eupLQW7cZ0Csxa7FVa4D3ssMNMfvmf//xn02392muvmcLs66+/Lqeeeqq5X0lJiSmyL1q0yBSuBw0aZArkWlBfu3atKfZqxIgWiH/55Re58sorTeSLFoS14KtF9muuuabWWF555RUpLi6WP/zhD+Y93nfffXLaaafJr7/+KsnJvgLW6aefbsZ4ySWXSN++fc1rTp8+XVavXm0K1P/617/kqquuMkXkv/71r+YxWqQPpEVyLTDfeuutpqO8uSZOnGgK6MOHDzdRNhqjMnv2bPn0009l9OjRTRpDIC3gX3jhheaLgbvvvls2bdokDz/8sHz11Vcyb948ad16Z0FPC+LHHnusDBs2zHyx8PHHH8uDDz5ovlz44x//2Oz3AoSDlZQkVtsc083t3bxF3M7CmWFmb9mu/1H3FcSdxhpnjPqlVk4rEw9jcsrbt43IGAEAAKIZhfIYZGVl+KJX6CgHAOwhb3W5zHv9BIkWIy+aKe7k9N1+/Pbt201xWTPKtbirRV/t3j7hBN971OJ1t27dTCe3bncKy4cffrjcfPPN/kL5/fffb3LN33jjDf829be//c18uaC0O1wL6dp9fe6555ptl112mRxxxBHmflpgz8ryLaCntNi9bNkyf9G+X79+plv8o48+MuPT4vqsWbNMAV0L5dnZ2SbKZMKECf7n0IK+PrfTlR2Mdsp/8skn4na7m/35adFfi+P6nqdMmWJe3+G876aMwVFVVWU+1/3331+++OILfyyLft76nv/5z3+aOXLovJ111llyyy23+D9P/ZLiP//5D4VyRH9OeeE2sXVBz97dIppPbuW2CfqFo5XtK5QLOeUAAABBRb51DM2XTUc5AADBHHPMMaabumvXriZeRTvGtQtcI0i2bNliuqI1q1w7u7WgrpfCwkLTxaxFbCcORLvLNUYlsEjucApQU6dOlY4dO8pvf/tb/23aGX711VebjnSNJgmkBWCnSB4YC6Md5UpjSbR7W2NLtGi+u7TIvjtFcvXWW2+J1+s13eiBRXK1O53+c+bMMfE0+mVEYHb52LFjZZ999pH333+/3mO0OB5IPyfnMwKilZXXxp9THin+Qnnd2BVHju+LO6JXAAAAgqOjPBY5p1IWl4rt9YoVBafKAwBik0adHHT6e5Kd5etejobx7In/+7//M5El2ln+7LPPmi5mp3Ncu6W1K1q7lZ2O5bq0qKuxLJpprjEojVm1apX06dOn3ue27777+m8PpJ3sgZyi+datW821jlMXHr3++uvNezjkkENM17XmomtBvqk0AmZ36fvW99O/f39pCc5noN3zdWmhfObMmbW2aTFdv+io+zk5nxEQrayaKBPTUR4hdsHWoAt51l3Qk0I5AABAcBTKY1Fmhog2dekp0CWlIhHKQQQAxD7tEnYnpZu4k2golO8pXYBSF+d0IkI04uOcc86RJUuWmE5ppYtDagd5ML179w7Z2Brq8nYiTdSf/vQn0239v//9z3Ska0Ffc721E/6ggw5q0utoZ3pdDXWDR9simbvbCQ9ET6E8cl/qaPRLkwrlxDcCAAAEFftHxAnIcrtEWhG/AgDAroquWmRev369PPbYY7L33nv741E0oiXYxckU18UjNaO8Md27dzdxLU4B3rF48WL/7btDX1sXB9Xsch1DZWWlWdByTyJQtCs7WJxL3a53fW19PwsXLmz0+Zo6Bucz0C8q6tJtu/sZAdHGlVdTKNec8mpPhDvKd0Y81c0oN/ejoxwAACAoCuUxyqqJX7GLKJQDANCQI4880nSZ/+tf/zKLY+q/n3rqKdmwYUO9++bn5/t/1tiV+fPny5tvvtlgB/jxxx8vGzduNN3fjurqann00UelVatWZlHP5igtLTWLWdYtXGvxvqKiwr9Nc9ebm2Guz6NxND/++KN/m34Gdd+fduHrmQW6oGfdLwACO9+bOgbt7m/fvr08+eSTtd7DBx98YBZC1e55IC5ot3ZKsojX9nd2h5PGMdpbtpufXQ0VymsyyoWOcgAAgKCIXolRVnam2OvpKAcAYFduvPFGOeOMM2TSpEkmw1zjWAYMGGAWvdQu802bNsnXX38ta9euNcVx5zFTpkwxj7vooovk4IMPNouB6sKgWvTVhT4vvfRSU3QfP368fP/999KjRw/zmK+++soU5p3u9KZaunSpHH300eY1dVxajH777bfN+M4++2z//XQsTzzxhNx5550mKkYL0UcddVSjz62Pv/nmm83ipLrYqBbl9Tk0C33u3Ln+++nz/fWvf5W///3vZhHN0047zWSnf/fdd9K5c2fTod+cMWj3vuauX3jhheaLA134VN/Pww8/bD6va6+9tlmfERCt9CwLXdDTXrfZl1PeoV1YX9/eVizi8eqpNL6ifTABGeX6xdfunJ0CAAAQzyiUx3hHOR0hAAA0Tou92lH9wAMPmOL4nDlzZOLEiaZwXlhYaIq8mv996623+h+jHeFffvml3Hbbbabr+vnnnzf300L2Xnvt5c8CnzFjhvz5z382txcVFZlFK5977jlTPG+url27mkLyJ598Ii+99JIkJSWZBS9fe+21WguL6jg1MuW+++6T4uJiU4DeVaG8Xbt25n1cd911ctNNN5kFP7XordExgYVypd3kert2xmvRPCMjQw444AD53e9+t1tj0M9Cn+Oee+4xxXr9AkAL9lpAb906eJYyEKs55aZQvnlL5GJX2uWI1cB6E9poY+jaBDvKRFplhHOIAAAAUY9CeaxyMgaJXgEAwBRjGypOa5TIL7/84v+3dmtrYXtX2rZta4rFemmIFs+fffbZRp9HO6cDY0sCBW7XYrZmqWvkiRbdNSom2AKrHTp0kPfee69Zn4EaNWqU/PTTT/W233777fW2aQe4XhrS0Bg02ibYez3zzDPNpTH6xYVego0v2BiBaGM5OeXaUR5mdoGzkGfw2BVzW1KSSGa6KZJrV7lFoRwAAKAWMspjlNMRQvQKAAAAED0Leno3+7q7I9NR3vhZGk5Ouc1ZqQAAAPVQKI/5xTzZyQUAAACiIXolmjvKze3OWanbi8MyLgAAgFhCoTxGOTu5QvQKAAAAEHG6mKdRUip2aXlYX9sudArlu+oorzmG2E6zDQAAQF0UymOV01FevKPB3FMAAAAA4WGlpe5cRyiMXeV6LOCPXtlFoVxqCuWaUQ4AAIAYLpR/9913cuWVV8p+++0nmZmZ0q1bN7Mw1NKlS3f5WF0cyrKsoJeNGzdKrPGvWl9ZJVJRGenhAAAAAAnPVdNVbm8OY/yKRjFWVYu4LLHa5DSpo5z4RgAAgPqSJIbce++98tVXX8kZZ5whBxxwgClwP/bYYzJo0CD55ptvZP/999/lc9xxxx3Ss2fPWttat95F50UUslJTRFKTRSqqxC7a4etgAQAAABDZnPLla8Sbv1Xc4Y5daZMjVlLjr0pGOQAAQJwUyq+77jp55ZVXJCUlxb/trLPOkgEDBsg999wjL7300i6fY8yYMTJ48GCJB7qja+dvFSneIVKzeBAAAACAxFnQ0+ss5Nlu180/Vk6WudZGGwAAAMRw9Mrw4cNrFclVnz59TBTLokWLmvw8xcXF4vF4JG5yyjl1EgAAAIg4K69t2KNXmpxPHriYZ8kOsePheAgAACBRO8obWrxm06ZNpljeFCNHjpSSkhJTcD/22GPlwQcfNMX2xlRUVJiLo6ioyFxXVVWZS7g4r+V/zVYZ5qp6a5F4wzgONDIniArMS3RiXiJLP3f9/0yv12suDmdBaOc2RB5zEv3zon9Pbnf9iAv++wZ/oTx/q9heWyyXFfLXtJ2O8lxfPnqjMjNEXC4R/W+LdpW3yQ75+AAAAGJFzBfKX375ZVm3bp3JHm9MRkaGjB8/3hTKs7Oz5fvvv5eHHnrIdKnPnTtXunbt2uBj7777bpk4cWK97dOmTTPPG27Tp0831/sU5kt3EVk+/ydZVhx7C5LGE2dOEF2Yl+jEvERGUlKSdOzY0XxZXFlZGfRsK0QX5iQ6lZeXyxdffCHV1dX1bistLY3ImBA9rLY5Im6XiP5+bCsS0X9HU0e5Fu6zM0W2FYu9vUQsCuUAAADxUShfvHixXHHFFXLooYfKBRdc0Oh9zzzzTHNxnHLKKaajfMSIEXLXXXfJk08+2eBjJ0yYYPLRAzvKtbA+evRoU3QPF+1S0gLTqFGjJDk5WbyffSv2uq+kV14H6XP8cWEbBxqeE0QH5iU6MS+RL+6tWbNGWrVqJWlpaf7t2h2rBdmsrCyxrNB3PmLXmJPonZfCwkLz96P7j4F/R3XPOkTistwu09ltbyoUb/4WcYe4UK6/l83qKK/JKbe1UE58IwAAQHwUyjdu3Chjx46VnJwcmTJlStDTX3fl8MMPl2HDhsnHH3/c6P1SU1PNpS4t9ESi2OO8rqdNjugJvtaOMopOERap3wU0jnmJTsxLZOjaHFp0dblc5uJwoj2c2xB5Dc2J/vu2226T22+/XaKZnsE3Y8YMWblyZcjGfuSRR5prfZ1IzEtD/x3jv21QVp6vUG5yyvv1DO2LlZaLlFfs7GZvyviyW4kGCdnbOWsFAAAgUEweEW/fvl3GjBkj27Ztkw8//FA6d+6828+lneFbtoRvsZ3QLObJqvUAgMQ1adIkU7x0Lhoz06VLF1Ow1Xi2RKLF6cDPQhsJunXrJqeeeqr88MMPEksWLlxoCuuBBXcgFoRzQU8ndkVyWomV0rQvapwFPTV6BQAAADHcUa6njp944omydOlS0wnev3//PXq+X3/9VfLy8iQWWZovqDu5xRTKAQDQ9Up69uxp9hW++eYbU0CfOXOmLFiwIGhMRjz77W9/K8cff7w5k2DRokXyxBNPyAcffGA+l4EDB4Z9PGVlZeYLjOYWynWNGO0e79GjR711YoBoZbXfuaBn+PLJmxa7UqtQTvQKAABA7HaU68HeWWedJV9//bVMnjzZZJMHs2HDBpNfrnm4jvz8/Hr3mzp1qlnU87jjYjPfW0+bNEpKxfZ4Ij0cAAAiSs82O++88+T3v/+9PPPMM3LDDTfI8uXL5Z133pFYsGNHy33xPWjQIPNZ6Bou99xzj7z00ktSUVFhCubheP269IuK5hbKG5OSkmIuiA76u3XzzTebszzT09NNtOHuLNysa1jomRBXXnmlxDJXTaFcM8pDzckndzVhIc/AjHKDjnIAAIDYLZRff/315mBXD4Q1LkUP+gIvgYtv7rvvvrVOtx4+fLhZzPO+++6Tp556Sv7whz/IySefbKJX/vKXv0hMykgXcbJLi0sjPRoAAKLKb37zG3OtxfJA+mX6uHHjpG3btqaAO3jw4FrFdI1208iSRx55xL+toKDA5IW3a9fOLJ7n+OMf/ygdO3b0//vLL7+UM844w8Sd6Pomup9x7bXXmo7qQBoLowur6ti081sX7jz33HP9RUfdN+nQoYPZftJJJ8natWv36LM46qijzPWKFStqxdV8/vnncvnll0v79u1lr7328t9fu8/188vMzDRj0HVhfv7553rP+9Zbb8n+++9vPke9fvPNN4O+vr5W3Xxy3U+7+OKLTXFVPys9G0A/z8rKSjM+/RzVyJEj/VEyTia5dpk7OeWOzZs3m+fTz03Hc+CBB8rzzz8fNJrmgQcekKefflp69eplXnvIkCHy3Xff7eanC/19fuihh8zv8MMPP2z+fvT3Ws/oaKo33njDNMPEU/SKbC0Su3Jn404oeAtrFvJs1/SOcqlptiGjHAAAIIajV5xszXfffddc6tLOqYZoJ/r7779vTtUtLS2VTp06ySWXXGIWltIDqlhkuSyRrAzTDWIXl4jVuqY7BACAJtKib4WnTMqrk6NiMc9Ud5opZLYEJ9u6TZudBSQt9h522GEmw/zPf/6zKQS/9tprcsopp8jrr79usrxbt25tir5ffPGFXH311eZxWvDTcekX9RoJst9++/kL405BXukZb7qfoQVfLap/++238uijj5pCt94WqLq6Wo499lizuLgWbjMyMsx23T95+eWXTXyKjvXTTz81heo94XxZoGMKpEVyjaC79dZb/R3lL774oulE17Hde++95v1oJ7qOc968ef4YFN2nOv30000M3t133y2FhYVy4YUX1iq4N2T9+vUydOhQ86XEpZdeKvvss48pnOsC7fp6I0aMMJ+9flmhXxpoA4RyruvSLyK0cP7LL7+YbmQtuuvnrQVcfY1rrrmm1v1feeUVKS4uNo0TOq/aSHHaaaeZSD4W5Gwe/R1/9dVX5f777zdncajzzz/f/A3ddNNNMmvWrF0+h8YlaUOMdqXr72LMy0wXSU8TKSs30ShW5/ZhiF5pTkc50SsAAAAxXyh3uoh2RbuQ9BLozjvvNJd4Y2VlmoV4WNATALA7KjzlctlXe1aEbUn/Pf4rSUtK3+3FvrXzW4tus2fPNvnW2i18wgkn+O+jBVPt9tbuYb3NKRZrEViLdFooV1r81qKtQwvieh/tRteftVDuFM210OvQwrJGTzj0tt69e5ti7+rVq81rO7RzXLumtcjsmD9/vimSa2e0djzrlxdXXHGF6dT98ccfm/xZaLFZPwuNrdMxa1e7crq0HdpV/8knn5gOYFVSUmIK1Bpfo6/v0MJ5v3795B//+Id/u35e2mygXyLk5OSYbUcccYSMHj1aunfv3uj49Oy/jRs3mnnSjv7AnHn98ka/rNA50EK5xnHU7R6vS8ekWex6hqHTmX/ZZZeZ8fztb3+Tiy66yHTGO3Quli1b5v8SRd+bnmn40Ucf1fp9wa7p34n+/gT+HWhHv/4O6+/9mjVrzJkVjdEvKrxerym0x0Oh3JwB0b6t2KvW+xb0DGmhfNtuZ5RLeaXYFZVipRJjBAAAEHOFcgTPKbdlE4VyAEDCO+aYY2r9WzuftXDqdDhrYVu7s7UYq93EenFo97SeZaZdzdptrkXa//u//5MlS5aYIqoWx/U+2n2tP2sRVgvEWtQN7CgPLJJrh7Z2Omv8m95Pu7EDC+VKO8/rrp+itNM50J/+9CfTBd1U+l704sjOzjZFfO2aDqTd606RXGmutHZgaze7Ftodeh/Nnf7ss8/868HomX7ale8UyZUWtbXDvLG8cy2IamSLLs4eWCR37M4ZBfq5aQSOjtuhneFa9NdtGjETWADXMw0DzzRw5lA7ytE8+nvdt29f8zsWSM8YUPp70lihXL+00Bz9Z599ttbfz67oF016cRQVFZlrXaMocJ2iUHJeJ+jraYf3qvVSvbFAvCEaj11eYdYqUtU5mWI19XXcLpGUZJHKKqkq3CZWXjNiW2JAo/OCiGFeohPzEn2Yk+jEvMTuvDR3ziiUx0FHucGpkwCA3Yw6efKw9yUrKztqold2lxa2tWCnneVadNPoFKdrXGkshxasb7nlFnMJRnOunUK50qK4Ftq1GKhnpmmhXGNSnNu0OKhZ2IFFP+2I1czzrVt9kQgOHVcgXdyybkzJqlWrzDxodEggLdY3h3b3ave4Ppd2Z2sHfOBn4aj7OtplHZhpXpdTDNVxqj59+tS7j4517ty5DY5NF1jXoqZGc7QUHY+Ope7vsBPV4ozXUfcLC6doXnfOsGv6pYlGGtblbNOYncZo5MpBBx0kZ599drNeV8/E0LNG6tJIICfGKFyCLVzas7BQ+moW/w8L5KeKwpC8blZxuQzXLw2S3TLj00+a9djD3SJ6FDF72ieypU14P69w2Z0FZRF6zEt0Yl6iD3MSnZiX2JsXPdO2OSiUx7psX6HcLqajHADQfNq9m+pON3En0VAo3xPawep0KGvmuEalnHPOOaYrXBfO1E5mpfEO2h0ejMakKF1gUovIWmzXznQtsB966KGmUK7xLVp41UK5dos7n5vGnGhHtXauayyJ5m5rBrp2qWtWtvP6Di1ch+oz16Jx3Q77YOp28Dpj1JzywEVKA4v78SCwiz5Q4EKtaBo9ayLYlzAav+Lc3hA9Q0HXBtAInubS+J7rrrvO/2/98kU71zX6p253e6hoh5IemOnffd1se/unZeJd+Z50Ts2QrscfH5LXt39cKt65qyS1U3uzeGpzeNZOEVm+Rob2309cBwXP/o9Vjc0LIod5iU7MS/RhTqIT8xK78+KcddhU8XG0k+DRK4roFQAAahdCteN05MiR8thjj5mIkL333tvcpjtRTSkia1e5Fsq1YD5w4ECTca3d4xo18uGHH5qu6cCO1p9++kmWLl0qzz//vFnMcHc6TzTbW4vVK1asMPnhDi32h0OvXr3Mdfv27Rv9jJwMcqcDPdCuxqpfNmghc8GCBY3erzkRLDoezXDXzy7wywfNZw8cL1qeftkSGIHi0LUCnNuD0cVsNRrnd7/7nQwZMqTZr6vF+WAFev37DvcBbLDX9HbKk0r9IX+r+YKppRYpDlS9rVj0qy1XXptmv2c7J8s81l1SJklxesAfid8F7BrzEp2Yl+jDnEQn5iX25qW58xXbrWPwR6+waj0AALXpApDaZf6vf/3LFO20+KvbnnrqKRMXESwSpG6hfOXKlfK///3PH8WiRVjtIn/ooYdMB0NgPrnTpRzYlaw/P/zww00e85gxY8y1jjGQvodw0E57LWLrop3B8vycz0hjNfTLA/1SIDBSRr8U0AVOG6OfoXb8v/vuuzJnzpx6tzufn3bjK81M3xXtptXFQXWuAguxjz76qDmbQBf1RGjo70Kwvydnm56dEcwLL7xgvlTRPH79O3MuStcP0J+be6psNDGLa2ptPCBHvKXZBb6oIFczFvKsu6CnvZ1jCAAAAAcd5fHSUU70CgAA9dx4440mq3vSpElmAU7NMddIlgEDBpiFLLXLfNOmTfL111/L2rVrZf78+f7HOkVwLeZp4dgxYsQI+eCDD0w3a2AnrEataEe2Rrto3IoWnDVWojm511p81qzm//znPyay4rDDDpNPPvnE5KuHg475iSeeMF2+gwYNMmPRDnDNXn///ffNeLRDX2nH/tixY83nedFFF5nIGS1Max56SUnjxTf9PDVLWgvYmqeuWeJaWJ08ebJZJFVz1fWz0C8fdBFSLcbr563Z6fqFR136HPrlgkbcfP/99yYuZ8qUKfLVV1+ZLxn0bACEhs6TRqjoaa2BkSdOnIreHoz+TumXMfo7FayIrpc333zTfKkSi6zkJLHa5Ii9ZbvYm7fsXFeoBdkFvi+RrHatd79QTrMNAACAHx3lcZJRLkU7yNUEAKCO0047zRSvdQFOzRDv37+/6WLWAq8Wz6+44gp58sknTZezLsJZd1FKpyirxeC6BXTtVg+MftDT+rRLWguDzkKDmhWuBb/m0CK5dtl+9NFHctNNN5liohapw0Vz3bU4r4ua3n///SaT/dVXXzXv68ILL/Tf77jjjjOFbf1cNS/6jTfekOeee86fE98YfW4tpI4bN05efvllE8Ghn5N2/DsLMWpGus6NLrB68cUXy29/+9sGu9U13mPGjBly7rnnmi53XSBSC/c6Hh0/QkfnUH8Hnn76af82jWLRz37YsGEmN9wpjDtROEq/hNFCeN2Lc4aA/qyPj2VWni8+yZu/JSTP7y2sKZTvVke578sjOsoBAAB2oqM8xvm7UzwekbIKkQzfwkkAACQK7SLWSzBaAK/bja1d5FpMbQrtNq9LO2Ab+nJaO6ODZZLXvb8W6fUSjC6CeM8998jjjz9eK2+7KV+IOwuP7slnprRgrZemfBGhl0CnnnpqvfsFG1O3bt12OQ+///3vzaUuLYrXpV9qPPvss7v9+dBwsHu0mK1nbeiXJfqlhi6Iq/Oq0Sn6pY9Dc/s///xz/+esZ2DoJRhdFyBWO8kDWe3biixZYTrKW5pdWSWyrdj3Ormtd/+s1O2+5wAAAACF8pinp3VKeqopkuupkxaFcgAAAISRng1wyy23yIsvvmiihg444AB57733TExRIjOFci1Gh6CjXCNdjLQUkczgC6Y2JXpFikrMlxehWGwUAAAg1lAojwPaEWJroVxzyjvmRno4AAAASCB6FoTG9OilIcHOAoj3zn4rzxeJYuc3fZ2C5i7kqbEru1XkrukoF49XZEeZSCtf5BEAAEAiI6M8Dlj+nHIyBgEAAIBo4KrJKNdFN22NSWxBtj+fvPmxK+ZxSW5/cZyccgAAAB8K5fGgJqfcLtoR6ZEAAAAAULpgZkqyiNcrdmFNVEoL0eK7sto1fyFPBznlAAAAtVEojxFrin+Vl5f8n/wkXzW8k6vRKwAAAAAiznJZAfErW0IUvbJ7HeWBOeW6zhEAAAAolMeMwrJN8vavL8hymV/vNsvfUc5OLgAgcfJ/gXDj7wfNFbpCua+j3JW75x3lQvQKAACAQaE8RuSmdzTXJbK93kGaP6OcjnIAQAOSknzrd1dXV0d6KEDM8nq9tf6egF2xnJzyzS1XKNe8c3urL8rFarf7HeXidJRTKAcAADAolMdYobzaqpTS6jo7s1nOaZMUygEAwbndbnMpKiqK9FCAmFVaWur/WwKawtXeVyj3tmShfEuRiNcWSU4ScbrC9yh6hYxyAAAARTtMjEhLSpes5BwprtouBWUbpXWGb6c7sKOcQjkAoCGWZUn79u1lw4YNkpqaKpmZmWabdshWVlZKeXm5uFx8fx4NmJPoo2fzlZSUyPbt26Vbt27mbwdoVkd5vi9TvCXYhc5Cnq1NDvpuj00XG6WjHAAAwI9CeYx1lZtCefkm6S396+cLlpWLXVUtlnaXAABQR05OjpSVlUlBQYHk5+f7C4C6LT09neJflGBOote2bdtk//33j/QwEEOsmo5yjUi0yyrESk+NioU8A48hKJQDAAD4UFGNsUL5iqIlpqO8Ft3hTnKLVHt8OeVtcyI1RABAFNOia6dOnUxneVVVldmm11988YWMGDFCkpOTIz1EMCdRbenSpXx5gWax0lJFsjJ9hfL8LWJ169SChfLdX8gzMHpFSkpN7rlFpBAAAEhwFMpjSG5aB3OtHeWBzAGb7oBvLTLxKxaFcgBAIwIzlvVaF/hMS0ujKBslmJPo5Hy5BOxOV7mthXLNKW+JQrkTvbKHHeWSmSHidol4vCIa4dgme4/HBgAAEMsIvozBBT3rdZTrjnKWk1POqZMAAABAtHDl+Tq/vfkts6CnXeBklO9hR7nmmxO/AgAA4EehPIbkptUUysuDFMqdnVyNXgEAAAAQVTnlGr2yp2yv3XId5bVyyov3+LkAAABiHYXyGJKbXhO9UlY7ekVZ2XSUAwAAANHGyqsplG/2ZYvvES1o67pEbpdYrfc8KsXJKecYAgAAgEJ5THaUbynPF4+3Omj0ilnMEwAAAEDUdZRrR/ie8DoLebbNEUvzxfd0bESvAAAA+FEojyE5qW3FZbvEFq8pltfi7OTqQjwAAAAAooIWtcXlEqmq9nWER0E+uX9sOVm+56WjHAAAgEJ5LHFZLsmUHPNzfp0FPf3RK3SUAwAAAFHDcrv9eeJ7uqBnS+aTB0av7GkBHwAAIB5QKI8xTqG8oKFCOd0gAAAAQJTmlO9hodyJXmmhQrk4GeVErwAAAFAojzUNdpRn1XSDFJfucfYhAAAAgBDklO9xodzpKG+h6BUyygEAAPwolMeYTMkO2lEuWRm+a69XpLQsAiMDAAAAEIyV5yts2/m+jvDdYdu22IVbQxO9UlEpdnlFizwnAABArKJQHmNa+TvKN9TLPpTMdPMz8SsAAABA9HA5HeV7klFeUipSUSVi1SwQ2gKstFSR1GTf2DiGAAAACY5CeaxmlJdubPjUSRb0BAAAAKIvo3zrdrErq/Yon1xaZ4uVlNRyY8vJ8j0/8SsAACDBUSiPk4zywAU9pYhCOQAAABA1WmWIpKeK2DtzxpvLeZyrhfLJ6zbbCIVyAACQ4CiUx2ihvLS6RHZUFde+MctXKLcplAMAAABRw7KsnV3luxm/4q3pKLfatUw+uV9NTjnRKwAAINFRKI8xyZIirZKDL+jpj15hJxcAAACIKtYe5pQ7HeUttZBnvWMIOsoBAECCo1Aeg3LTOgaNX7GcjvJidnIBAACAaOKq6Sj3bt7NQnmhUyhv4egVJ6OcZhsAAJDgKJTHoNz0DkEX9HQyyoleAQAAAKK1o7xmUc7dXMyzxTvKneiV7XViHQEAABIMhfIYlJveeEe5FFMoBwAAAKKJlefrBLc3bxHbtpv1WLu0XEQvIcgo31kop6McAAAkNgrlMSg3raajvE6hXPwZ5RTKAQAAgGhiIlMsESkrF9lR1qzH2oU1XehZmWKlpoQkekWKSsT2Nq+ADwAAEE8olMeg3PRO5jq/bEPQ6BWpqBS7ojISQwMAAAAQhJWSLNI6299VvnsLebZsPrnhnJXq8YqUNq+ADwAAEE8olMdTR7l2l+gOuFnQk65yAAAAIJq4anLKvfm7Vyh3tXA+ubKS3CKtMnyvQ045AABIYBTKYzijvLA8Xzzeav92y7J25pQTvwIAAIAwqKiokJtvvlk6d+4s6enpMmzYMJk+ffouH/fGG2/IWWedJXvvvbdkZGRIv3795Prrr5dt23xF4Xhk5bXdzY7y0Czk6R8XOeUAAAAUymNR69R2kmQlidf2yNaKgto31sSv2EXs5AIAACD0xo8fLw899JCce+658vDDD4vb7Zbjjz9eZs6c2ejjLr30Ulm0aJGcd9558sgjj8hxxx0njz32mBx66KFSVlYW34XyZnaUe0MZvUKhHAAAwEjyXSGWuCyXtEvvIJtK10l+6UZ/h7mysluJLsFD9AoAAABC7dtvv5VXX31V7r//frnhhhvMtvPPP1/2339/uemmm2TWrFkNPnbKlCly5JFH1tp28MEHywUXXCAvv/yy/P73v5d4Y7XfzY7ywhB3lGe38i/oCQAAkKjoKI9RTnG8bk65E71iE70CAACAENNit3aQa3e4Iy0tTS6++GL5+uuvZc2aNQ0+tm6RXJ166qnmWjvN45Erz9cRbhduE1sXz2wCu6LSH6totQtVR3mW77XIKAcAAAmMjvIYlVdTKM+vWyiviV4ROsoBAAAQYvPmzZO+fftKdnZ2re1Dhw411z/88IN07dq1yc+3caNv3zY3N3eXueh6cRQVFZnrqqoqcwkH53Wa83p2ZrpIcpJIVbVUbS5sUoe4vakmajEjTaqT3fqC0tK8Oi4R8WwrDsnzh9PuzAtCj3mJTsxL9GFOohPzErvz0tw5o1Ae4x3l+WUbat9Qc9okGeUAAAAItQ0bNkinTp3qbXe2rV+/vlnPd++995oO9XHjxjV6v7vvvlsmTpxYb/u0adPMwqDh1JSFSwMNT3FLVlW1fPfBNCloVxN50oj2BcVykIhsc4vMnjpVQiG3sEQO1i8c1q6Xr0P0GuHW3HlBeDAv0Yl5iT7MSXRiXmJvXkpLS5v1XBTKY7yjvMHoFTrKAQAAEGK66GZqamq97Rq/4tzeVK+88or85z//Mdnmffr0afS+EyZMkOuuu65WR7l2ro8ePbped3uoaIeSHpiNGjVKkpOTm/w475b3xP5pmQzu0Vtcvxm06/t/Pkfsn9dLm17dzSKpoWCv3yzeBS9LtvgWYo1luzsvCC3mJToxL9GHOYlOzEvszotz1mFTUSiPUbkZDRTKa6JXyCgHAABAqKWnp9eKQHGUl5f7b2+KL7/80uSaH3vssXLXXXft8v5anA9WoNeDpHAfwDb3Nas65Irnp2XiKtzWpMdVbSkSj8k3bxuy92a3ayNmFktKJclyiZXkllgXid8F7BrzEp2Yl+jDnEQn5iX25qW588VinjEqL71T8Izymo5yKdnR5AWCAAAAgN2hESsav1KXs61z5867fI758+fLSSedJPvvv79ZHDQpKb57eVzt25pre/OWJt1fF/40j8sNzUKeRka6iLvm0JAzUwEAQIKKqUL5d999J1deeaXst99+kpmZKd26dZMzzzxTli5d2qTHb9u2TS699FLJy8szjx85cqTMnTtXYlFuegdzvaOqWEqrAvLIW2WIWJaIrTc2L4cHAAAAaI6BAweaffG6p7XOnj3bf3tjli9fLscdd5y0b99epk6dKq1a7TqzO9ZZeb5CuTe/aYVyb8FW3+OasPDnbo/JZe1c62h7ccheBwAAIJrFVKFcF/d5/fXX5eijj5aHH37YFL2/+OILGTRokCxYsKDRx3q9Xhk7dqzJPtRi+3333SebN2+WI488UpYtWyaxJj0pU1ol+/IXC8o2+bdbLpevWM6CngAAAAgxXXTT4/HI008/7d+mUSzPPfecDBs2zOSGq9WrV8vixYtrPXbjxo0mU9zlcslHH31kmlkSgdW+pjO8aIfY5fVjawLZ1dUi23xfQlih7CjX589xCuUcQwAAgMQUU+c16oI9WuhOSUnxbzvrrLNkwIABcs8998hLL73U4GP1NM5Zs2bJ5MmTzQ690m70vn37ym233WaeN9bkpneUkqoiE7/SLbtXrZxyXcyTnHIAAACEkhbDzzjjDLO4pjah9O7dW55//nlZuXKlWZjTcf7558vnn38utq2nPfpoJ/mvv/5qFu+cOXOmuTg6dOhgFmaKR1Z6mq+xpaRU7PytYnX1rT0UjL1lu+9M0dRkfzNMyMaVk2VeikI5AABIVDFVKB8+fHi9bX369DFRLIsWLWr0sVoo1x3u0047zb9Nu1a0WK4Fdu18CbYgUDTLS+8oK4uWSn5Z7VxIK7uV2Os2UygHAABAyL3wwgtyyy23yIsvvihbt26VAw44QN577z0ZMWLELrPJlZ7pWdcRRxwRt4VyZbVvK7YWyjWnvLFCeYEvn9xq10YsjVcM5Zic6BXOSgUAAAkqpgrlwWhXyqZNm0yxvDHz5s0zES16amegoUOHmlNFNVtRO9OD0SK6XhxOBmNVVZW5hIvzWs5129T25npTybpa47Az0821Z3uR2GEcXyKqOyeIDsxLdGJeohPzEn2Yk9idl0Sds7S0NLn//vvNpSEzZsyoty2wuzzRuPLaiufXtSan3N3I/eww5JPXj14hoxwAACSmmC+Uv/zyy7Ju3Tq54447Gr3fhg0bgna1dOrUyVyvX7++wUL53XffLRMnTqy3fdq0aZKREdpTIIOZPn26uS6QbSKWyI/L50rr5VP9t/fenC8axLLqp4WyqLww7ONLRM6cILowL9GJeYlOzEv0YU5ib15KS1lIHU3vKFf2Lhb09HeUhzifPLCjXOgoBwAACSqmC+W6INAVV1whhx56qFxwwQWN3resrCxotIp2wDi3N0QzFzUfPbCjXBcm0sWHsrN9C2qGg3Yp6cGZnoaanJwsOeuT5Pv5H0tqW7ccf8jx/vt5Z/0g9urPpFvbXOl5/M7tCP2cIDowL9GJeYlOzEv0YU5id16csw6BXbHyfIVvE73SiJ3RK6HvKBcW8wQAAAkuZgvlGzdulLFjx0pOTo7JH3e7GztpUSQ9Pb1WfIqjvLzcf3tDtMAerMiuB0mROIB1Xrdj1l7m3wXlm2qNw9M6W/TEX6ukjAPsMInU7wIax7xEJ+YlOjEv0Yc5ib15Yb7Q/I7yrSaCpqH8cbswEtErFMoBAEBiqh3YHSO2b98uY8aMkW3btsmHH34onTt33uVjNGJF41fqcrY15TmiTW66b+GfwvLN4rE9/u1WdqbvB06bBAAAAKKO6RDXtZMqq0QaKEzbHq/YW7abn13hjF6pqBS7vH6DEQAAQLyLuUK5doCfeOKJZvHN9957T/r379+kxw0cOFDmzp0rXq+31vbZs2ebnPG+fftKrGmTlituK0m8tke2lhfsvMFZsb54R0IvkgQAAABEI8vtFqtdjvlZF/QMxt5WJOLxiiS5RXKyQj+mtFSR1BTfa9NwAwAAElBMFco9Ho+cddZZ8vXXX8vkyZNNNnkw2iWu+eWaJekYN26cbNq0Sd544w3/toKCAvM8WngPFq0S7dyWW9qltzc/F5Rt9G+3smo6yquqRcorIzU8AAAAAA2w8to2mlMemE9uuazwjIn4FQAAkMBiKqP8+uuvl3feeccUtrds2SIvvfRSrdvPO+88/+Kbzz//vKxYsUJ69OjhL5QfcsghcuGFF8rChQslNzdXHn/8cVN8nzhxosQqjV/ZXLpe8ss2yj5yoNlmpSSLpKWYIrldXCJWeux9CQAAAADEfU75wuUNF8rDmE/uH1NOK994KJQDAIAEFFOF8h9++MFcv/vuu+ZSl1MoD0YX+5w6darceOON8sgjj0hZWZkMGTJEJk2aJP369ZNYlVeTU15QuqFexqBdvkXsoh0i7dtFaHQAAAAAGu0oz/cVxBvrKA+bmogXOsoBAEAiiqnolRkzZpjM7YYuDi1+67+dbnJHmzZt5JlnnjGRKzt27DDPN3jwYIllzoKe2lFeixO/Qr4gAAAAEHVc7Z1CeUPRK05HeegX8qy7oCcZ5QAAIBHFVKEcjXSU1ymUW9mZ/gU9AQAAAEQXK89XALe3bBe7urrhjvJwFsr9GeXFYXtNAACAaEGhPMblpncK2lHuLOhpolcAAAAARBfdX9d1hfTs2JqiuMP22mIXhj96hY5yAACQyCiUx21Hec1OLh3lAAAAQNSxLGtnTnndBT21UF1VLeKyxGqbHb4xkVEOAAASGIXyGJeb3sFcl1QVSVn1jnqFcjLKAQAAgGhf0LN2odzfTd4mRyy3O+zRK3oMoV3tAAAAiYRCeYzLSG4lmcm+zo+Csk07byB6BQAAAIiNBT3rdJR7/Qt5hi92xahZ50g8XpEdpeF9bQAAgAijUB5H8Sv5ZRv821jMEwAAAIhuVk2h3JvvK4xHciFP83ravd4qwzcGzkwFAAAJhkJ5HMh1cspLN9ZbzFN2lIld7YnU0AAAAAA0O3pla9gX8qwbv0JOOQAASDQUyuOoUJ4fuKBnRrqIu2Z66SoHAAAAoo4/WkWbW3aUBekop1AOAAAQLhTK40BeeidzXRBQKLdcFjnlAAAAQBSzUlNEWmfVyim3bTti0SvmNbNrxrO9OOyvDQAAEEkUyuMqozygozwgfsUuphsEAAAAiOYFPb1O/Ip2lpdXmB+ttjkR6ygXMsoBAECCoVAeV9ErOxfzVFZ2zWmTdJQDAAAA0Z1T7nSU13STa6e5lZIc/gERvQIAABIUhfI4kJfhK5QXlm0Wj+2pv6AnGeUAAABATCzo6Szk6YrAQp61m20olAMAgMRCoTwOtEnNFZflFo9dLdvKC3fekO1klLOTCwAAAEQjq33wjvJILORpXjfHySjnGAIAACQWCuVxwO1KknZpefXiVyx/oZyOcgAAACCqC+UF28T2esVbsDViC3nWyigvKRW7eufZqgAAAPGOQnmc5ZQXBCzo6T9tkugVAAAAICpZrbNFktwiHo/YW4vELtwW0UK5ZKZrJ47vZ85MBQAACYRCeZzIS+9krvMDC+U1GeVErwAAAADRyXJZ/qK4xq/4o1cilVFuWSLklAMAgAREoTwBOsp1MU/btiM1NAAAAABNiV9Zs9FEnkQyo9y8NjnlAAAgAVEojxN5GfU7yiUrw3ft8YqUlkdoZAAAAACaUij3LPrVt6FVhlhpqZEbT01OOYVyAACQSCiUx4k8p6O8NKCjPClJJCPN/ExOOQAAABCdXHk1HeWr10e8m9y8vhO9sr04ouMAAAAIJwrlcRa9UqujPHAnl3xBAAAAICpZNYVyqUlLjNhCnnU7yjmGAAAACYRCeZx1lJdUbZeyal+uYeCCnlJERzkAAAAQzdErDleEFvKsWygXolcAAEACoVAeJzKSW0lGUqt6C3pKtq9QTjcIAAAAQqGiokJuvvlm6dy5s6Snp8uwYcNk+vTpTXrsunXr5Mwzz5TWrVtLdna2nHzyyfLrrzU53QnE0rjEVjXrC0VB9IpwVioAAEhAFMrjMac8oFDudJSTUQ4AAIBQGD9+vDz00ENy7rnnysMPPyxut1uOP/54mTlzZqOPKykpkZEjR8rnn38uf/nLX2TixIkyb948OeKII6SwsFASNn4lKqJXssw1GeUAACCRJEV6AGg5uRkdZVXxL7VyyndmlFMoBwAAQMv69ttv5dVXX5X7779fbrjhBrPt/PPPl/33319uuukmmTVrVoOPffzxx2XZsmXmOYYMGWK2jRkzxjz2wQcflH/84x+SSFx5bcSzYm2UFMprolcqqsQurxArLTWi4wEAAAgHOsrjSF56p/od5TXRK8JpkwAAAGhhU6ZMMR3kl156qX9bWlqaXHzxxfL111/LmjVrGn2sFsidIrnaZ5995Oijj5bXXntNEjanXIvSGsUSybGkpoikpZifbXLKAQBAgqCjPI7k1kSv5JcGZJQTvQIAAIAQ0aiUvn37mnzxQEOHDjXXP/zwg3Tt2rXe47xer/z4449y0UUX1btNHztt2jQpLi6WrCxfBEiwXHS9OIqKisx1VVWVuYSD8zot9Xp2Xk0Xefu2Ul1dLRGX1UqkfItUb9kmVtva8xvNWnpe0DKYl+jEvEQf5iQ6MS+xOy/NnTMK5fGeUU70CgAAAEJkw4YN0qmT76zGQM629evXB33cli1bTKF7V4/t169f0MfffffdJtO8Li2wZ2TsXBQzHJq6cOku2bZ069VetrZOkeKpUyXSBleVSzv9suPLr2TD0gUSa1psXtCimJfoxLxEH+YkOjEvsTcvpaWlzXouCuXx2FEeLHqlvELsyiqxUpIjNTwAAADEmbKyMklNrZ9frfErzu0NPU7tzmPVhAkT5LrrrqvVUa6d66NHj67X3R4q2qGkB2ajRo2S5OT428f2Fn8o9txFcmDP3nLQkTvjcaJdvM9LrGJeohPzEn2Yk+jEvMTuvDhnHTYVhfI47CgvLNsoXtsrLsvlyzhMShKprjbxK1a71pEeJgAAAOJEenp6rQgUR3l5uf/2hh6nduexToE9WJFdD5LCfQAbidcMh6rW2eLRRa2KS2Py/cXrvMQ65iU6MS/RhzmJTsxL7M1Lc+eLxTzjSNu0PHGJS6rtatlWUWi2WZYVsKAn8SsAAABoORqTovErdTnbOnfuHPRxbdu2NYXu3XkswsPKcSIcWcwTAAAkBgrlccTtSpK26e3Nz/mlAQcdNYVyFvQEAABASxo4cKAsXbq03mmts2fP9t8ejMvlkgEDBsicOXPq3aaP3XvvvRtcyBPhYeX4Pn97O4VyAACQGCiUx2lOea0FPXXFerpBAAAA0MLGjRsnHo9Hnn76af82jVN57rnnZNiwYSY3XK1evVoWL15c77HfffddrWL5kiVL5NNPP5UzzjgjjO8CwVjZHEMAAIDEQkZ5HOaUL25gQU86ygEAAOJTZWWlWdAoM7Mmci9MtBiuRW1dXHPz5s3Su3dvef7552XlypXyn//8x3+/888/Xz7//HOxbdu/7fLLL5d///vfMnbsWLnhhhtMhuRDDz0kHTp0kOuvvz6s7wMNR6/I9hKxvbZYLivSQwIAAAgpOsoToaPcn1FONwgAAEAse/XVV+Xaa6+ttW3ixInSqlUrad26tZx66qlSUhLefb4XXnhB/vSnP8mLL74oV199tSnYv/feezJixIhGH6fRKjNmzDD3u/POO+WWW26RAw880BTU8/LywjZ+NECPIbQ27vWK7CiN9GgAAABCjo7yOOwolzod5ZJV01HOYp4AAAAx7cEHH5SDDjrI/+9Zs2aZQrl2Ze+7777y6KOPyl133SV333132MaUlpYm999/v7k0RAviwey1114yefLkEI4Ou8tyu0VaZYoU7zA55VbNMQUAAEC8olCeEB3lNfmCRK8AAADEtOXLl8sFF1zg//crr7wiHTt2lDfffFOSkpLE6/XK66+/HtZCOeKXnpmqxxC+nPIOkR4OAABASBG9kgAd5U73BwvxAAAAxDZdKFM7uB3Tpk2TMWPGmCK56t+/v6xduzaCI0Q8sXKyzLW9vTjSQwEAAAg5CuVxJi+jk7kurtwm5dVltTPKS0rF1oxBAAAAxKSePXvKxx9/bH6eM2eO/PLLL3Lcccf5b9+0aZPJKwdagv/M1O003AAAgPhHoTzOZCZnSUZSq9rxK62chXhskR2+4jkAAABizx/+8Ad57bXX5IADDpDRo0ebjO8TTjjBf/tXX30l++23X0THiPhh5dR86UKhHAAAJAAK5QmQU265XSKZGeZnFvQEAACIXVdddZU89dRT0qtXLzn55JNN9Ep6erq5bcuWLbJx40Y599xzIz1MxIuaQjkRjgAAIBGwmGec5pSvLv6ldk55diuxNXpFd3K7tI/o+AAAALD7LrnkEnOpq23btiaOBWj5jHIK5QAAIP5RKI/jjvK6C3raupNbTEc5AABAPLFtWz777DOz0Ofhhx8uWVm+4ibQYhnldJQDAIAEQPRKHMrLqB29UmtBT6JXAAAAYtZf//pXGTlyZK0iuWaVjxo1SsaOHSsDBgyQ5cuXR3SMiMOMcj0ztbo60sMBAAAIKQrlcd1RvmHnxixfoZxuEAAAgNj1+uuvy9ChQ/3/njJlinzyySdy5513ynvvvScej0duv/32iI4RcSQzXcTt9v1Mww0AAIhzRK/EaUa5KiitnVGuiF4BAACIXevWrZPevXv7//3GG29I//79ZcKECebff/zjH+WJJ56I4AgRTyzLMl3l9pbtJqfcapsT6SEBAACEDB3lcdxRXlC+Sby2t1b0ik0nCAAAQMxKSkoyWeRO7Ip2kx933HH+2zt06CAFBQURHCHiDjnlAAAgQVAoj0Nt0/LEJS6p9lbJ9oottTPKi9nBBQAAiFX777+/vPTSS7J161Z57rnnpLCw0GSTO1atWiW5ubkRHSPiM6fc3l4c6aEAAADEbqF89erVMnPmzFrb5s+fL+eff76cddZZ8tZbb4Xy5RNWkitZ2qTlmZ/znQU9s5xOEDrKAQAAYtWtt94qP/zwgymGX3LJJXLYYYfVWtzz/ffflyFDhkR0jIgv/gjH7TTcAACA+BbSjPKrr75aSkpK5OOPPzb/3rRpk9mRr6yslKysLLP40OTJk+W0004L5TASNqe8sHyTFJRtlL5t9t/ZUV5ZJXZ5hVhpqZEeIgAAAJpp1KhRMnfuXJk+fbq0bt3aNJ84tMt8xIgRcvLJJ0d0jIjXjnIK5QAAIL6FtFD+7bffyjXXXOP/9wsvvCBlZWWyYMEC6dmzp8lTfOCBByiUh0BuRkeRrfP9HeVWaopIarJIRZVZ0JNCOQAAQGzSxTv1UlebNm3kn//8Z0TGhPgvlAsZ5QAAIM6FNHply5Yt0r59e/+/33vvPTniiCOkV69e4nK5TIF88eLFzXpO7VC/7bbbTJG9bdu2ZiX2SZMmNemxej+zcnuQy8aNNRElcdRRrgrKNvi3WVk1XeXErwAAAMS0FStWyOOPPy4333yzuejPug1ocTlZ5oqMcgAAEO9C2lGel5dnFhRS27Ztk2+++Ubuuece/+3V1dXm0hwFBQVyxx13SLdu3eTAAw+UGTNmNHtc+njtaA+kp67Gk9yaQnl+acAXAJovWLDNdJQDAAAgNl1//fXy8MMPi9frrbVdG1H+9Kc/mTM2gRbPKKejHAAAxLmQFsqPOeYYeeSRRyQ7O9sUtHVn/pRTTvHfvnDhQunatWuznrNTp06yYcMG6dixo8yZM2e3FisaM2aMDB48WOKZ01GeH9hRnp0pNju5AAAAMevBBx808Srjxo0zBfN9993XbF+0aJHZrpcuXbrItddeG+mhIt6iVzTCkbWOAABAHAtpoVy7x5cuXSo33HCDpKSkmO4Wp5O7oqJCXnvtNTnnnHOa9ZypqammSL6niouLJSMjQ9xut8Sj3PRO5loX83RYWU43CB3lAAAAsejf//63nHTSSWY/OtCwYcPk1VdflfLycnnqqacolKPFmLWO0lJEyivNgp4UygEAQLwKaaG8Q4cO8tVXX8n27dslPT3dFMsd2l3+ySefNLujvCWMHDnSZJ3reI499ljTmdOnT58G769Ffb04ioqKzHVVVZW5hIvzWk15zdbJ7cx1UeU2KSkvllR3mngz08w27/bisI47njVnThA+zEt0Yl6iE/MSfZiT2J2XcMzZypUr5Zprrmnwdt23/fDDD0M+DiQWKydL7PJCUyiXDr7jDAAAgHgT0kK5Iycnp942LZxrxng4aQf5+PHjTaFc42C+//57eeihh2T48OEyd+7cBov2d999t0ycOLHe9mnTppnnDLfp06fv8j622JIkKVJtVcobH70mOZIrnTdulwEax/LrSvl+6tSwjDVRNGVOEH7MS3RiXqIT8xJ9mJPYm5fS0tKQv3779u1l/vz5Dd6ut+k6QUBL55TbmwpFiHAEAABxLKSFcu0Y1wL0jTfe6N/27LPPyu233246tDV2ReNYwhV/cuaZZ5qLQ/PStetmxIgRctddd8mTTz4Z9HETJkyQ6667rlZHuRbVR48ebQru4aJdSnpwNmrUKElOTt7l/T/58kVZW7JC9hvaTw7IHSb2kpXiXfKm5KZlyPHHHx+WMce75s4JwoN5iU7MS3RiXqIPcxK78+KcdRhKZ5xxhlnIs0ePHnLVVVdJZmam2b5jxw557LHH5JlnnjELegItqian3N5eHOmRAAAAxGahXAvi3bt39//7p59+kj/84Q9ywAEHSO/evc1Cn5o3fvPNN0ukHH744SbT8eOPP240F10vdelBUiQOYJv6unkZnUyhfGtlgbm/t02OVOoNxaUceLewSP0uoHHMS3RiXqIT8xJ9mJPYm5dwzNff//53+eGHH+Qvf/mL3HrrrdK5c2ezff369VJdXW3OnLzjjjtCPg4kXke5MtErAAAAcSqkhfJFixbJ6aef7v/3iy++aDqwv/zySxNZctlll8kLL7wQ0UK50u7wJUuWSLzJq1nQM79sg7m2sn0dR7KjVGyPR6w4XcgUAAAgXuk+tJ61+fbbb8sHH3wgq1atMtuPO+44c8bgiSeeKJZlRXqYiMOMckWhHAAAxLOQFsr1FNDAaBJdWEh34p1c7yFDhshLL70kkfbrr7/GZZZjXnpHc11QttG3ITNDxGWJeG3TVS6tfTu8AAAAiC0nn3yyudQ1a9YsmTFjhuk4B1qK5USvkFEOAADimCvUndrfffed+fmXX36RBQsWmFxvx5YtW4JGmrSEDRs2yOLFi02epCM/P7/e/aZOnWoW9dQCfrzJrSmU59cUyi0tkrfydZXbxTsiOjYAAAC0vM8++0xuueWWSA8D8VooJ6McAADEsZB2lJ977rkmI3HdunXy888/S5s2bWp1vmiBum/fvs1+Xl2oaNu2bSaLUb377ruydu1a87MuapSTk2MW4Hz++edlxYoVZrEjNXz4cDnooINk8ODB5j660KguLqoF/XjsusnLqNNRXhO/op0gdIMAAAAAaE5GuRTtENtr+xpwAAAA4kxIC+V//etfpbKy0nRtd+vWTSZNmiStW7f2d5PraaHXXHNNs5/3gQce8OcxqjfeeMNc1HnnnWeK4MGcddZZ8v7778u0adOktLRUOnXqJJdcconcdttt0qFDB4nXjPKCsk3itb3isly+Qrk5bZKOcgAAAABNoGsdaW3c6zXrHUlWzdpHAAAAcSSkhfKkpCS56667zKWutm3bysaNOzudm2PlypW7vI8W5fUS6M477zSXRNE2LU8ssaTKWylFFVuldVo7sbJqukGIXgEAAADQBJbb7YtwLN5hFvS0KJQDAIA4FNKM8kAlJSWyaNEic9GfEXpJrmRTLA/MKTfdICzEAwAAAKAZyCkHAADxLqQd5UoX87zppptk5syZ4tVT9bQ673LJb37zG7nvvvtMXjhCu6BnYflmk1Pep81+/nxBFvMEAACIDVdffXWT7ztnzpyQjgWJS48jbNlEww0AAIhbIS2Uz549W4488khJSUmR3//+97Lvvvua7dpV/t///ldGjBhhcsqHDh0aymEktLz0jrJk64+SX7bB/Ns5TZKMcgAAgNigC9k3h2WFd6HFbdu2mcaYN99806wDpPv2Dz74oAwaNKjRx2kTzQsvvGDWGpo3b55Zw6hnz55y9tlnyw033CBpaWlhew9oTkc5hXIAABCfQr6YZ5cuXUw3eceOHWvddvvtt8thhx1m7jN9+vRQDkMSvaNcaUe50sU8DTrKAQAAYoJzVma0jm3s2LEyf/58ufHGGyU3N1cef/xx0yzz/fffS58+fRp8rBbVL7zwQjnkkEPksssuk/bt28vXX38tt912m3zyySfy6aefhr3oj4Y5Z6YKhXIAABCnQt5Rfuutt9YrkqsOHTrIpZdeKn//+99DOYSEl5fRsU5GeU0nSFGJ2LbNwQcAAAB225QpU2TWrFkyefJkGTdunNl25plnSt++fU3B+5VXXmnwsXrW6VdffSXDhw/3b7vkkkukR48e/mL5McccE5b3gSbIyTJXdJQDAIB4FdLFPDWLvLq6usHbPR6PuQ9CJze9U+2OcmeF+mqPSFlFJIcGAACAOCiUawPMaaed5t+Wl5dniuVvv/22VFRUNFooDyySO0499VR/XCOiMHqFjHIAABCnQtpRrju+//d//yfnnHOOdO/evdZtq1evNqdlavwKQptRrvJLawrlyUki6ammSK4LeloZZD8CAABg92i2uGaR121+0Zzyp59+WpYuXSoDBgxo1nNu3Ojbb9UYl4ZoAT6wCF9UVGSuq6qqzCUcnNcJ1+tFmp3pO26wtxdH9XtOtHmJFcxLdGJeog9zEp2Yl9idl+bOWUgL5f/4xz/Mgp377LOP6QzRUzDVkiVLTIeJ2+2Wu+++O5RDSHhORvn2yi1S4SmXVHea6Sq3tVCu3SAd2kV6iAAAAIhRGzZsMPv7dXXq5Durcf369c0ulN93332SnZ0tY8aMafA+egwxceLEetunTZsmGRkZEk6Jst5SclW1HKU/7CiTD957T+woPzM4UeYl1jAv0Yl5iT7MSXRiXmJvXnRNnKgplB900EEmp1wX7HznnXf8g9Od1+OOO84s6NlYpwj2XKvkbElzp0u5p0wKyjZJl1bdzUI89uYtIkUs6AkAAICdC3NWVlY26b6pqalmrZuysjLzc11pab7uY729uY02H3/8sTnztHXr1g3eb8KECXLdddfV6ijv2rWrjB492hTZw0E7lPTAbNSoUZKcnCzxTtc38s5+VPMz5bjhvxGrbY5Eo0Sbl1jBvEQn5iX6MCfRiXmJ3XlxzjqMikK56t+/v7z55ptmxzs/P9+fW6inZ951111msU/NKkdo6AGMdpWvLVlhcsq1UC7Zvpxyu5h8QQAAAPh88cUXMnLkyCbdV/PD9azR9PT0oDnk5eXl5lpvb6r//e9/8re//U0uvvhi+eMf/9jofbU4H6xArwdJ4T6AjcRrRkpFTiuxt2yXpNIKcXWI7vecSPMSS5iX6MS8RB/mJDoxL7E3L82dr5AXyh1aGNeFfhCZnHItlOeXbai1oKdNRzkAAEBc0UgSPWuzsUU0G6KF7+eee65J93WiVfRa41fqcrZ17ty5Sc+n3UDnn3++jB07Vp588slmjRthpAt6btlucsoBAADiTdgK5Yic3AxfTnmBs6BntrNiPYVyAACAeKJncVZXV+/WYzt27Cjjx49v1mMGDhwoX375pXndwAU9NX5R4xadNYoao/fV9YwGDx4sr732miQlcYgSrUyEo4hUv/+FeFdvENc+PcW1915iMWcAACAORPcKLGgReem+jp/8so21OsqlmEI5AAAAdt+4ceNk06ZN8sYbb/i3FRQUyOTJk+XEE0+sFY+yfPlyc6kb4aJd5D169JD33nuvWVEtCD/3/n1EXJbYhdvEM+M7qXryNan426NS+czrUj1zrngLt0V6iAAAALuNr/4TgGaUK80oN/wd5WSUAwAAYM8K5YcccohceOGFsnDhQsnNzTULceoaRBMnTqx136OPPtpcr1y50lwXFxfLscceK1u3bpUbb7xR3n///Vr379Wrlxx66KFhfDfYFffB/U0XuXfZKvEuXiGexb+KFO0Q78Ll5qKsvDbi6tfT123eu5tYKWS5AgCABC2Uz507t8n3Xb9+fUu/PBrIKK/VUe4s5kn0CgAAAPaA2+2WqVOnmkL3I488ImVlZTJkyBCZNGmS9OvXr9HHFhYWypo1a8zPf/7zn+vdfsEFF1Aoj0JWZrq4B+5jLkm2Lfb6fFM09y7+Vbwr1omdv1U8epk5VyTJLa5eXX1F8332Fqt9W7EsK9JvAQAAIDyFcs0WbOrOj23b7CiFMXpFO8rNZ+5Er5SVi11dTaYgAABAFNuyZUuT71taWirh1qZNG3nmmWfMpTFOJ7lD41Z03xSxS4/lrC7txdWlvcjRw8QurxDvstWmaO5ZvEJka5F4l6w0F3n7M5E22eKuKZq7+nQTK21nNA8AAECktXiF9Lnnnmvpp8QeapveXiyxpMpbKdsrt0pORhtt/xHxeMypktI2J9JDBAAAQAM0zoRGFMQCLXy7B/QxF9NtvnmLr9NcO86XrzGFc8/X881FXC5x9exiiubuQw4wneoAAABxVSjXUyQRXZJdydImLVe2lOebrvLWqW1FNH5la5HYxTvEolAOAAAQtW699VaK34jNbvMO7cTVoZ3IEUPErqwS7y/abb5CvEtWmIgWLZ7rxfPDIkm57gJ+zwEAQESRuZFAC3pqoTy/dIP0bt3fxK/YWignpxwAACCq3X777c26v9frDdlYgN2li3q6+/cyF+Ut2GqK5tXvfy72us3iXbpS3P16RnqYAAAggbkiPQCEd0FP7SivtaBncUlExwUAAIDGTZs2rcn3raiokFNPPTWk4wFagiu3jSQdPkjcQw8w//Z8PifSQwIAAAmOQnkCdZSrfH+hvJW5pqMcAAAgup1yyilNKpaXlJTIcccdJ++9915YxgW0BPeIg0Us8UWybCyI9HAAAEACo1CeIPLSO9XuKM/ydZRL0Z53lNtFJeL5fqFU/e8DqXzif+zgAgAAtKD999/fFMs//PDDBu9TWFgoI0eOlM8//1zuv//+sI4P2BOudq3FtX8f87PnC7rKAQBA5JBRnqAd5eKPXml+R7ldUupbiKfmoqvZB/J88b24zjy2JYYNAACQ8D7++GMZNWqUiVR54403ZMyYMbVuX7dunbl92bJl8uyzz8r48eMjNlZgdyQdMVgqf1omnjkLJen4EWK1yoj0kAAAQAKiUJ4g8jLqZpQ3PXrFLi33rUjvFMY35Ne+gyVidekgVuss8S74Rbyr1ofiLQAAACSk7OxsUywfPXq0nHbaaTJlyhQZO3asuU2L41ok37Rpk0yePNl0ngOxxuq5l1h7dRB77SbxfP2DJI0aLtHCrqwS76JfxbVfb7GS3JEeDgAACCEK5QnWUb6tolAqPRWSlNVwR7ldXiHeX9fuLIyv2yRi176P1SlPXL27iatPN3Ht3VWsjDQTwVKx4BexN+ab57DSUsPz5gAAAOJcVlaWTJ8+XY499lg5/fTTTbF8r732Mv8uKyuT999/X4466qhIDxPYLZZlSdIRQ6Tq5fekeuY8cY8cKlZSdByqVk2ZJt45P4t71KGSPOY3kR4OAAAIoejY+0DIZSXnSKo7TSo85VJYtkk6Zrfx3VC0Q+yKSvGuXC/eZat8hfG1G0W8tSvjVvu24urT3Vcc79U16OmQ2qVutc0Re8t28a7aIO5+PcL19gAAAOJeq1atzKKeumDnuHHjJC0tTZKTk+XTTz+VwYMHR3p4wB5xDewn8t4Mke0l4p23WNxD9o/0kMzaS97vfzY/e75bIEnHHiaWi2W+AACIVxTKE6hLQ7vK15WsNDnlHdt08d3g9UrFXx8x17Xur4vqOB3jvbv5o1p2+TrdO5tCub1ynQiFcgAAgD02d+7cWv++66675IILLpDNmzfLY489Ji6Xq959Bg0aFOZRAnvGcrsl6fBBUv3+F1L9xRxxDd7PHMNEUvUHX+48s3ZbsXh/WSPuvt0jOiYAABA6FMoTSF5NoVxzyq08tymG24XbfEXyNtmmIO7uXVMYb5O9W6/h6tFFvPMWkVMOAADQQrRbvG7B0LZ91TstmNfdrvf1eDxhHSPQEtyHHCjV078We91mc6aru0/kitLeNRvE+9My7TgyzUPepavEM2cBhXIAAOIYhfIEkpveyVznl20w18kXn2YWzLF6dDZF85bo2HD16GyuNcrF9tpiuSLbBQIAABDrnnvuuUgPAQgLKzNd3IP3E8+sH8TzxZyIFsqrp840166D+0vS8IOkcukq8f64VOzTR4mVmhKxcQEAgNChUJ5gHeVKo1eUq2OuiF5akNU5TyQ5SaS8QuzNhWK18PMDAAAkmrpd40A8c4842BTKvQuXizd/i7jy2oZ9DN7la8S7ZIWIy+XLJW+bI1ZeG7Hzt5pieTTkpwMAgJbHSiQJRDPKVUGpr1AeqmxBq1snf1c5AAAAADSVq307cfXf22SDe774Puyvr/FFVVO/ND+7DzlAXDVn3mqnu/LM8S3uCQAA4g+F8gSSl1G7ozxUXN198StmQU8AAAAAaAb3EUPMtee7BWKXlof1tb2LV4i9Yq1IUpIkHXOof7vrYF+h3PvLKrG3FoV1TAAAIDwolCdiR3nZRv8CUKHgzylnQU8AAAAAzeTq3U2sTnkilVXi+WZ+2F5Xj5GqP6jpJj/8ILFaZ+0ck8av9Orq63T/fmHYxgQAAMKHQnkCyU3rYK4rvRVSVLktZK/j6tHFXNubCsPeAQIAAAAgtpmokyMGm5+rv/xebI8nLK9rFutcu0kkNVmSjhpW73Ynm9wzZ0FIG48AAEBkUChPIMnuFGmT6ltcs6BsQ8hex2qVIVZua/MzXeUAAAAAmss9aF+RrEyR7SXinb8k5K9ne71S/eFM32uPGGyOaeqN6YC+IslJYm/eIvaa0MZZAgCA8KNQnmDClVNu1XSVe8kpBwAAANBMlmaEDx9ofq7+fE7IO7i9cxeZM2IlPU2SjhwafExpqeIa0Mf8zKKeAADEHwrlCSY3vVN4FvSsySm36SgHAAAAsBvcWihPcpvubTuEDTh2tUeqP/rK/KyRK1Z6asNjGlwTvzJvkXkcAACIHxTKE0yes6BnaYgL5d1rOspXrTenMQIAAABAc1hZmeI+eD9/V3moeL79UezCbSbqRRfxbIyrT3eR7EyRHWXiXfRryMYEAADCj0J5gslND1P0SqdcswiOVFSJvbEgpK8FAAAAID45i3p6f1omXi1mtzC7skqqp31tfk465lCxUlMavb/ldol7UH//op4AACB+UChP1I7yUBfKXS5xdfPFr3hXEr8CAAAAoPlcHXPF1a+HiG2LZ+bcFn9+z6wfRIpKRNpki/vQA5r0GPcQX/yKd+FysXeUtfiYAABAZFAoT9CO8lAXypVVk1POgp4AAAAAdpd7hK+r3PPNj2KXV7TY8+pzVX/yjfk5afRws4BoU7g65YnVpb2IxyueHxa32HgAAEBkUShP0I7yrRUFUuWpDOlrubqzoCcAAACAPePap6dYHdqJVFSKZ/aPLfa8ni++N1njVl4b/yKdTeVf1PM74lcAAIgXFMoTTFZKa0lxp5mfC8o3hadQnr9V7JLSkL4WAAAAgPhkWZa4RxxsfvZ8OVdsr3ePn1MjU6pnfGt+TjrucJM93hzuQfuKuCyxV28Q7+bCPR4PAACIPArlCbiTGbac8sx0sdq3NT976SoHAAAAsJvcB+8nkpku9pbtZmHPPVX92bci5ZVidW4vrgP3afbjraxM0+muPHN+3uPxAACAyKNQnsA55fmloc8pd/XoYq5Z0BMAAADA7rJSksU9fKD5ufqLOXv0XHZRiXi+/N78nDTmcLFc1m49jz9+Zc7PYnvtPRoTAACIPArlCShcHeWBC3raLOgJAAAAYA8kHXaQiNsl9op14l29Ybefp/rjb0SqqsXq1klc/Xvt9vO49ustkpYqsq1YvMtX7/bzAACA6EChPJE7ysvC2FG+ZqPYnj3PEgQAAEB02bZtm1x66aWSl5cnmZmZMnLkSJk7d26zn6eqqkr69+9vogIfeOCBkIwVsc3KbiWug/Y1P1d/vntd5fbWIvF8Pd/8nDR2hPl92+3xJCeJe6AvtsVL/AoAADGPQnlCd5TvfhdGU1nt2/m6LCqrxN6wOeSvBwAAgPDxer0yduxYeeWVV+TKK6+U++67TzZv3ixHHnmkLFvWvBzpRx99VFavpisXjUs6YrC59s5fbIrezVU97SsRj0dcfbqJu0/3PR6Pe8h+5trz4xKxKyr3+PkAAEDkUChPQOHsKNe8P1d3X/wKOeUAAADxZcqUKTJr1iyZNGmS3HbbbXLFFVfIjBkzxO12m383lRbX77jjDrn55ptDOl7EPleXDuLq1VXEa0v1zOadueDdvEU83y0wPyeNGdEi47F6dBGrXWuRiqoWWWQUAABEDoXyBO4o10K5bYd+0RlXTU65l5xyAACAuCuUd+jQQU477TT/No1gOfPMM+Xtt9+WioqKJj3Pn//8Z+nXr5+cd955IRwt4oW7pqvc8838ZnVxV3800xTYNZfcOUbZUxrd4h5c01VO/AoAADEtSWJMSUmJ3H///TJ79mz59ttvZevWrfLcc8/J+PHjm5yheNNNN8mbb74ppaWlMnToUHnwwQdl0KBBkijapXcw15Wecimu3CbZqW3CtKAnHeUAAADxZN68eWY/2uWq3X+j+9hPP/20LF26VAYMGNDoc+g+/fPPPy8zZ85scl60FuADi/BFRUX+nHO9hIPzOuF6Pexka2SKdnEXbpPKb+aLa/jAXc6LvT5fvPMW+/4x6tAWnTf7wL4iH30l3mUrpbJgq1g5rVrsueMFfy/RiXmJPsxJdGJeYndemjtnMVcoLygoMKdlduvWTQ488EBzamdzMxTnz58vN954o+Tm5srjjz9uMhS///576dOnjySCFHeqtE5tJ9sqCk1XeagL5a5unUUsEXvLdrGLSswiPAAAAIh9GzZskBEj6kdYdOrUyVyvX7++0UK5nt141VVXyVlnnSWHHnqorFy5skmve/fdd8vEiRPrbZ82bZpkZGRIOE2fPj2srwefrm1SpH+hSMm0mTJz6zpt7W50Xg5asFba6+9sXpb8+MN3Ij+07HiG5KRL2+1lsui/b8rKbu1a9snjCH8v0Yl5iT7MSXRiXmJvXrRJOq4L5brTrTvkHTt2lDlz5siQIUOanaE4efJkGTdunNmmp4X27dvXZCjqIkSJlFOuhfKCso3Sq7Vv5fhQsdJTxeqQK/bGApNT7j6gb0hfDwAAAM2nTSWVlU2LsUhNTTXd32VlZebnutLS0sy13t4YzTb/6aefzH56c0yYMEGuu+66Wh3lXbt2ldGjR0t2draEg3Yo6YHZqFGjJDk5OSyviZ00csV79zOSWVYhY3ruI1b/Xg3Oi71qg3g/X2KK6V0uOE32ymvb4uPx5v4k9usfS78dXtl3zJgmnx2RKPh7iU7MS/RhTqIT8xK78+KcdRi3hXLdEdcieUtnKL700kvm9M1gO/rxmlP+y7afW2RBz0pPhSza8oPMz/9G1peslvP7XyOdW3WrdR/NAPRooXwVhXIAAIBo9MUXX8jIkSObdN9FixbJPvvsI+np6UFzyMvLy8213t4QPXDRgree6alF7ubQffZg++16kBTuA9hIvCbMBy9Vhxwons++FZk5T5IP3KfBeamc/rW5dg/ZX5I7+2IoW5o9aD+peHuGyOYtkrRpi7i67t4xa7zj7yU6MS/RhzmJTsxL7M1Lc+cr5grlkchQjIYMROf1Aq/3RNtUPfFQZNOOdc1+Pj1FdnXxLzK/YLb8VPitLNzyg1R5d34+mUlZctmAv9Z6jFd3FL/5UTwr1uobkHhBTlV0Yl6iE/MSnZiX6MOcJE4GYrTRwreu/dMUTrSKc7ZnXc62zp0bXjDxgQceMB3sGrviRK6sXbvWXOs6RLpNH5+SkrJb7wfxL+nwQeL5/DvxLl8j3nWbxNWlfhHcs2yVeJetEnG7JGn08JCeResa0NvkoOuinhTKAQCIPQlVKN/dDMVoykBsqUykzbLF5IYv+PUHmfrr1F3ev1SKZb38WnNZLuXWjlq3Z9hZ0lray3pruXyz5jPpumagWPoCzu2llfIb3VFdtUGmvfe+2K74OhWRnKroxLxEJ+YlOjEv0Yc5if8MxGijZ22OHz++WY8ZOHCgfPnllya2JbAZZfbs2WY/WSMOG7J69WpTEN9vv/3q3faPf/zDXLTRRV8DCMZqky2uA/uZ4nT153Mk5Zyx9Rp8qqd+aX52HzpQrLY5IR2Pe/D+vkL53IWSdNKRYrndIX09AADQshKqUL67GYrRkIHY0plIuRsz5Lt5H0lya0uOH358vdsrPOWyaMs8+bHgW9M5vqZkea3bU91p0r/tIDmg3VA5MHeYdGnV03SVX/jxaCn1FsuAw/eRblm+nEBnJ9X785PiLi2X4w48WKw46bAgpyo6MS/RiXmJTsxL9GFOEicDMR7ouj8ab/jGG2/41wAqKCgwawKdeOKJtfa9ly/37U/26uXbR7z66qvllFNOqfV8mzdvlj/84Q+mYH/yySdLz549w/p+EHuSRgyRynmLxTtvkdgnHCGSvvN3zrtwudir1oskJ0nSMYeEfCyuvj1EsjJFineId9Gv4t6/T8hfEwAAtJyEKpTvboZiNGUgttTrdszqYq4LyjeZ5/LaXlmxfYnMz58tP+R/bTLHq707Tx/W7nBd9PPAvGEyMO9Q6dfmAEl21z4NNkVSZEDuYJm7+Sv5acu30qtt7ZzAyh6dxbvwV3Gt3SRJezcvhzLakVMVnZiX6MS8RCfmJfowJ/GfgRgPtDh+yCGHyIUXXigLFy6U3Nxcefzxx8Xj8dQ7I/Poo482107MikYi6iWQc5t2mdctogPBuLp3EqtnF7FXrJPqr+aJ1BTEba8t1R/MND+7Dx8kVnarkI/FcrvEPWhf8Xw+x8SvUCgHACC2JFShfE8yFONNbrovbmZrRYE8+P0E+TF/thRVbqu34OeBeYfIwLxDZEDeUMlOab3L5z2o/XBTKJ+3eZac0vv8Wre5uncxhXLvynUiIwa38DsCAABAuLndbpk6dapZkPORRx4xZ2gOGTJEJk2aJP369Yv08JAgkkYMlqoV68Qz6wdxHeE7zrB/Wir2+s0iaSmSdNSwsI1F41e0UO79ebnYO8rEymx4QVsAABBdEqpQvicZivFGi94p7jSp9JTLzHUfmW1p7gwZkDdEBuYNMwXyzpndxbKalyWuhXK1cMs8KasulfSknRnuVg/fFxHeletb9L0AAAAgctq0aSPPPPOMuTTG6RZvTI8ePUxkH9AcrgF9TP64vWW72HMXiWXbYk/72tyWdMSQsBarXV3ai9W5vSnSe+YvlqThB4XttQEAwJ7ZWS2OM9olvnjxYpMnGXhq6KZNm0yGoqOhDMV4pwXws/peKvu3Gyxn9L1E7jrsP/LimM/kL0P/Kcf3PFu6tOrR7CK56pzZTTpkdDGxLQsKvqt1m6tbJ31hkW3FYm8rbsF3AwAAACBRWS6XuH/ji/GxZ86VzhuLRAq2imSmi7umwzyc3IN9C9Rq/AoAAIgdMdlR/thjj8m2bdtk/XpfZ/K7774ra9euNT9fddVVkpOTYxbgfP7552XFihWmM6W5GYqJ4LQ+482lJWlxXbvKP1w5WeZuniVDOh6x87bUFLE654m9brOJX3EPrJ1hDgAAAAC7wz3sAKn+8CuRzVtknwJfw49Grlhp4W+G0pzy6ndniL1yvXg3bxFX+7ZhHwMAAEiQQvkDDzwgq1at8v9bO8SdLvHzzjvPFMqDIUMxPJxCueaU66mzgZ3prh5dxKOF8lXrKZQDAAAAaBFaEHcPGyCeL76XJK8tkp0p7sMiE3uiC4e6+vUU7+JfxfP9z+Ia85uIjAMAACRA9IrmG2oBNtjF6R7X4nfgv+tmKGrkyo4dO2TGjBkyeDALS7akAblDJMlKkk2l62TDjjW1bnN1r8kpX7EuQqMDAAAAEI/cvznYF/WoxWrtJk9JjtxYhuyMX7G1cA8AAKJeTBbKEd10Ac992/m6N7SrPJCzoKe9bpPYVdURGR8AAACA+ONq11qsk46UVZ1bizVk/8iOZb/eImkpIluLxP61dvMQAACIThTKEbL4laCF8natRVpliHi8Yq/dFKHRAQAAAIhHruEDZXGfDmIluSM6Du1mdx/oi5pkUU8AAGIDhXKExKCaQvlPhXOk0lPh36555a6arnJd0BMAAAAA4pE/fmX+ErErqyI9HAAAsAsUyhES3bJ6S9u0PKn0lMvCwrm1bnN172KuvSvXR2h0AAAAABBaVo+9xGqbI1JRKd6flkV6OAAAYBcolCMktHPciV+ZWyd+xdVzZ0e5LrgKAAAAAPHGclniGrxzUU8AABDdKJQjZAa1Pyx4TvleHUVcLpHiHWJvLYrQ6AAAAAAgtNw1hXLv0pViby+O9HAAAEAjKJQjZA7MGyYuyy1rS1bI5tL1tRa2sbq0Nz/b5JQDAAAAiFOu3DZi9ewiYtvimbso0sMBAACNoFCOkMlMzpK+bQaYn3/Y/HWt21w9yCkHAAAAkDhd5Z7vFhA9CQBAFKNQjpAa1FBOeY+dOeUAAAAAEK/cB+4jkuQWe2OB2Os2R3o4AACgARTKEVLOgp4/FnwrVd4q/3ZXd1+h3F6fL3blzu0AAAAAEE+sjDRx7dfb/OyZsyDSwwEAAA2gUI6Q2jtnH8lOaS1l1TtkyZYfd97QJlsku5WI1yv2mo2RHCIAAAAAhCd+Ze4isT2eSA8HAAAEQaEcIeWyXDIw71Dz87yA+BXLsohfAQAAAJAQXPv0FGmVIVJSKt4lKyM9HAAAEASFcoTcoA6H1SuUq52Fchb0BAAAABC/LLdb3IP29S/qCQAAog+FcoScdpRbYsmKoiWypTzfv93Vo4u59q5az+rvAAAAAOKae/D+5tr78y9il5ZHejgAAKAOCuUIuZzUNtKrta974ofN3/i3W3t1EHG7zemHdsG2CI4QAAAAAELL6tJerI65ItUe8cxfHOnhAACAOiiUIywOaj/cXM/b/JV/m5WU5CuWi4i9ivgVAAAAAPFL12lyFvWs/vgb8f66NtJDAgAAASiUIywOyvMVyn/I/0Y89s5V3lnQEwAAAECicA8dINI6S2RrkVT+3ytS9cbHYpdXRHpYAACAQjnCpW+b/SUzOUtKqorkl60/188pZ0FPAAAAAHHOapUhqTdc6CuY2yKemXOl4v7nxLN4RaSHBgBAwqNQjrBwu5LkwLxDzM/zNs/yb3d193WU2xvy6aQAAAAAEPesjDRJPnuMJF92plhtc0x3edXTk6Xyv1PF3lEW6eEBAJCwKJQjbA5qf6i5npe/s1Bu6WmHbbJFbFu8azZGcHQAAAAAED7uvj0k5cYLxf2bg0UsEe93C6TivmfFM39JpIcGAEBColCOsOeUL9v6sxRVbqvfVU5OOQAAAIAEYqWmSPKpR0vKleeK1b6tSPEOqXr+bamc9JbYRSWRHh4AAAmFQjnCpl16e+me1VtssWX+5m+CLOgZ+pxyz9KVUv3VPLFtO+SvBQAAAABN4erZRVKuHy/uYw4VcbnE++NSqbj3Wan+9ieOXQAACBMK5Qirg9r7usrnBuaUOwt6rlovtjd0O4HeVRuk6t9TpPr16eLldEYAAAAAUcRKTpLk438jKdf+Tqy9OoiUlUv1qx+Y/HLvlu2RHh4AAHGPQjkiUij/If9r8dpe87PVub1IUpJIabnY+VtC8rq6KE7lC2+LeHyvWT3965AW5QEAAABgd7i6dJCUa34nSWOPEElyi3fJSqm871mp/nIuxzAAAIQQhXKE1b7tDpI0d7psqyiUlUVLzTYryS1W147+rvKWpjuTVa+8b1aTt9q1FklNEXtDvnh//qXFXwsAAAAA9pTldknS0cMk5YYLxeq5l0hllVS/+bFU/t8r4t1cGOnhAQAQlyiUI6ySXckyIG+o+XlerfiV0C3o6fn0G/Eu+tV0rSePP0XcvxlktldP+4q8PwAAAABRy9W+raRc8VtJOn2USGqy2CvWSeUDk6T642/E9ngiPTwAAOIKhXKE3aC8RnLKW3hBT8+yVVL9wUzzc9K4UeLq0l6SjhgikpIs9rrN4l24vEVfDwAAAABakuWyJOmwgyT1xovEtU9PkWqPVE/9Qir/9aJ4126K9PAAAIgbFMoRdgPbH2qul2z5UXZUFdfuKN9UIHZZRYu8jr29WKpefFfEtsU9dIAkDR1gtluZ6eI+3Okqn0VXOQAAwB7Ytm2bXHrppZKXlyeZmZkycuRImTt3bpMf7/V65YknnpCBAwdKenq6tGvXTo466iiZP39+SMcNxBqrbY4kXzJOks8ZK5KRZhp/Kv/1glS9/4XYVdWRHh4AADGPQjnCrmPmXtI5s7t47Gr5Mf9bs83KyvTlh9si3tV73lVue7xSqUXyklKxOuVJ0mnH1Lo96YjBvq7yNRvFu3jFHr8eAABAItIi99ixY+WVV16RK6+8Uu677z7ZvHmzHHnkkbJs2bImPcdFF10kV199tRx88MHy6KOPyq233irdunUzzwOgNsuyxD14P0m9+WJxHdhPxGuL55NvpPLBSeLdWBDp4QEAENOSIj0AJKaD2g+X9StWybz8WXJo56PNNqt7Z7ELt4l3xTpx9+u5R8+vpyLav641C3cmjz9ZrJTkWrdrYd49fKB4Znwn1R99ZU5h1J1OAAAANN2UKVNk1qxZMnnyZBk3bpzZduaZZ0rfvn3ltttuMwX0xrz22mvy/PPPyxtvvCGnnnpqmEYNxD49nkm54GTx/LhUql6fLvbmLVL58IuS/Nux4j6gb6SHBwBATKKjHBExqIMvp3ze5q/90Sf++JVVe9ZR7lmwTDyf+TrVk88eI668tkHvl3TkELPAp716g3iXrpJood3wAAAAsVIo79Chg5x22mn+bRrBosXyt99+WyoqGo/Ue+ihh2To0KGmSK7d6Tt27AjDqIH4oUXx1BsvFFfvbiIVVVI16S1fFIuXYwoAAJqLjnJExH7tDpYUV6oUlG2UtSUrpGvW3jsX9Fy1XmyvbRataS5v4TapemWq+dl9xGBx6+mIDbCyW4n70APF8+X3Uj3tK3H17R7xrnJv/hapfPxVU9xPvvg0sVJTIjoeAACAxsybN08GDRokLlft/hstfj/99NOydOlSGTDAt05MXUVFRfLtt9/K5ZdfLn/5y19M7EpJSYn07NlT7rnnHlNsb4gW4AOL8PpcqqqqylzCwXmdcL0emiYh5yU1WeSiU8X64Euxv5xrolg8azaK67djxMpIk2iQkPMSA5iX6MOcRCfmJXbnpblzRqEcEZHqTpP92g2Seflfy9zNs0yhXLPENTdcyivNop7m382gC9hoB4WUV4jVo4sknXDELh+TdNRQ8Xz9g9gr1on3l9Xi7tNdIkU766tf+0hke4l4t5eY95J88eliJbkjNiYAAIDGbNiwQUaMGFFve6dOncz1+vXrGyyUL1++3Oz/vPrqq5KUlGTyzXNycuThhx+Ws88+W7Kzs+W4444L+ti7775bJk6cWG/7tGnTJCMjY4/fV3NMnz49rK+HpknIeXGJdNqnk+y3dKO4l66UknufkXn7dZGSVqkSLRJyXmIA8xJ9mJPoxLzE3ryUlpY267kolCOiOeVaKJ+3eZac3Os8sdwucXXtKN7la8S7cr24mlkor37zE7Pyu2SmS8r5J4nl3nWB2crJEvewA8Tz1TzxTJsV0UK5Z/ZP5r1LcpKu0iPeJSul6tUPzKr2u9NdDwAA0BwafVJZWdmk+6amppoz8crKyszPdaWl+bpY9faGaPe4KiwslG+++UaGDRtm/n3SSSeZrvI777yzwUL5hAkT5LrrrqvVUd61a1cZPXq0KbCHg3Yo6YHZqFGjJDm59no4iBzmRcRev1m8L7wrGVuL5LAf14p1xmjfwp8RxLxEJ+Yl+jAn0Yl5id15cc46bCoK5YhooVx+flB+LvxeyqvLJC0pXayeXUSWr/HllB96YJOfy/PdAvF8M1/EEkk+70SxWmc1+bFJRw0zjzUF+uVrxNWrq4SbXVQi1e9+5hvPmMPF6pArVf95Q7xzF0p1dqYknzQy7GMCAACJ5YsvvpCRI5u2z7Fo0SLZZ599JD09PWgOeXl5ubnW2xvi3KZFcadIrlq1aiUnnniivPTSS1JdXW26zevS4nywAr0eJIX7ADYSr4ldS+h56d5F7OsukKoX3xXv0pViazTlhgJJOn6EaU6KpISelyjGvEQf5iQ6MS+xNy/NnS8K5YiYLq16SF56J8kv2yALCufI4A6/EVf3zuLRjqaV65r8PN71+VI1ZZr5OWn0YeLu16NZ47DaZPu6ymf9INXTZ0lKr7Mk3Kre/ESkrEKsvTqI+zeDfTuwZx0nVf+dKp4Z34mVnSlJRw4N+7gAAEDi0ML3c88916T7OtEqeq3xK3U52zp39i3WHoxzmy4GWlf79u1Nl5Au7qlxLACax8pMl+RLx0n11C/F8+ls8Xz2rdjrNkny704ytwEAgPoolCNi9HTdQe0Pk49WTTHxK06hXNmbt4i9o2yXO3F2eYVUPf+WSFW1uPr1FPeo4bs1Fl9X+Y/iXbpKvCvWiUs728PEs2CZeOcvEXFZknzWcf4uD/eQ/cUu3iHV730u1e/MECsrU9wH7xe2cQEAgMTSsWNHGT9+fLMeM3DgQPnyyy9NbEvggp6zZ882WeF9+/ZttFCur7luXf0GCc021/iWrKymnyUIoDbL5ZLkE44Q114dTKSjHutU/vMFSb7wFHF1qf8FVSLT9RI0xtPqnGc+NwBAYuL/ARD5+BURUyhXVqsMsfLamJ+9Gr+yi52Zqtc+FDt/q0jrLEk+d/ezvK22OaYwraqn+cYSDqbQ/7pv0QH3kUPr7bC6Rw4V94iDzc9V//1APEtWhG1sAAAAuzJu3DjZtGmTvPHGG/5tBQUFMnnyZBOfEhiPoot36iXQWWedJWvWrKm1CJM+/u2335ajjjqqVvEdwO5xD9xHUq4+T6x2rcXesl0qH3lZPN8vjPSwokr1R19J5UPPS/Vbn0Z6KACACGLPExF1QN4QcVtJsmHHGtlQstpss3r4url1Qc/GeGbOFe8P2ontkpTzTzZF9j3hPuYQ09XtXbJil0X6llL9/hci20vMTmvS6OFBu+6TTjpKXAftqytsSdVzb4l3Tf3TmwEAACJVKD/kkEPkwgsvlDvuuEMef/xxOfLII8Xj8cjEiRNr3ffoo482l7qLcmp8y+mnny633367/POf/5TDDjvMxK784x//CPO7AeKXq3OepFx7vrj22ducjVv18ntS9fanYnu8kui8BVvF88ls87Pnq7niXbsx0kMCAEQIhXJEVHpSpuzbdqD5eV7+1+baH7+yquGcci2iV79Ts/jlSSPF1aPh/MvADvTXlz0rD8+9VcqqS+vd7mrX2h9tolnloeZdsVY8X80zPyedeaxYKcEXGNAu+eTfHi+uvt1FKquk8t+vizd/S8jHBwAAsCtut1umTp1qOsMfeeQRufHGGyU3N1c+/fRT6dev3y4fr/nkM2fOlGOOOcYUyf/617/KXnvtJZ9//rkceGDTF3YHsGtWRpok//40cR9zqPm35/M5UvXk/8QuqX9slEiq3/5MxOMxDVhii1S98bHYXjvSwwIARACFckRd/IrL6ShfvSFoh4PuyFW+8LaIxyv/z95dwDd1dn8A/0XrpUoNKNJCcXd3Gzp0AmzMmLu8c99ggzHjv40NBmPo2HB3d6e0QCnUW6Cl3si9/8950pQ6Bdombc73fbMkN3aTm5Rzzz3PeZQtG0HVvU2ZXmdx2Bz8FfojdkavxdKwX0quKlcoIJ2PgBRVcZUEssEA/bJNptfs0Byq4MBS769Qq6CZMlJM9on0TOh/WQ45Nb3C1o9VPCnxBuSUNEuvBmOMMXbf3N3dMXfuXNEyhSbf3LlzJ9q1a1fkfpGRkeJUWP369UXrllu3biEzMxPbtm1D+/btK2ntGbPBvuVDuot9C9hpIF2OQs7MPyt038eaGUMjIJ27JJLkNPkpfSZyZCykY+csvWqMMcYsgBPlzGoS5WeuH4HOmAOFrydgpwVy9JDjkwrcl47s6xetA1LSRC9zMfml4s59yddGLMby8LkFrl9LLdgjkyi9PaBs07jCq8oNWw9CTrgBuDhBPaxXmR6jsLeD9skxt3sL/rZC9DhnVY8UnQDdjHnI+WoujBSYWyEagSHdSOFqGsYYY4yxakjVoiG0Lz1qmh8qJQ26HxbBeOQsbIlsMMLw3zZxmYqvVA3rQt3ftG+qX7MTchbvazHGmK3hRDmzuLquwXC380KOMRuhN0+KKgdloF+xfcqNWw+IHuLQqKGZPFIkj+9kV/R6/H52hrj8UMiz6ODbC0bZgF/OfCmSgYWpaSiiApDOXoIUk4DyJsVfh3HbQXFZM6ovFE4OZX6swsUJmqfHAs6OYlZ2/bx/RXU6qzrEwZ6VW8SICGqlo//jXxgOnIQ1kWm9/loL3ee/wrCaJzRijDHGGKuOlL5e0L48CcqmDQCDEfrF601tR6gNiQ0w7j4KOSnZVLw0oKtYpurRDoqaHmIUr2HTXkuvImOMsUrGiXJmcVQRXrj9St6Envkm1TSGR+YFK5oxA8SENHdyPHEffjjxkbg8tN5EjAmeiqnNXodWZY/zN45jV/S6Io9R+nhC2cpcVW7qm16uSdJlG01tY5o2EK1j7pbSyx3a3GGB0sVr0P+9jqt+qxAaxknDOaHVQNk6hEq3YVi+GfoNe4o9cFPZ5Ftp0P20GNKJUHHduO8k5LQMS68WY4wxxhirAAoHO2geGw31QFOi2Lj3OHRzllb7+I/aWJpHEKuH9hCfg7nlpXpUv7zPQootOMKZMcZY9caJcmYV2uQmyo+b+5SbJ/S8YprQk3o56xeuEZOrqDq2gKp9szs+Z9jN05h+5A1RPd49YBAeb/aaSMrXdPTHuIZPiPvMP/cdMvRF+0Sr++dWlZ8OhxRXfsGRcf8JU5LUTgPN6P5lahtTHGUtX2geGwWolJBOhsFAM9ZbQZKVlY6Gb+rX7hKX1QO6QPPIMKgGmL77xi0HoF+ywaIVPNSbMue7hZCpR6WjvWkortEIQ+6ks4wxxhhjrPpRKBUiUa6ZOhqw10KOiBZ9y41nLlbbfQwRk+fooajjB1W7gvuWqkZ1oWzREKAip3+3VtvPgDHGWFGcKGdWoYV3RyihRFTaZVzPir+dKKceyVThumA1kJEFRUBNqEf1vePzRaVF4LNDL4l2Lq29O+OF1h9Dqbj9dR/e4FEEONfFLd1NLAr9qdhhiMoWjcq1qlxOToVhXW6SdGhPKNxd7+v5qIee5qGh4rJxzzEYtx8ql/VkFUeMiEjLEAloMaxToYBmUDeoxw0ElApIR85CP/cfi/SeN568AN2PfwO30qHw8UTWsw9gU9d0JGuzYNx3QrRjYYwxxhhj1ZeqaRC0Lz8qYkGKCanNo44S5merV8JcuhID6ahpsk7N6H7iQEFhmhF9RLtP+XJU3khLxhhj1R8nyplVcNHWQLC76Uj+icQDUFA1KwVoAHR//As5Mgawt4Nm8ggotJpSnyspMw4fH3gO6fpbaOjeDG+2/wYaZcHH0PWnmr8lLm+KXIHLKaHFV5VTIHXqAiSaePM+UGCp/2eLqWqhrj9UXVqjPKhaN4aagjhKwq7bDcPhM+XyvKz80cgEGr5JFKN6Y9nl37Hq8l8wSHqoO7WE5vHRoh2LFBYpWp/QcNDKQN9Nw6Z90NPBKL0BypD6uPhoU7x25hnMS1mIH1ocFgepjLk7E4wxxhhjrPpS1vSE9qVHoOrXSYyCFfMi/VF9EuayJIkqcaLq0BzKOqa5sQqjoiYxdxVVn6/eaZFCFsYYY5WPE+XMapj7lFNfcaKsm1tVTm0gKLk9cYjoz12a1JxkfHzwOdzITkAt53p4t+P3sFc7lFjF3i1gICRI+OX0l5BkqcDtSv+aUDYPFu1ezP3r7pV0KgzS+cuiVYpm3KBiqxbulbpnO6h6dxCXDcs2wkivw6yKSEav3CqGbyqbN8QW7VEsCfs/zD83E+/uewLxGdFQNWkA7bMT8iZqzZn9130foCnTpJ0LV4tEOVH0bIM1vVLx4bEXkJxzXSwLdY7DRdfrpsmOuBc+Y4wxxli1p6ACpSE9YPfeM1D1LZQwn7UAxnOXqmzC3HjoDOToBNFihnqTl0bVqz0Unm6A6GdevnNXMcYYs06cKGdWo01N0wQyp5MOiypbRaBpQk9zkKKipHUpsgyZ+PTQi4hJj4SXgy8+7PwTXLVupT7msaavwkHthIspZ7H16r9Fblf3NyXvpRMXICXeW9JSzsgSs8eL99G3k2jrUt6olYuyXVNTH70/VxWYBJVZnnTyAqTLUYBajeSBjfFX6A9iuVqpQXjyGby6ayJ2Rq0TFS3aFx829QZPToXu+0WQIqIrZJ2o77+YtPNkmDiAkzWmG2b4rsZfF36EJBvRq9ZQcSCJrK4bBjnxJqRQPgjDGGOMMWYrFE4O0AztAbt3n4aqT0cx+pGSzPrfV1bJhLmcmQ3D+t3isnpgNyhcnEq9v0Kjzmv7adx1tMKLWBhjjFkeJ8qZ1Wjg1lgktjMN6SJ5qGpcD3Cwh7JRvTse7ddLenx95HVcSjkHF60bPuz0k0iW34mHvTcmNnpGXF4Y+gNu5SQXuF1ZywfKpg2oJBiGrQfv6X0Z1uwE0jNFKxk1DWGsAFShrhk/CMqQeqJ9hm7uP/ec2GflS87RQb9qh7is6tsRv1z7AdnGLDT2aIWf+vwrzrMMGZh94n3MOvYusmqooX3hYSioT39WNnT/txTGU2Hluk7StTjkfLfANFrDyQGRk1rhrYzPcCxhLzRKLZ5t+T5ebP0JxjV8Utz/mEc0YhxTYdx5pFzXgzHGGGOMWT+FsyM0D/SE3XvFJMy/WyhGtFaFhLlh417TvFc+nlB1K1srTBr1KfYHJQkGC0/saTx2XrTz5LmDGGOs4lS5RHlOTg7eeust+Pv7w8HBAR07dsSWLVvu+LiPPvpITJxX+GRvb18p683ujCbbbOVt6gN3PHE/FDVcYPfJc9A8NQYKlarExxllI74//j5OJR2EvcoB73X8HrVc6pX5dYfUG4+6rsFI16diYej3JVeVHz8PKalgIv1OjOFXYcztG64ZNxAKtRoVhT4j0cO9tq8IAHW/LBcToTLLEsM0U9PFsM19jW7iROJ+UUlOyeiajv74tOtveCjkWSgVKuyO2SCqyy/khEM7bTyUzYIAgxH6Batg2H20XNbHeCIUuh8XA6kZgK8nNo9zxPuR/0NSVjz8nGrj6+5/on/gKPH3sbZLfXTw7QUZMtbWMVXFS9GmVkiMMcYYY8yGE+bU+pES5lHxYjJ6a0+YS7FJMO4/IS6rR/Urdf+yMDEnlFoFKfwqpNPhsASai0q/aC2M+07AuOeYRdaBMcZsQZVLlE+ZMgUzZ87Eww8/jNmzZ0OlUmHIkCHYu3dvmR4/Z84cLFy4MO80b968Cl9nVnata5oS5ZRMJBTAUMKuJBSI/X5mBvbGboZaocZb7b8RE3jeDZVSjaeavyMub7u2ChdunipwO7XDoAkOqa2JcVvZq8rpSL9h+SbTa3RtDWW9WqhoCjsttE+Oud2649cVkLOyK/x1WfGoqt+4y1SFnTGsHf64MEtcpkpt88EclUKFsQ2fwOdd58LHMQCJmbF4b98TWBrxO5STHoCqSytTn/z/tkO/esc99wmnx+k37IF+4RrAYEB2U3/M7nEO8678BINsQBf//vimxyLUq9GowONGBU0W53t8ruKmNhOGneWTsGeMMcYYY1U4YT6sV/EJ89l/wRgaYVUJczFf0L+58wW1aAhVw8C7ejzNk2WeE0q/anulV3QbT4fDsHRj3nXDziM8uShjjFWQKpUoP3z4MJYsWYIvv/wSM2bMwFNPPYXt27cjMDAQb775ZpmeY8yYMXjkkUfyThMnTqzw9WZlZ64oj7h1ASnZd24dsiz8N2yIXAYFFHipzadolZtov1uNPVuhT+3h4jJN7GmUDAVuVw8wVZUbj56DdCOlTM9p2LwfMt23hvMdW8eUe+D61FjAxQlyXBJ0v6+ErC/4flhlBeTbAKMEZZP6mK9fgTRdihi9YE4+5xfi0RIzey4WvcFpgtml4b/i/QNP4+bgpqIHPaHWJ/q/1kA2GO6+/cuCVTDmTkJ0rZcf3g5cioOJO8UBpiebv4nX234FR41zsevVxKM1jAoj1tcOE/3Wqb85Y4wxxhizbXkJ83efEnNKQaOGfC0O+t9WWFXCXDoVljdfkHp473t6DjVNauruCqSkwXAXxVP3yxh2BfqFq0UrUFWH5qaCqIwsUVnOGGPMxhPlK1asEBXklCA3o9YpU6dOxYEDBxAVFXXH56B/qFNTU63iH2xWlJu9J+rXCBGXTySVPrP4xivLsSTs/8TlJ5q/kTfx4L2a1OQlOGtcEZkajvWRywrcpqzrD2WjuqI3nXHboTs+lxSdAOPOw+Ky5sH+Yub4yqT0dIOWkuX2WsgR0dD/tRayUarUdbB10pmLkMIiAZUKp3o4YU/MRiihxHOtPhStV4pDiWo64PNKm8/hqHbGheRTohXL/kY3oXloqJh0kxLVoq1OZnbZJ+388W8xTFRWKbBjuD3eU/6EhMwYeDv44Ytu8zCk3oRSR26MDn5MnG8LiEC6MhsGHu7JGGOMMcZy0aSYmuG9TRXmVpYwFwUjq03zBan7doTSo8Y9PY9Cq4GGWrBQ8nr74btuyXkvpCvR0P/xr6nwpmUjqMcNzGsLathxmKvKGWOsAlRcw+QKcOLECTRs2BCurq4FlnfoYBoGdfLkSdSuXbvU56hfvz7S09Ph5OSEkSNH4ttvv4WPj88d+6LTyYwS7USv14tTZUmM3AOlPq5SX9MSWnl1FhXlx+L3optv8cnv/XFb8euZr8TlMUFT0b/Wg/f9uTgqnTGx4TT8du5rLA79GR29e8Pd3uv2Hfp0AMIiYTxyBnKvdlC4u+a9Zv7XpoS0tHSDGNqnaB4MqVFdSJbYZjXdoZw0HNLv/0I6Ew7dX2ugGD8IClWVOj52T4rbLpWJhmNKq7aLy9k9muKXyNniMiWkA52C77henX36oUHXJvjh1IcISzmNWcffxVH/QXh88kTYL9oG+XIUcn5YBOXjo6Bwcyl5Pa7FQVqwGkjLRLaLGnN7X8W+1D3itrY1u+O55u/DWVvjjuvT3L0D6rgE4VraJWz1v4iRB1wg924vWv1Upe3CisfbxfrwNqm624W3GWPMlpkT5ureHWDYfgjGfSfzEuao4wc3j8pPP9B6UBU4VYOb26fcK2XzYFE8RcUwhlXboH1iDCoKFV7p6HPTG6AMqQfNww9AoVRC2boxFFv2Q05KhnHvCaj7daqwdWCsqqIR2Ma9x6Fs3ABKH09Lrw6rYqpUojwuLg5+fn5FlpuXxcbGlvhYd3d3PP/88+jcuTPs7OywZ88e/PTTT6Kdy9GjR4sk3/OjVi8ff/xxkeWbN2+Go6MjKoM68xjsUtdBq/bBls01qXk3qqss+o8COBq7B2tj14oq3PxiEYGtWARZIaOR3BZOFwOw/uL6cnltCVp4wR/XjbH4avtb6IkHC9zezs0RnimZiFzwD0KDbx9gyT+hbGDUTYTEJEGvVmKvswTd+rKvWw6ycAxboYYW9dEcnvATbWXuh3eID1qdj4XyVBjiYmJwurE/ZOX9PWdVUZaJfitCg8jrCEpORZadGjOMK3EjOwEusjvcIupifUTZvw8dMQIOcMcp7Mae2I04IR/EwBYP4IFTatgn3EDmt/NxrHkA0p2LTkrsl5CKpmHxUMkyLnhlYHaT/UhJvQGFrEBb9EPThM7YnbCvzOsSiOa4priE9bXDMSS6ES7/uRzXarmjKm0XVjreLtaHt0nV2y6ZmZmVui6MMWa1CfMRfUwJ8x2HRcIc1+LQ/hogBZ6E3KNdqaMZywu1zDTuyB3lO6KPqAq/H7TO6lF9oZsxD9L5CBjPXYKqaRDKm5RwA7pflgHZOijq14Jmykgo1Kb9fyp6oqpy/d/rYNh5GKpurSt99DJj1s6w5YBoO6rYewLaNx+/798+sy1VKlGelZUlktyFUfsV8+0leemllwpcf/DBB0UlOk0K+vPPP+Ptt98u8bHvvPMOXn311QIV5VS5PmDAgFIT7OVJl9UZR1buBXISEOIbh/ptb7efqW6oP/iubcuRaUhHSOd6CHJrmnfbpZTzWHx4OiSjhE6+ffFyq0+hLOeDBk1uNcA7+x/DFcVZPNphGpp5tsu7TQ6JhvTLctRJSEPdKWNhcLQTO8z9+/eHRqMRPcml/QvFfbUj+qJfh7JPLEqtML46+ipiMiLF9fM4iACnuugeMBjd/QeKNhn3Sg6NgLRwLXyvp8P3pgTlQ0Pygq3qiCr68m+XyiS+A/sWiMtRw+vjQtIicfnlDp+iuVf7u36+B/CAaMFC1eVJWXH413kxVOMewYjNzrBPTEHXs3FQThoGRVAd0+tLMmSqMrkQJq7vap2OP9y3QCflwMPOGy+3/hwh7i3vej0M0gBc2H0QSYjDLt8r6H/TA02fGCQqW6rCdmEl4+1ifXibVN3tYh51yBhjDFC4OuclzHX/bYeS5rpZtQOGhJtQj+5X4fsjhlU7AIMRyuBAUQ1eHpQ1PaHq2R7G7YdgoPfUsC4UmvJLq0g3b0H3f0tFH3JFLR9opz5YJMnHVeWMlUxOz4Rx91HT5Zu3YNh6EJoh3S29WqwKqVKJcgcHhwItUMyys7Pzbr8bDz30EF577TVs3bq11EQ5JeeLS9DTTlJl7cBqNDUR3Pl1hO58H9FnFiAgeACcPcvnH3tro4EGLb074kDcNpy+eRiNvVuJ5THpkfjq2CvIMWahhVcHvNr2c2hUd9f6oSwaebXAwLpjsDFyOX4/PwOzei2FxtxTulE95NSvJfp+K/Ych+YB0ySd9D1Qq9XQ/7fDNDwuqA40XVqVuVLiws1T+PLwK0jVpcDT3geNPFrgSPwukTRfEj5HnJp4tkHPWkPQxa8fnLV3eYCmRSMYH1NDP/8/4Nwl4O91UE8eAYW6Sv0JuGuV+Rs1063bLQJyQ8MA/Jq1ADJk9K0zAm38TP0E70Xzmu0wq9cS/Hr6K+yO2YBl0X/iTJeWePZ8R3iFp0L6419oJgyGslmwqC6Rz1xEjtKAP3tEYQcO0VAJtPLuhJfbfI4adu73/Lsc0eBRzD07HWvrhKPPoQbQXIiEqmWjKrFd2J3xdrE+vE2q3nbh7cUYY8UnzBUTBuHCretoFHkdxoOnICXdhJb2R5wdK2wSTOnsRUBpqgIvzwp2df/OMB47JwpkqGJdPeDe4/z85NR06OcsBW6lQ+HjKeacUjgUzUOIqvIBXaBfxFXljBUmJtvN0QP0t4WS5jsOQdW2CbdgYWVWpZoVU4sVar9SmHmZv7//XT8nVYbfvHkTVYF3vX4w2DWCLBlwbufHkCQDqqvWNU3BxonE/eL8RlYiPj7wrEgkN6jRGG93+LZCkuRmD4c8hxpaD5GcX335rwK3qQd0FefGA6dEMGMmHT0HKTwSUKugHjugzMHYnphN+GD/0+K90USm03sswBvtvsa8gVvwXKsP0MyrnWi/cv7Gccw59Rke29wfXx95HYfidkBv1JX5PamaNIBm6mgx27t07jL08/6DrK++3yFLMJ6/LD5bKJVY1S5efH/c7bwwpckr9/3cThoXvNL2c7zU+lM4qJ0QmnIKb9X5Gwfa68UEPxQo50z/Q0wiGuucgQ/6HBJJcmpdNLHRNLzX6Yd7TpKbUcLfReuGRPs0HPaKhmHnkft+X6z6ka4nV8oEV4wxxhirOmjfKLKOJ5STRwB2GjHnju67hZDiksr9tWQqWvl3m7is6tYGSt98806VA5qnh3qxE6pWpSrw+yVnZEH3f8tE8l3hUQPap8eVehBBVJV7uwOZ2aKqnDEGyClpMO4z/R40E4dA2aS+2Fc2rNhssQmFWdVTpRLlrVq1Qnh4eJFhrYcOHcq7/W7QDyUyMhLe3t6oKsGFznUI1FpXpF0PxbVTphYf1TlRfjH5LOLSr+Hjg88iKSse/k6BeL/TjyJRWJGoYnty05fF5eXhvyEx83b/e2VwHSjqBgAGA+Rdx/KG9+hzJ29UD+wKpbdHmb5/y8PnYuaxd6CXdOjg2wufd/0dHvbeeYnRfnVG4tMuv+LX/uvwaOMXUdulAQySHgfjtuOrI6/h8c0DMOfU5wi9cbJMf/hVjepB88SDYiZ6KTRCzKJOE0+y+0cHHcwBeXQPf/wbt1RcfrL5W3c/AqAUvWoPxcyei9HQvbloT/S90z/4v16XkKXSA8mpOFA7Hu922Iprhii42Xniw84/Y1yjJ6EqhxZF9moHDK03XlxeFRgK6WoMpMiYcnhXrLqQYpOg+2Y+dN/OL5edRsYYY4xVL4rG9aF96VEoPN1EWwTd93+JXt/lybj3GOTEm6KiVD2wGyqCslUIlA1qi31CQ+5+4L2Ss3PExJ1y/HXA1QmaaeOhcHMp9THU/tBcyU5V5fQcjNk6w9YDYnS3ol4tMQmuelQ/U+7jchSkY+ctvXqsiqhSifIxY8bAaDTi119/zVtGrVjmzZuHjh07iupwcu3aNVy4cKHAY5OSih6pnjNnjlg+aNAgVBWyygUNOpoSuBHHfkVG8hVUR14OPqjjEgQJEt7eOwVRaREigfxh55/uuyq2rHrVGoomHq2RY8zGH2e/LTiJS25QIh86Da3OAHnNLnE0X+FfE6ped+5DrZf0+OHkR/j7ws/i+vD6j+DN9jNEIrI4Xg6+GB08BbN7LcPMnktECwyqVE7Xp2Lz1X/wv32PY9q24eL5qIq5NKqGgdA8OQbQaiCFXYH+j5WcLC8Hxl1HTP3JXR3wi+s6GGUDOvr2Rie/PuX+Wr5OtfB517kY2/BJUTG+C0fxTq89+L+uYfi+wU5kS1lo6tkW3/b8Gy28O5Traw+uNx52KntcdU7GGfd4ripneWgHTb9gFc47xOC8YzQMq3dYepUYY4wxZoWowlv70iOmRHOOXuyPGLYdKpeKTxrxa9hkGpWsHtqj2NYl5UHsE47uJ1q70IhO44Ur91xsI4qXrsUBTg7QPjMeSk+3Mj2Wq8oZKzR578HT4jL1JKffKP2WaPJbol+9A3KmqW0zY9UmUU7J8LFjx4rJNd98802RMO/Tp4+oCp8+fXre/SZNmoTGjRsXeGxgYCAee+wxzJw5U0zeSf3Jn3/+eVGF/vTTT6Mq8QkaDM/aXSEZdTi/82PIkhHVUeuancU5tSRx1rjiw04/o6bj3bfXuVf0h/WpFu+IyUIPxe/AsYS9ebcpG9WFoo6f6Efe8nws5JMX6AHQjB8Ihar0yt003S18cuA57IhaI5776ebv4LFmr5ap4pfWqV6NhpjS9BX8NmADPuo8B71rD4O9ylFMBkoV6s9vH403dj+CtRGLkZJTfFshVVAdaJ/KTZaHX4V+7j+Qc8rexoUVJCenipm1yebeOlxKDYWj2hlPtXi7XPsh5qdWavBQyDR82vVXeDv4IsGYiF0aU4A8JngqPu48J290Qnly1bqhf+AocXl1nVCxY0BBCbNttGOrX74Jp/Tn8VmrHfis5U6ERe6H8eJVS68aY4wxxqwQtRXRPDMOqi6tABkwrNtlmmvnPltD6mm+oBwdFLV9oWrfHBVJ6ecNVfe24rLh362QDXe37rLRKIoMpEvXADut2D+7mzYxXFXO2G2GzfsBSRK5GnEQLhcVMlLPf+pXTn9nGKtWiXKyYMECvPzyy1i4cCFefPFF6PV6rF27Fj16mCZVLMnDDz+Mw4cP46OPPhKPP3LkiEi27969G46OFTOBSEWhxFvjHu9CpXXCrcQzuHZ2Caqjdj6mbapV2ePdjrNRx7VBpa9DoGsQhtV/SFz+7cx0UV1euKrc41aWOFf1aAtlbb9Sny8uIwpv75mCszeOivYx73b8DoPqjb2ndaPEOk16+mLrj0U/81fbfIG2NbuJ5PullPP4/ewMTN08EJ8efAEHYrcVqdBQ1q8N7dNjRVBGwZkY7sfB1T2ho9N00CQp2BlL0v8Ry6h1T0UkqgujSV5pwlkaAeHnVAfvdfwBDzd+DiplxU3USiMgVAo1zrkn4rLzdRh3m1oQMdtl3H8S8aFH8UOT/ZAVsjj9X8ghZP63CbJRsvTqMcYYY8wKUYGRZswAqB/sb6rMPnYeup8WF5gH6m5IkbGQjpwVlzWj+0GhrJiClSLzV7k4QU5KhjG3LWdZyJIE/d/rTfMbqdXQTh19x33JO1eVH7/rxzNWHUgJN8SccUQ9uHuB2xRqFTT0N4b2WWgi4cjbbXUZqxaJcnt7e8yYMUNM4JmdnS2S3wMHDixwn507dxZJCv722284d+6c6G+u0+lw8eJFfPXVV3BxKb33l7Wyd/ZBw06mFiyXj/yEzFtRqG6aerYRExd+0fV3hHi0tNh6jG/0FDztayIhMxorL87LW65sXB8IqGm64u4K9aDS+99RH/G39kxGbMZV0Urly25/oE1N08Sg94tatnSvNQjvdfoev/ffiKnN3kCQW1NIshHHE/dh+tE38OPJj4pM/qmsV0tMFAN7LeSIaE6W3wNjeCSkU2GQlcDckGPiYEozz3boX8dUdV0ZqJ/9S20+xc99/0Nbn/L5TpXG29EP3QMG5VWVGw+d5mFsNkyKikPG6s2Y2Wwv0jU6MeGyh50XYh3TsNRxB4wHTlp6FRljjDFmxdRdW0Pz1DjAwV60IMmZtQBSVPxdPYcsydD/u1VcVnVoDmVg5YxEptYummG9xGXDlv1iMsE7oVyFYcUWSCdCAaUSmikjoAyqc2+vX6Cq/IjF9+WkxBtl+gwYK0+GjXvphwVls2AoaeR/IfT7UrZvJkav6GliTy7kYdUpUc5u8w8ZBY+ADpAMOTi/6xPIcvX6sVPVNk1c2MCtYBudykaV3481e01c/vfSn4hNv5a3fspRfXHDzRHKiUPE7Ocl2RO9ER8ceBppuhQEuTXB193/RKBrcIWsr5u9Jx6oPxEzeizEj31WYmSDSaKP9faoNXh//1NIzr5e4P7Kuv6iFx4c7CBfiYHul+WQszhZXhaywQjDSlNAvrebhNNpJ6BV2uHZlu9VWMsVazEqaLI4P+IVjTjVDRgPnLL0KjELoAMkuj9X4begg7jqnAJXrTve7vAtprV6X9y+vlYYzu9ZCTnDNPKGMcYYY6ykeZS0Lz8CRU0P4FY6dD/+DSO1tywj4+EzkCm5bq8Vvckrk7JtEyjqBQA6vWmk6Z2S5Gt3icpWKADNw0OhanJ/I6etpaqcWu7ppv+BnC9+g+HwGYutB7MtUnSCKFyj35N6cMnFi+KAFh2Mi00UE/4yVhJOlFdhogVLz/ehUjsgJe44os+tsPQqVVtd/PqhlXcn6CUd5p75Om/EAvW+O9qyNhSBxQ+To/stC/sNM4//DwZJLyZ3/LTLb5XSkoMEONcVLUDe7/SDqDoOSz6NN3Y/isspoQXuR0ddtdMoWW4P+WosdP+3lCuEy4D+gZUTbyLFTYEF2g1i2YRGT8PP+d4qQqoSaoXUzqc7ZAWwtvYFGPYcEwcOmI31JV+8Husdj2Cfz1XR9umNdtPFiBn6bvSuNUx8P+bU24OMjdstvbqMMcYYs3JKbw9oX3oUypB6oq2hfsFq6DfsEdXipZGzsmFYv1tcVg/sCoWLEyp7v5xavdCcVdLJC6XO0WLcehDGHYfFZfXYgVC1vv+iMGuoKqcqcv3CNQBtK4MBhiUboF+6AbJOX+nrwmyLYeOevANGNG9AafMiqB/omfuYvTzygZWIE+VVnIOLP4I6viguXzr0PbLSuN9SRQU/TzZ/W0ygeCLpAA7G3TnpQ21Ovj/xIRaHzRHXRzR4FG+2nyHapFS2VjU74+vuC0Ti/EZ2Av63byr2xmwqcB9lLV9onx0vZlunagyRLOcq0BLJt9Jg2LRPXF7Q6RLSDWmoXyMEwxs8AlsxKmiKON/tG4nk7CSxY8Bsh3HnEZyN2YdFDUytVaY0eRnNvEwTWpGpzV+Hh9oT8Y5pWJzwF6TYRAuuLWOMMcaqAtHK5IkHxQR8xLjlAPR/roKcU7CFZH6GjfvERH00YZ+qWxtYgjLAxzQxKa3Pyq1ios7CDHuOw7DBlNRTD+8Ndafyay8qqsqpGt8CVeVULKNbsNq0Dfy8xcEKqu41HjoD3Q+LIF1PrtT1YbZDioyBdD5CzHGgHlh6K1yi6tgCirr+QI4e+v+2Vco6sqqHE+XVQK2mY+Dm1wZGQxZCd31WpD87Kx/+znXy2k38fvYbZBkyS7xvmu4WPjr4LHZGrxVVls+0+B+mNH0FSoXlfnIBzoGi5Uvrml2gM2bj22Pv4O8LP0PK17KHAjzttAmAsyPk6ARTsjy95Pdpy/Rrdol/YI+FZOJA9hGxnZ9v9WGFTqJpbZp4tkaIRysYlBI21AqDYdeRSvv7I6qZN+7N7WEZVymvyW6TrkQjYet6zG6yH5JCRo+AwXggd+JjMxrF8mzbj8TlDQFhOLPuT/73iTHGGGNlqpDWUCJ5wmBApYJ0Jly0YpGTU4vcV4pLgnGfKTGsHtlXTBBqKWLOKio6SrhRJFltPHIWBnMP9QFdoM49EFBeRFV5f8tUlRvW7IQcGQPY20EzZaRIlGtoHizap4xJhG7mAhjPXKy09WG2w7DedOBJ1b45lNR+6A5ogl+aQFhMHnw6HMbzlythLVlVw4nyakChUKJJzw+gVNvhZswhxF74z9KrVG09GPw4fBwDRFX2srBfi71PXPo1MWnn+RvHRX/z9zrOxsC6Y2ANKHH1bsfZGF7fVPW8PHwuph95o0DSX+nvDe2zE0yzt1NgM4eT5YVJl6MgHT+PTLUOf9Q2VZVTL/h6NRrB1ozOPXi01f8yMuKjIV0y9fCvSKK343/bYdy83zT6Yc5SUU3AKgf9PUhfuBIzG+9FqjYH9VwbldiXnyaX7eszxNSCxXUNMk+etsg6M8YYY6zqUXdobhrxmptwFQUSV2IKxYTbRLsPZfNgqBrVtej6Kpwc8vqjU5W7nJouLhtPh0O/xNSmUdW9raniugIoW4dUelW58UQojHtM/Z41Dw3JS1aqGtaF3auToagbAGTnQD/vX+gpoc6TKLJyYgy/atr3VKnyWg+VhdK/JlQ92t0e/cHtgVghnCivJhxr1EaD9s+Ky+EHZyE7PcHSq1Qt2ansMbXZG+Lymoi/EZUWUeD28zdO4K29UxCXcQ3eDr74sts8UcFtTVQKFR5r9ipeaPWRaCVzKH4H3tkzBYmZt9v2KH29TMlyVyfIcUnQ/bwEclqGRdfbWlBwp8+dwHNx52jc1N+An1MdjGv0JGxRW5/uqO1SH1lqPbYEXIJx15EKfT2xQ7RyqykgV0AMsUW2DrpflokDGKxiyZIE3aI1mOezCxGuN+GsccVb7b+BXSktpR5r8xY84Y4Eh3T8dfxbDkYZY4wxVmbKerVg9/KjUPjXFK09aL/EPFEkVYRKF68BajXUI/rAGqg6tBDzWCFHBz1N2hkWaerdLctQdWgu1rO44oJyryrfUfFV5VLCDeiXbhSXVX06QtUsuOD6uLlA+9wEqHqakpLUm103Z0neAQTG7mufMHdeAlXnllC4u97V48XBKjcXyDdvwbD1QAWtJauqOFFejdRpNhE1ajaHUZeB0D2f8xD3CtLetwc6+PaCUTZg7rnpkGH6nHdFr8eHB55Bmi4FQW5NRU/wQNcgWKs+dYbj0y6/ws3OE1fTLuGN3Y/g3I3bsz8rfTyhfXYi4OoMOf46dD8t5qCGArz9J8TBg/M+KdiqMk3E82zL98VBFFtE7YTMvco31ApH9oWLImiuCDSRk+GfLTDuO2Ga1Xz8YGhffhTK4DqiDY7utxWisoBVHOoTujltG3b6XYESSrzW9iv4OAXccSTLc+1MLVg2ep/F6W2LKmltGWOMMVYdKDxqQPvCQ1A2bwgYjaaJIv/bBv3qHeJ2VZ8OUHrUgDUQrR0e7C9iVenoOeh/XynWWdmyEdTjBorbK1JeVXlWNox7Kq6qXM6tEodOL2Jx9eDuxd6PWuFoRvSBZvIIwE4LOSIaOd/+CWMljEJl1Zd0/jLka3GARg11v053/XiFnRaakX3zDuBU1P4rq5o4UV6NKJQqNOn1IRRKDW5c24e4i+ssvUrV1tRmr0Orskdo8glE4DSWX5yL746/B4OkRye/Pvisy69wt/eCtQvxaIkZPRaKSShTdSn4cP80bL66Mu92ZU0PaJ+baDramnjTlCy34dmhqaresGEvdEoD5jY9IZYNCBxdYAJDW9Q9YCC8HHxxS5uNPT5XYNx1tGKS5Ms3wbj/pNjx0EwYIobjiiBn6oNQhtQTgbp+7j8wXrhS7q/PTMMbzx9chT+DTDtdDzd+Hq1qli0wbe3fHf2dTJVeP6f+gczr8RW6royxypWSkoKnnnoK3t7ecHJyQu/evXH8eNkTNMuWLUOnTp3g5uYGT09P9OzZE+vWcRzLGLtNxHyTR4j+3sS4+xhAPcvdXaHu0xHWRFnHT1SWCwaDiFM1Dz8gKr4rWmX0KhdzBS3bKPYPqahK88gwKFSlvzdVy0bQvjJJTPaJtAzo5yyFYdtBEeMzdtf7hRv25rUyUrg639PzULsmZZMGgFGCYcVmLjRleThRXs04uddD/XZPicvh+75BTkaSpVepWqrp6I+xwVPF5b1YjeWXfsvrU/1Gu+mltiGwNpTg/KLr7+jq319Uyc859Rl+O/O1SPoT6jMnkuXurpCTkk3J8mIm0rEFhnW7RY+9lc0jESclwMPeG5OavARbRy18htd/WFxeW/sC9EfPlGtfexEMLdsI46HTNCkDNA8Nhap9M6TrUnHh5ilRSaB5fBSUTYPEzghV7hjPXSq312eAfCsNCUuXYlaTvTAqJXT265c3uXFZTe7+IbwMLkh0SMeCHR9W2LoyxiqXJEkYOnQo/v77bzz//POYPn06EhMT0atXL1y8eOfJ23744QeMHz8eXl5e+Oqrr/D+++/j1q1beOCBB7By5e2D94wxJqq1B3WDZtJwEf8RmvRTodXA2lCvcmrBQlXwNMGlQl15k4xWdFU5tUCUToYBSiW0k0dA4eJUtvWiIqyXHoGyXVPRiob2rfTzVkLOzC73dWTVl3Q6DHJsImCvhbp3h3t+HmqBpB7dT/wtEXOQHTtfruvJqi5OlFdDgS0nwcWrMQy6NFzY+xUfGasgIxo8Cn+nQMgKCUqFCtNavofJTV8WrSiqGkrsUwuFh0JMfe7XX1mKTw4+jzTdLXFd6ekmkuU07FG+kSKS5VJSMmyJdDUWxsNncMU5GWvcTQHnU83fEW0lGNAvcBScNTUQ75iOw+6RpvYo5dQTW790g/jsRZL84aFQtW2K8OQzeGnnWLyz9zF8feR1pEsZospI2cI0JFc/7z8YT4WVyzrYOurLn7nwP8yuuxUpdtmo7VwfL7T+6K77azppXfBs43fE5U12R3DqNFeLMlYdrFixAvv378f8+fPx4Ycf4rnnnsPOnTuhUqnE9bIkytu3b481a9bgmWeewcsvv4zdu3fD2dkZf/75Z6W8B8ZY1aJqFQLtG49B8+wEUalsjRTOjrB7ZRK0j42s9ER+RVaVS1eiYVi9U1xWD+8NZb2Au1s3rQaaiUOgHjsQUKsgnbsM3cw/IUXzaENWtv0Sw0ZTNbm6Z3sxge79oJZN5olAqZWTnJFVLuvJqraql9Fjd6RUqnNbsKiRFLkTCZe3WHqVqiWNSouXW32GQLkJ3m03W7TgqMoo6TW24RN4u/23sFc54Mz1I3hz96N5E5bSPyIiWe7pJia90H07H4Y9x21iuJxI1lJvbIWE31qfgQQJXfz7o6NfL0uvmtVwUDtiSL1x4vLqOqHQ7zsOWW+4/8998XpIR85SM3RoHh0GVZsm2H5tNd7d9wRuZptGzNCEtK/tmoiw1LPQPDocytaNqcQR+oWrYTzOlQH3y7BhD+ar1iC8xnU4qpzwdoeZYnvfi9aNB6G/0TQ8+qeLM5Cp43kPGKsOiXIfHx+MHn07DqIWLOPGjcOqVauQk1N6giY1NRU1a9YscPDN1dVVJModHKrOCD3GWOVSerlDFVTH0qthtSqiqpzaUOr+XC3ibHp+Vfc2917J27kltC88bCrEon3L7xfBcOAkF/mxUhmPnTO1/HFyyJsk9n6pKOHu4ykmCxYjyJnNM41XYtWOi2cw6rWeiohjvyBs39fwCGgPrYO7pVer2qnr2hC9MRbNvdqjuujo1xtfdZ+PLw6/gvjMaLy1ZzJebfsF2vl0F7NJU7Jcv2itGJ5k+HerGPqknjBYVJ1XJ7LBCCkiSkwUIiYLuZ6CdfUu44oqFs4aVzzZ7E1Lr6LVGVpvAv67tABXXJJxTn0FrY6dg7pTy3uuFtD/vQ7SiVAxrJOS5HLz+ph7ZgbWXVks7tPet6do+fLTyU/Ed5WS5w+FTMPIhyaZKlSOnIV+0TrRd45atbC7Ry1stp5fjK0hl6CAAq+0+wL+zve3Uzql96c4uXk0kuxT8efODzBtwMxyW1/GWOU7ceIE2rRpA2Wh3rsdOnTAr7/+ivDwcDRv3rzEx1OLFkq2U2X5sGHDkJ2dLS5T+5WXXiq5vRkl4PMn4SnhTvR6vThVBvPrVNbrsbLh7WKdeLtYQN+OwOINMOw8DKlTcyjs7e55u1BsLi1YDaSmA5SAH9UXBsP9FcXA1xOKFx6CvGwTEBoBw/LNMF6OgmJUX6tsp1NZ+LdSyv75pn3isqJnOxioL345fUaKkX0g/7IcxoOnILcJgSLQv8h9eLtYp7Jsl7vdZpwor8bqtn4MiVe2I/3mRYTt/RrN+39l6VViVUSgazCmd1+I6UffwPkbx/HFoZfxaOMXMDJoMhRuLtBMmyBaaxjW7RIJc92MeVAP6wVV51YVPpN7RZJT02E8HwEp9DKk8Egg5/Yf1DinDPwTeFpcfqzpq3Cz97TgmlonVzt39AscKVr3rKoTiua7joqJjO72OyFT6xQ6GJPb+5D6UGY08saMg8/h7HXTRKHjGz6FcY2eEq2Ovu35N345/SV2x2zAX6E/4kzSEbw44hO4qJQwHjwN/ZL14jnvNWlvq6i658KqBfijiekzn9DoGXHA7H45unnhWa+n8XH6t9icvRNdoveiZa1u5bDGjDFLiIuLQ48ePYos9/PzE+exsbGlJsq///57XL9+HS+++KI4EepXvm3bNnTu3LnEx3355Zf4+OOPiyzfvHkzHB3vbdTLvdqyhUdvWiPeLtaJt0slkmV0ddTCOTMHYfOWISLQ8563S3BEEupH3YRBpcDBQFdkbNtafuvprUa9bC8EX7kOHA9FathlnGwSgExHLWwZ/1YKqh2TjCbJqcjWqrAnNR7S+vXl+vzNfFwRkJCKlD//w8G21GK3+H1Y3i7WqbTtkpl5d/OncaK8GlOqNKIFy5F/JyMhYgt8IgagZv0+ll4tVkXUsHPHR53nYO6Z6dh89R8sCP0e19Iui17sWpUd1N3bQNm4HvRLNkCOiIbhny2m6vLxg0WblqqA2sbIUXEwUtV4aATk6ISCd3BxgqpxfSga18cfqTOgS9ajpXcn9K49zFKrXCV692+MXIGzHgm4HHERjcKuiM/wrpLkC9dAOh0OqJSi7/i12hK+3P0IkrLiYK9yxEttPkEnv9t/yxw1zni5zWdo7t0ev52ZjlPXD+HV3RPxUs9P0UzV2nRQhypVDEaou93bEFFbrNhI+msJZgZtg0EpoX3NHhjT0DSBcXlo2XMiBvy1GZvdz+DHYx9gts9qsR0ZY5afmFOn05XpvnZ2dmL4fFZWlrhcmL29vTin20tDSe1GjRqhVq1aYgLPtLQ0zJo1S7Ry2bNnD4KCgop93DvvvINXX321QEV57dq1MWDAANG6pTJQhRLtmPXv3x8aje1WP1ob3i7WibeLZUgBFyAv3oDghDQ0mjIOCge7u94u8rlLkHaZ5v7RThiCnjQnUAWQaULFv9fDJT0T3U/HQDmmPxQV9FrWjH8rRck6PaTp88RlhyE9Mahz+RdAyT0yIX37J1wzsjHQ1Q/KQq2FeLtYp7JsF/Oow7LiRHk15+rdWEzuGXlynpjY082/DbT21atFBqs4GqUGz7T4H+q6BmPu2RnYGb0OMelX8XaHb+Fh7y16A2qfnQjj3uOm6vKL16Cb8QfUw3pD1bnlXU/2VxnkrBxIYVdgDKXK8QjRiyyPAlDU9jMldhvXQ4TTDRxO3IXD8X8gKu0y7FT2mNbiXat8X9aipqM/uvkPENXda+qEImjnkTInyik5S33FpTMXAZUKmsdG4kCNS/hh78fQGbPh61gL73SYhTquDYo8lrZJvzoj0ci9Bb45+jaupV3Cp4eex6jGUzBG3RqKXSdgWLlVTPRJE7+w0mWv2Ybv3Fbipn0W/B1q46W2n5brRMUKlRKPdnwHJ089iUSHFMw/+hWe7fxZuT0/Y+ze0CSavXv3LtN9Q0NDERISIvqIF9eHnFqokDv1GR87dizUarWYzNNsxIgRCA4OxrvvvoulS5cW+zhKzheXoKedpMregbXEa7I74+1inXi7VC65bVPoth0SfZ2Vh07nTfJZ1u0iJSVDRwUnopdzO2jaNq24lQ2pD/n1KdAtWC0KsaRF66CKToD6gZ5QqFSwNfxbuc2w9wSktAyAWsF2aQ2FugK+D+41YHigpyiwkjfvh7p1Y9F6tjDeLtaptO1yt9uLE+U2oF7bJ8WknhkpVxC+fyaa9fnE0qvEqhBKQA6uNw4BznUx4+hbuJhyFm/sfgQvtf4ELbw7irYa6h5toWxc31RdTjOhr9gsKoI14wcV+49LZaIJYSgwNPcal67EiAlo8throWxUT6y/sWEAzuacx+H4HTgS+jGSc67n3U2lUOPJ5m/Bx+nuZna3RaOCJotE+SHvaMQePos6Mb2gDPAp9TGywQD9n6shnbsk+osrpwzH31iPlcdMlQOtvDvhtbZfwVlb+veptkt9TO+xAH+c/VaMhFh5aR7OebTEi31GwGN7OAyrdpgqy/t2Ktf3XJ0YT17Awtg/EFo7CfYKe7zdaRacNC7l/jrOISGYduRBfOywAFuS1qNzwhC09il+541VDkmWIMlGGCUDjHSeeyq8zHzd29GvQr4bzHIo8T1vnunv7p2YW6vQObVfKcy8zN+/aJ9Ps4iICGzcuFH0Ms/Pw8MD3bp1w759pl6kjDHG7o1CqYR6QBfo/1oLw86jUHVrW6SqvLQqXv38/4BsHRT1AkTCusLX19UZ2mkTYFi/G8Ydh2HcdRTS1Thop46GwokneLZFcnYODNsPicvqgV0rJkmei9qGGg+fhRwZA/1/26F9bGSFvRazXpwotwEqtZ2pBcuqxxF/cR18G/SHV+D995lltqWFdweRgPzy8CuISovAhwemifYX1K+bqoiV3u7QPjdBzKpOgQ31+M6Z/gfUw3tD1alFpVZhU9LV82YGpFU7oLtwRfRazo9mgFc2aSCS4+m1nHH8+gEcjv8TJ/cdQLbx9hBxavPRxqcrOvj2RJuaXeGirRotZSytbo2GaFuzG44l7sXa2hfw1K6j0D40tPQk+fz/IJ2PANRq6CYPwOzU73E80ZQgGdlgEh5p8gJUirIFRaLyv+W74jv788lPEZZ8Cm9qIjCt33i03Zpums3cYIRqQBceHVCIlHQTO7f9jA3B4eL6S+0+EwcfKkqLIVMwcPkhbPIPw89HP8R3A1Zy4vU+UBI7Ofs6kjLjkJgVK86pZVFiZiySsuLFyAyR7JbyJbxlUwJckoyQkO8gYhnQ38j/dZxVrSa0tnW+vr6YMmXKXT2mVatWokUKtW3JP6HnoUOHRFuVhg1LHjafkGBqeWY0GosdSnvfE8UxxhiDslUIFJv3i+Ih495jJVaVFy420q/YDDkuCXB2hHbS8Eqr6qaRh5phvaCsGwD94nUiaan7bQW0z4wrdkJSVr3RwRJkZIl9eFVFjmgQB5YU0IwZAN3M+ZDOhIsWraomRUczs+qNE+U2ooZPc9Rp/hCunf4Lobs/R6dxy6Gx42QEuzt+TrXxVbf5WHThJ9GH+mDcdhxL2Csm+RwdNAX2ageoe7a7XV0eGQPD8k2m6vJxAyu0ulzOyBKtVIxnL0K6cAXtdHrIiDbdqFJBGVQHyib1RYI8wS4Vh+N34XDCIlwIPVkgOeRpXxPtfXuK5Hgzz3bQqGx7Epl7NSp4skiU7/a9gjGHj8PnVg/A0dSvNj9Zb4B+3n+QLkQAGjUSHumAr+PfQ1zGNWiVdniu1QfoUWvwPa1DV//+CKrRBN8ee0eMhPgGczGwX088tL0msGmfaYLPwd05WZ5vW1xcPBe/1j8gro8JerxAL/iKoPR0w8O1p+Jk+idIcLiBeWe+xfNtPqrQ16zKqIr7RnYiEjPNye/853G4kRUPg1z+iUWlQiUOVNHIGpXSdJmS6xn6NHx26CW8034mWtXkURq2asyYMVixYgVWrlwpLhOanHP58uUYNmxYgfYoly9fFucNGph2Oqn/OCXXqb3K008/nff3ODo6WiTfqaqcMcZY5VeVGw+cgnT0HA0vhoaS5DUqP3egah4Mhfcj0P34N+RrcdD/8S80T46BQsNpLFtB+/iGXUduV5Oryq8VZEmU/t5Q9WgH484jonUn5REUWm61Ykv4L4wNadDuGSRF7kJWahQuHpyFJj0/sPQqsSqIJtyjFiQDAh/E72dn4Mz1I1ge/hu2X1uNKU1fRlf/AVDW9ID2+Ykw7j4Gw/o9oid4DvUuH9EHqg7Nyy0xKV1PFq06jGcviZYvkOS827K1aji0agx1syAgqDYuZYaL5PiR01+Kivj8qAd7e99e6OjbE/VrNObEaTlo4tEGDd2bIzz5DDb6XcDDe44DA7sUHc45719IYZGAVoNT42pjdtQ7yDJkwMvBF2+3/xYN3Brf13pQq5zPu/2ORaE/YtXlhdhk2IWwXrXx4oHm8Nt60NSGZVgv3uY0ycmqdfjWZw10KiNau3fAhMbTKuV1nfv1wDM/9MInwWuxLXo1utTqL0ZwVGWmqm2q1DZAL+mLvWyQ9DBIBhhk0zJKcNN1upyjz0Y4jiMtPAo3chKQmBWHpMxY3MhOElXgd0pqezn4oKaDv2iNUtPBT5x7O/jBQe2Ul+gWSW86V6rzJcKLXqfLxf0+dMYcTD/6hjhY+sXhl/FW+2/Q1oeTmraIkuOdOnXCY489hvPnz8PLyws///yzqBL/+OOPC9y3b9++4jwyMlKce3t74/HHH8fcuXPFbTSBJ03mSY+nSUBpwk7GGGPlVFW+5QDkhBt3rCqXrsXB8O82cVk9tAdUQXVgKUpfL2ifGgvdnCWQLl0T8xlpJo+wyZ7ltsiw47Cp9Y9/TShbhlTa61JSntpR0sh0w9YD0AzpUWmvzSyPE+U2RKVxEC1Yjq1+ArEXVsGnwQB41uIKMHZvAl2D8HHn/xNV5fPOzRQVjVS5uyFyOZ5o9gbq1WgEda/2oopbv3gD5KuxMCzdCOlUbnW5291XJciSDDkqDkaaeZ2S4/G3e4gThZ83lM2CIIfUw7ZTBxDQ3h7Hry/B0V17ivQbb+rZJq9ynFrHsPJFiTUaZfDVkdewJeAShh8+DOde7Qomyf9YCSn8KiStGmtHGLEk+kvIkNHEsw3eaDcdbnYe5TYp7ZSmr6C5Vwd8f+J9ROqi8E7HREwNbYXuOykCM0I9sq8YamerfOOT8b3dUiR5ZMBH44NXO04vc6ub+6Ww06J57wkYdDAcG2qH46fjn+D7viuqTAuWczeOYdHp2YhMvwwDctuY3GULk2LR19FUfFuAWqmBt4Pv7US4o7/pujj3ExMtU7K7PNHwa+j0QI4OcrZOnKtydHiz4UeYqfgch+J34KvDr+L1dtPR0a9Xub42s34qlQrr16/HG2+8ge+//14kuNu3b4/58+ejUaNGd3z8nDlz0LJlS/z+++95iXF6/IIFC9CjB++YMsZYuVaVL1xTalU5VfDq/lxFPbGgbBYMVe8OsDRlHT9opj4I/a/LxT4gjVzWTBxq07G7LZBT02Hce1xcVg/uVqnbm/ZPNKP6iaIu6pWvatME8OQ2rLaCE+U2xt2vNWo1HY/oc0sRuutTdBq7DGqtk6VXi1XhZGhn/76ij/eqSwvxz6V5OH/jOF7f9TD6B47GQyHT4FrTE9oXHjINXdq4V7TYEL3LR/aBqn2zO1byUjsI6eJVERQZz18CUjNu36hUQNmgNpRNg0WC3FDDHkcT9mJ39GwcVeyG4Zg+766Oame0qdlFJMepWvVOk0Ky+0efNU0CG5MeiW3u5zH82PnbSfIFqyFdvIZsB+D/+l/GoSRTu4/Bdcfh8WaviWRgeWvr0xWzei3FrOPv4uz1o/i58SGccU/A4wf0cDIYoB4z0CYDbjrgdFa/BWf8EmAHLd7uMrvSfx/KNo0x4cAgnMiMQzySxGSsL7S27hYs11IvY+G52TiatPeO91XICqhzq7jVdFJpoFJpoFZqoVaallFy23RZI6q4U67fQkidZvB1rpVXFU7JcDc7TygVdx52KhslkdA2JbdzCiS5ZVqe/3K++xS5nzjpKVte9EVUSrwy5Sn84K/GvtgtmHH0TbzS9nPR9ojZFnd3d1EVTqfSmCvJ81Or1Xj++efFiTHGWMVRtmxk6lVeQlW5LEmiPQuSU6HwcoNm4hCrGXUpqtonjzCNRj12HgZ7O6hH97Oa9WPlz7DtkCjUUNTxE+1TKxvlF5RNG0A6dxn6f7ZA8eSDlb4OzDI4UW6Dgjo+j+vX9iA7LRYXD36HkO7vQFGGnW7GSps8cVyjJ9G79gNYcH429sZuxqarK7A3dhMmNpqGQXXHQN2nI5RNg6BfvF70mDMs2QDpdBg0YwcW6Xkn+o2fvyxaqlDbFlHJmPdiWigb14OKkuON60OyV+P09cPYc3UmDsXtQKYh3XQ/BfUb9xEV4x18e6GpV1tRWcwqDyXzRgVNxo8nP8b6WmEYtPcIVCG+kOb9B0REI8E1BzM7H8e11KsiUfhUi3fQP3BUha4TVdt+1HkO/gn/A0vDfsEe30hcdr2BF8+ko55Rgmb8IFFxYyvkrBwcWP091tYJFdefa/2RmIy1stFOjvPIQXjm93P4uNU2bI9aLQ7CtfOxvomnb2QlYnHYHOy4tkZUjitlBfrENsBAQ0fYZ8hQpWZBZQTUkhJqSpBLStD/iuXkIEbX0N9ARQ1n00ibGi6QnB2wN/IYurl0gsogATd0kGMokX0VUvZFGEWiOycv4W06z02GU1KbLusrYBJE2he105pO5FY65D/X4cUnnhYHAXbHbMDMo+/A2MZwz3MLMMYYY6wyqsqPiKpyqG/HKMYtB0z7Xho1NFNG3rGPeWVTNQ0CJg6F/u+1MO47IeY/0gy2vliR3T85ORXG/SfFZfWQHhY5IEKvSVXlORevQb4cBRw37S+x6o8T5TZIrXFEkx7v4/i6aYgJXYnkuGOo3XQC/BoO5epydl+o4vG1dl9h0I2xmHtmBiJTwzH37HRsvroSU5u9jhY+HaB94eHb1eXnTdXl9A+QItA/t9/4RchXYgpWL7q5iMBIHNVtUBuySokLN09hz6VZ2B+7Fam65Ly7UnK8i18/yBGOeLTXVGi1PBmnJfWoNQR/h/6Mm0jCXs0pdD2aDeQYcNrnOn5odhDpOelwt/PCm+1nIMSjZaWsE7UUoQM7Tb3aYNaxdxGLRLzfdgseuXQdAxcZoB0zELDXVvsKFenmLZz/6yfMqW3qQTksYDy61x5ksfVR1vJFk5C+GBwdjfW1wzDn5GeY3Xu51Yz+oIkr/700H2su/w2dlCOWdUiqhfEJHRE4Yrxp5y23RRQyMiGnpEG+lZZ7ni4uI98ykcjOyBIHBuWYxCKvRzVe0rGr99/EhXp40vfZnOC2tzNdttfcXmaXe3vebfmW0XnudZpLwPy7oMlw9fP/E1U20h+r8PzTT4uK+O1Ra/Dd8fdEv/U+dYbd79ozxhhjrKKqyvccA3q3F8vlsEgYN+8Tl6mQSelfE9ZI1baJGAVn+GeLSOxTMl/dy/LtYYq0rDMYTbGeTi9GSEOvB3QGyHQurptvy70ubjPdT8rRoVFUIuSoeKB+bdgiw+b9pvY/QXWgahhosfVQeNQQIy8M63ZBXrcbmpYBFlsXVnk4UW6jPGp1QHDnVxFx7BdkplxF2L6vcenIj/BvNAK1m46DYw3b/IPMykdTz7b4pucibLn6L/6+8DOupV3ChweeQSe/Pnis6auo2ZeqyxuYqsuj4qH/e12R5xATdjQLEsknRS0fsSzi1gXsCftBDPG/nhWfd19XrTu6+PdD94CBCPFoBaPBiPUR66t9orMqoCr+4UGPYv65mVhT5wJ6xtfD2noRWBx4HJJRQrBbMzEJoKdDTYt8T2f2XIwfTn6Eowl7MK/hMZxLSkC3WVuhggpqrT3UdvZQ2TtAbecItb091A5OUDs4ms6d6LIz1E50coLKyRkatbbEyQ+tiRQZg4P/zMb39XcgR2VELUMgHmr2oqVXC+oh3TH+q3M44RmLOCTh97Pf4KU2n1h0nfRGHTZGLsfyi78jTZciljW65YWHLrdCSP2u0Lw0AAonh7z7i/Y9Lk5QuDgBtX1L3oHKyimUTE8DxOV0SCmpyLmZAjsXZ1M1V75kdbEJbfvc+xS3TF0xveZpEi3NpBHQ//6PmGvA+Nu/mDbtGdE2iQ6O/njyIzFR6YDA0RXy+owxxhi7z6ryXUeg7NQC9tl6SEs2ADKg6tIKqnZNYc3UXVuLOMqwfjcMq3eKuEjdqXIKbgqTrifD8N92SHFJplHQ5qR4MR3r7kZdeu4fFyOnlg9UXVtD1boxFFrbGB0tJd2E8cgZcVltBSMGVL3awXjsnGhX2TAiyRTHs2qNE+U2LLDFwwgIGYm48LWIOrsUmbeuIurM34g6sxhedbqhdvMJ8AjoaPUJH2adqGqXWq5Qr9olYf+HjZErxMSfxxP2YUTQJDwYNAXaFx+BccchGDbtE8GE6DcueoEFQelhmiyD+lvvCftFtHOhy/l7jnf06y2S4y28OhSYvM4Io0XeMyvegMBRWB72K+Ic0/BBm22i1QnpU3s4nm7xDrQqyw3rdLVzx/86fIe1EX9jwbnvcNg7WpxKRHFRZu7J9DaKpZKp7YZK9KUO1gbh+Z4z4OloOuBjacbj57Fpxw+YG3QYskJGK7f2aJrcr9wngLwXlFx2HNADz+xIwEett2Fn9Fp08e8r+t1XNkmWsC9mMxZd+AkJmTFimX+mKyZeboG2WQ2gfXCA2Gm5F+LfVUd7KBztAX/vIrfr9XrsXL8eQ4YMgUZjvTtFChqa/dgo6H5dLkYCGX5dgaeeMyXL119ZijmnPoNB0mNIvfGWXlXGGGOMFVNVLu86ilbnYoDMHChq+4p5pKoCVd+OkLOyxUSLhuWbRIGAqlVIpb0+JUuNB06aEvX524QWRgUUFMvRqDyNWrS1ESdxXZN7WZ3vsgaSUoGY0+fgfyMTcnQCDEs3wrB6B1TtmkHVtRWUNT1RnYncgCSLNqvKepav4BbFIWP6Q/fjYtSKvwV5xRbI1D6WtherlnjL2jhqtVK72XjUajoWN6IOIursEtyI2id6mNPJya2euN2X2rJoHC29uqwKctHWwJPN38KAwAfx+9kZOHP9CJaH/4YdUWswuclL6Np3AFTd24p/DM198JIy47D30n/YG7NJVJGbaZV2aOvTXSTH2/p0s2iClZWdg9oJg+uNx4qLv4skOVVcP970NZE8s4YDcbQOwxo8jMaerbEs7Fek5iTDYNDBYNTBaNSLRJ9RMohWEkbZIA7EGGQjjApJXJaLeQviNoWEHOhxUn8Wr28agzdaf4kmdbvBUiigp8Bzafgv+Cf4nFjW238onmz+P2zeuBnWQtWtDRodOIWhUdFYW+cC5pz6XIwUob8lleV00iEsOP89Lt8y9SJ0MzhhzOXG6BVfH5rGQdCMGwSFq3OlrY81oyp27RNjoJuzROzM6f9vKR5/7klolFqsurwQv535WvyGhjd4xNKryhhjjLFCVeXyjsMQEZajPbTUl1xdNVJEFL+rH+gJULL84GnoF60VI+lUjetX+GvTSED90o2mfu60Lg1qQzO4G+Bgny8hTslxtUiy3i0qmDijT0atnr2hPB4K44FTkG+kiFY5dFIG14GqS2tRYHYvz2/NqDJfOhFqNdXkZsr6taF4oCektbuAo+egS7hh+r24W0eLSFa+qsZfQVbhaDJPrzpdxCkj5Sqizy1FbNgaZKRcwYW9X+HS4R/hHzJStGVxcLX8Ub3qiJJYiRFbcfnIHNi7+KFh51fg7GHqeVsdBLoG4ePO/yeqyuedm4mkrDh8e+wdbIhcjieavQF3e2/sv2JKjofeNE3cQWiCuJbeHUVynCbldNRwcqoqGlp/IrZe+w9Z2Vl4q8MMtPbtDGsT5NYE/+v43V0/zigbYdDrYMzMgD4jDcaMdBjocmYGUlPiMefW74hySsEHJ1/CY1cnYXD3F6Cs5AlDqedh9pK1+C3zL+yoGyGWjQmeiodCnoXBUAGTPt4HCvjVI/ti7NwkHPeKRSyuY+6Z6Xi5zWcVfmAl8lY4FoR+jxOJ+8V1B4U9HrjaCEMig2GvcYR6XB+oOjS3igM81oQOcmqfHgfdT4vFsFT9/y3DpOceFz3L/7k4T/zNpwNNo4OnWHpVGWOMMVa4qpz2uSYOqXJJP5EsHzMAcrYO0skLYu4UxdPjoKxfq8L216Vj56H/d6to/QK1GuqhPUTRl2i9V86otZ+6T0eoenUQSXma3FI6fxnSxWviBFcnqDq1FG1nxITw1YBhw17TSPOWjaDMbb9qLZTd2+DI1ctodylJtI/NmbUA2knDRR91Vr1wopwV4eQWiEZd30SD9s+KZDm1ZclKjcK103/h2ulF8K7bA7WbTYC7f3tOFpSTjOQrCNs3HTdjDovr1Abn0IqHUKvZeDRo+xTUdtXjHz76vnT274s2Pl2x6tJC/HNpHs7fOI7Xdz1MN0KSTS1TFFCgiWcbkRzv7NdXtMdgVZubnQe+674M27bsQDPPdqhubYZUWgeATm5eBW6jw4pfJvTGj9texUHncMy99Scu/XMKzwyaBTuXyqmQltMykDp/GWY7/4MTfrHi90UtbwbWHQNrpQqpB/vGDTEtNAUftNmK3TEbcDxxP2o510Utl3qo5VwPAS51xTlNIkzb4H7QKJa/L8zBruh1kCGL5+uX1hKjTtVBDb29CIDVEwbntYRixe/MaZ8ZB92Pf0O+ngL9L8vw0HOPicryJWG/YGHo96KynCbSrSyXU0LFazbyaFFpr8kYY4xVmary4b2h/3MVwmq5oakFJ0y83/eheWgo9JQsvxAB3dwV0D47sdyTrHJ6JvTLN0M6E2563dq+4nWVPhXfBoWS8FQpTyc5ORWGA6dgPHQaSM2AcfN+GLceEK1LRZV5cGCFJO0rg3QtDtLZiyIvoB5kuVG4pbnh4QTlC/0h/7UOcmwidP+3FOrhfaDq3oZzY9UIJ8pZidRaZ9RpPlG0XrkRtR9RZ5bgRvQBJEXuEicn9wYiYe4XPBgqze2JzFjZGXQZuHLsN1w7+zdkyQilSos6LR5FRnIEkiJ3iJ7xCZc2IqjDC/Br9ICo/K8O7FT2IlnSu/YDWHB+tug/TkeOqaK3W8AgdPMfYJHJHVnFotEANEmmrXHy8ccb4xbh382fY5F+FXbancS1dWPxZosv4dOkbYUPX7w+7y9Mr7MOl11vQqvQ4tV2X6GjXy9YOwo6g6ZH4uHLLfF30Gmk62/hQvIpccqPWjL5O9cxJc9zE+kBzvXEMvpbU5p0XSr+ufgH1l1ZAr2kE8u62HfA2AP+8L1lL3pFqkf1hKprmyq701GZqB2NdtoE5FCyPCkZ+l+WY9yzk8TIIOr1vjhsjpjgc2KjaRW2M0HbdHfMemy9ugpXUsPQxKM1Pu/2e4W8FmOMMVaVUeJV+vR5XF2/HtY9fWfpaOJyzZQRpjlTIqLFufb5ieXWy9t49iL0yzYB6ZkAHWAY2AWqPp2gUFX+vjlV/WuGdBetcyhpb9h/EvLlKEhnLoqTwstNJMxV7ZsVmGy+KjBs2CPOlW2bVMoBiHul8HSD5sWHTe13ToTC8N82SNHx0IwZYDMTrlZ3nChnZWzL0k2cqPI56twyxFFbluTLuLDnc1w6/IOYFLQWtWVx8bP06lYJNGwr4fImXDzwHXIyk8Qyr8AeaNjlNTi6moaK3Yg6gLD9M5CZchXnd32M6NB/ENLtLbh6N0F1QZWgr7X7Cg+lPyu+Z75OFTNMjjFLU6pVeHDIB6h/th1mhn+KCMfrePP883j14uNoMeSxCpkMxhgageili/BVyBbEO6bDRe2K/3WajRCPluX+WhVB6e0OVc92GLrdiAHZ7ZA0tg1i7JIRk3kV0elXxOS+MelXoZNyEJl6UZzyo8r5mo7+IoFuSp7XzatEt1c5iMkmKUmerk8V92/q1goPRbZG/ZNZpscH+kMzcQiUNT0s8v6rKtqB0z4z3lRZHpckdlYfnPaIqCyff34WlofPhd6ow6QmL5VbspwmXj17/Qi2Xlsl2nuZD3rQpKIe9t6iqpwuM8YYY6x6ogSlduqDeXOm6P5vGexeePi+2snIWTnQUxL0yFnTa/h6marIraAlCB0coEnl6STFXxdtWYxHz4pRfTTxp2H9Hihbh0DdpTUUdXytvtpZomR/WGTugYiuqArfN80jD8BYxxeGNTshUd/y+OumvuU8ArXK40Q5uytO7vVEspbaslCyPOrcEmSlxuDqqQW4evoveAf2REDICHjU6gSlindKi5N+8xIu7J2OlLhj4rqDay006vI6vAILTlbhWbszOo1ZiqizixFx7DekJp7F4ZWTxEGJBh2eg9ah+rQj8XPmvl7MNrRuNgQzAprg613PIVIbh0/k/8Mj889i+JB3oQoov1EUhj3HEbZ1GaY334VUbQ5q2vvhgy4/iWRxVaLu10kE/Zrr6fCfsxv+KhU6+HpCGdALioCakBt74bq7ATH6WESnmZLndE6JdEqAJ2TGiNOxxL0FnpeStuZkam2XBnjEfjSar0+CIiMLUCnFcE/qB2mJSqHqgA5yaKeNN/Usj4qHbu4/GP7UBJGsnnt2Ov67vEBUlj/e9PX72nG7npUgJobedm2V2M5mgS5B6Bs4Ej1rDYGr1q2c3hVjjDHGrH7OlKfGmg7WJ94UbTG0zz8EhYvTXT+XMfwq9EvWAylpohWIqncHqAd1tcrJTpW+XlCO7if6pRtp8s/9JyDHJIoEv+7IWShq+UDVpRVUbZtWSHHO/ZKuxkG3cI24rOrUAkpPt6rTI79neyj8a0K/YLU4QEN9yzWThkMVXLmtjOSMLBhoslfa3g72UNLBkTp+UNbxg8LHi/dp7pL1/UpYlaCxc0GdFg+JtizXr+1D1NkluBlzSLQLoZPG3g0+DQaKtiyuNZtZ/RHMymDISRMJb/qsZNkIpdoOdVs/jsAWj0Kltiv2MXSwIbDlJPgGDcbFQ98j/uJ6xFz4FwkRW8XBioAmo6FU8s+YsarE170uvnpgBX7a/Rb2pO/FAp89iFj/DJ4Jeg2OPbvcV4sP2SjBsGo7jp1fi+9a7UeOyoB6ro3wfqcf4G5fsH96VaCwt4N2yigY1u2CFJMIZOeIwN9Il3PRIUMPLze0CPCBMqA/FAE+ULTwRqq9Pjd5bkqcmxPpSVnxIknuaV8TE+o9gW6HNMDxMNPr+deE5qEhUPpz66fy2GnTPj0Wup+XiGHQ+nn/YsjUMWKCz/87/QXWRiwWE3w+2fwtKO+irZhe0uNo/G4xOfDJxAOQIInljmpndAsYiH51Roo2Xhx3MMYYY7ZH4ewoRrbl/LBItIHT/bIc2ucmiORhWcg5OhjW7oJx34nbbTYoNqxn/SOfFXZaqDu3FMlm+WocDPtPiElOKYFrWLYJxj3HoZk8wqpGSxqPnoN+2UbAYITCx7NKVJMXRklx5SuToJv/n/isaVJ7eVgvMTK2ouNROSUNhl1HYDxwCtDpTcuSU2GMTQQOnjbdSasR+0eUPBeJczp51OBYuRScYWP3RaFUick96ZSeHIGY8ytFSxFd1k1En1sqTo416sA3eLBI9jrWqA1bbLMSf3EDLh78DrqsG2KZd93eos1KWVvV2Dl5o1mfT1Gr8Whc2DcD6TfCELbva8SErkSjbm/B3a91Bb8Lxlh5slM74JXesxEc+ifmX/wBe30iER37AV6bOw4BYyfe0zBROTtHVDPsSNmGX5sfgaSQ0dKrI97q8A0c1HdfSWMtlHX9oX1uovhbKt+8ZaqQiUnIO8etdDHMlE7SKVPCm9i7OKFhQE00Egn0ZlAE1YTC0x3ZUhauZ8XD62oOFIu2i4mQRKVQ306i3yMNZWXlQ1nLF9onx0L3yzIxnJa+nwMmj4JKqcbPJz/Fxsjloi3KtJbv3TFZHpUWga1X/8PO6HVI1SXnLW/q2Rb96owQEz/T74oxxhhjtk3h5pI7wfhi04SLc/8RleaUSC6NFBkD/d/rRExJVF1bQ/1Azzs+ztpQAlRB8XNdf8jDe4sqY8OOw6aWeFTxPH4QVK1CLLqOsiSZDkjsPCKu02SkmoeHiiKZqogSzzR6Qb9is2jDQu1vpKh48VlXRN9yKSkZxh2HYDxyDjAaTesQUBPqPh0BlUq8tkyTo0bFAdk6yFeiYaST+QmcHETSXCTOa+cm0J0dy309qypOlLNy4+xeH426vo7gzi/jZvRhUf2cGLkDmbeuIeLoL+JUw6cF/IKHoGaD/tDaV/yQGkqsZKVG41bCaaTEn0JKwkkY9Vlw82kJd/+2cHFATf0AALMOSURBVPdvJ1qfVNTRtLQb4Qjb+zVS4k+K63TQoFHXN+BZu8s9PZ+bX2t0HL1QJMgvHfkZ6Tcv4tjqJ+AbNAjBnV4WCXXGWNVAf3eGNZmCut5N8c3B1xHpkox37OfhxV8j0GbAFNFzsKykm7egm7sCK+12Y3nIGbGsV62heLbVB9BUk97MIuinoZieblC1aJi3XE7PFNXmckxCXgJdTroJpGVAunAFuHDldlBopxHV4j4O9pDOXzY9b00PUy/yQH/LvLFqTlkvAJrHR0M/dwWks5egX7wefR8aDrVCgx9OfCgqw6my/PnWH0KlKHiQIsuQgb0xm8V9wpNN32vibueFPnWGoW/tEdy6izHGGGNFKL09TCPbqA3clRjo56+CZuroYgsiZIMBho37YNxxmBIIQA1naCYMhqpRPVR1lPxU9+4AVdsm0FF7EBrlt2A1pCsxUA/rZZECETkrG/qFa0xxOh2Q6N8Z6oHd7mtUrdX0LZ84BMbavjCs2iEm+qS+5ZrHR5VbOxna5zFsPwjpZJjpu0qvW78W1H07QRlSLy+vZd5XkiVZ7BeJpHnuiQ4eISMLUmiEOOWtP1WZ5ybPlZQ4D6hZ5Q4SlRdOlLNyR61AvOp0ESeDPhNJV3Yg7uJ63Iw5LBLWdKJJKj1rdxOtWag3t0pdtqFQdyIZ9Ui7fgEpCadEYvxW/Km8Ku784tNiEX9pg7hs5+wDd7928PBvB/eAdnBwuf9kiZ7arBydg6hzy+mvE5Rqe9Rv8wTqtHgYSpX2vqv4azUdi5r1++HykTkiaR5/aSOSru5GPXqN5g9xf3jGqpDm3u3xbb+l+Gr/y7icEY4vQ7Zi4s5EDD83GtoH+99xqChVv2T98Q/m+e/BNn9T8vfB4MfwcMjzNjGkjnYAVI3qAnTKN2xWjruemzinBHqiuI4cvdhZMoWVgKpHW6iH9OAZ6iuYqmEgMHkE9PP+g3Q8FAaNBj3HDRFtWGYdfw87o9eKnuUvt/4USoUKF26eEsnx/bFbkG00Ta6qUqjRzqc7+tYZgTY1u4iq9NKIEQhR8WIor7K+9Q+XZowxxlj5ouII7ZNjxMSeUtgV6BethebRYVAob49ioxhRVJHHJZke064pNKP6lrlVS1WhcHWGdtoEGDbsgXH7IRj3HIN0NRbaySPua8LTuyUl3oD+95WiLQ40apFYtnR1e7n3Le/eVnz3dH+uMlXxz6S+5cPu68CLdCUahm0HIZ2/ndhWNqlvSpCX0haIDj5QSxv4eELVvlnegSE5JsmUOI+KE0l06ukvRu7evCXa9ZhegB7rBWXj+lD372xTSXNOlLMKpdY4wq/hUHHKyUhC/OVNotI87XoYrl/dJU4qrRN86veDb/AQuPu1geJuepVm3xJJcUqIU2I8Nek8JGNOgfsolGq4ejcR1exuvi2h0jiJiTSTY4/hVuJZ5KQnIP7iOnEi9s5+otKckuYefm1hX8b2KESWJcSFr8WlQz+I9jOEEtoNO78Ce2dflCeazLNxj/8hoPEohO2bLg5AXDr0PWIvrBKV/fdatc4Yq3xeDr74otef+L9Tn2NH9Fr83eAUIhJv4ulvr8BlwkiogoqvmjUeP4/0ZWvwQ8O9OOYVAwUUeKL5mxhSbzxsGQVyNOSU2rbk798uKiqiEyBdTxbJ9arQb7K6UDUNAh55QFQQGQ+dFv0Su44cICb4/Pbo29gbswkp2TeQnHNd9JI3owloKTneu9YDcLP3LPU1ZIMR0qVrkM5ehPHcJdGWR1GvFuxeeKgS3iFjjDHGrI2ybgA0j42Cfu4/okWfwV4L9bhBgCSL1hWGTfsAowQ4O0IzZkCBUYvVDU3oqHmgpxjtJw4OXItDzrfzoXn4Aaga16/w1zeGRog4kOYcArXHeXw0lLV8UB0pG9SG3auTTX3Lr8VB/+sKyEN6QNWnQ5kLmajog6ruKUFOIwEEhQLKVo2g7tMJyoB7m1OJJqRVBPpBGehXoMpfikrIV3keK9pTUqLfGJcE6Uy4+J5Qpbkt4EQ5qzTUFiSwxSPilH7zsujbTVXd2enxIrlLJ6rupjYifsFD4ezRoMgfCmrjIpLiCSdFYjwz5fbOtJnGvgZq+LQUSXFqseLi3aTIZJmetTqKc2rDkpJwGsmxR8UpNekcstPjEBe+RpyIg2uAqDg3J8/tnYr/g5R6/YJos0IJa+LoVheNur6Z91oVxdW7MdqN+F1U7V86+D0yb13FifUvwLtuTzTs/JpYf8aY9dOq7PBC648R7N4Mv5+ZgYM1oxDj+C9em5cE/059oR7cTQQ25r+Hxs37cXP7dnzTbDcu1rgBjVKLV9t+gU5+fSz9Vqx250Dh6wX4eoG7kFsGVQzJOj0MSzaISibYa9FpcB+82f4bTD/6Bs7eOCruZ6eyR1f/AWJizhCPlqXuUMhZOZBCL8N49hKkCxGiD2MeOw0UNZxFH8z81WOMMcYYsx1i5OGjw6D/cxWMh86IZKMUmySSgkTZPFgkyRUuVXdOn7stXlC8Olm0YKHRd/rfVkDq1xnqQV0rJF4S+y07j4ie5NQuRFEvANopI6v95y165T83EYZ/tsB4+AwM63ZBio4XbX1Kq86muFU6HW5KkMckmhaqlKIiXNW7I5Te7uW/rg72phGgdMo3Uah0OQr6tTtNE+N+/xfUA7qKeZ1ov6o640Q5swhKggd1fB4NOjyLlLgTIsmbGLFVVHdfPfmnODl7NoJf8CDxh/WWaKVyGvrs2xN4mTm6BcLNpxVqiMR4C5GgLutROpXGQSSyzclsahVzK/6kqDa/GXsUaUmhyEqNEafYsFXiPg6utfPatDh7twSkLFzcPwOxYf+KNisqtQPqtX0KdZpPrLQWKFSF79/wAdQM7ImI478h6uwSJEXuwo2oAwhsORl1W00W75UxZt3ob9fgeuMQ6BqMGUfeQJTzTbzbZjOeP5WO1mGR0DzygOjTrV+yAfGhR/BV612Ic0yDs8YV73SYhSaePLEvs27qDs0BSpav3ArjlgOi7U37vj3wfscfsDFyBVrX7IxuAQNKnYBWTk4VFePU85wqyCFJt290cRI7gMpmQVAGB0Kh4VCXMcYYs3VUKS6PH2Q6WH/QVNgGeztoRveDsm0Tm2hXmB/1zNa+8JDopW3cdwLGrQcgX42B5pFh5ZrAlvUG6JdthHTsvLiu6tgcamotmVv8U91RHKqmCT3r+MLw7zYxqkGXcEOMciic8KaRkcZj50RrHNGahmg1UHVuCXXP9iLxXqnr7uYiettT73P9P5tFX3TDxr1iZABNvKr0Kv+EvbWwjW8ns1qU4DVNqtlWVF9fv7ZHtGa5fm0f0m+E4eKNsAL3p/7epjYqpopxaqdCLUjKs1UMtSwxty0x6NJF5Xpexfn1C8hKjUIMnS78K+7jCDViEw3isk+DgWIy05Kqziua2s4FDTu/Cv+QkQjfN0P0hb9y/DdEn1smDihQGxkHZz/Yu/jDwcVPtJmhZeXVI56xyiJJBtHeSDLkiHkFqHd/dUIJ7296/i2qbGkSw+nNd2HclZsYMfM6lF4eiEgPx9dtduOWNhveDr54v9OPqO1S8UMmGSsP6m5tTMnytbtgWLdb7AS06N4BLbw7lNxvnIZ9nr0E49mLon1OftR7Udk0CKpmwWISoqo+GRRjjDHGKuhgfbYOhtXbxcF0zbhBldqf29pQslrzYH9TK5ZlmyBdvCZasWgfHS5ah9wv+VYadPNMrUeo37V6RB+oulGrXduK00Tf8i6tofSraWrFEn8duu8WmFreNGkg5laitoSGnUeAlDTTg6jCu3sb0e9c4WTZgkeFkwM0jw6H1OQ89Cu3QL4aC90386Ee2Qeqji2q5fbkRDmzGtQehXqV00mXnSIqzBOvbBcV2qakeCu4eofc92SYd0OtdYZXna7iRAw5aUiOPyEqzilxTr3WFTDA0a0eQrq9BY+A9rAGzu710Xroz+LzCz/wrajUN0+kWhytgyfsXXzh4Owvkujisjj3F4l1rkZnlUUMzdOlIzszScxrkJORePs8ky5fN12mSXplUxUpTZbr4tkQLp6N4OJFpxAxaqUy/1ZUBE+Hmvisy2+Ye3Y6Nl9diaX1z+CKSzK6JdTFz60PIltlQF3XYJEk97D3tvTqMnZX1H06mnYMthwQFTaULFd3bFGgpzxNXET9xilBTpML5VEAiroBuZXjwVDW9LDMm2CMMcZYlaLu0VZUNdvSxIR3omrTBIoAH+gpiZtwA7o5S8Rk96peHe65+IAmCtXN+1f0uYajPTSTRphae9gwOiBh9+ok0ySfkbHQ//4PjK2biIlmkWGavB6uTlD3ag9Vp5ZQ2BdsH2xJCoUCqnZNoaxfC7rF6yFfjoKBDq6cv2w64OTsiOqEE+XMKmnt3VCryRhxsiZUse0d2EOcSGb6DWzbuBzdh02GnZ11JZPpj5lP/b5iXdNvXkRWWhyy02JN5+m3Lxv1GdBl3RCn1MRzxT6Xxt7NlDjPrUCniUnVWidxEIOq0ZUa07np5CASl+br1aHSVzLqIRl1uacc07khB8b8ywz5bjPm3lZomen67dtVKi3UdjVEX32NnWvueY0C53Sw5m4muLVWsmSE0ZANhfEWUhPPwpBzs1AS/HZi3GjIDRTuQKFQie+XZMguciCIlju51c9NnDeCi2cIXLwais+zKtGotJjW8j00cGuC3858jcPe0eJEmnu1x1vtv4GTpnKH4ZV4gEOfCV12MvRZyeJvgJNb3UprP8WqJvWgbqKy3LjrKAzLNpr6YtppRdU4Bd7IzM53ZzWUjQKhbBoMVdMG1b6vJWOMMcYqBifJi1L6eEL78qPQr9gs2qTQqD8qWNBMHAqF492NPjceOQv98k2AwSjmB9I8Pqpat+m4G4oaLtA+OxGG/7bBuP8kpOOmljTUWpMm+lS1a2bVbQMVHjWgnTbe1HN+wx5RzJJzdR404weJ6vjqwnq3AGNVACU3JY0flErr/SlRoora1dCpuOSWQZeGrLRYkTjPTos3XU7PTainxYnb9dkp4pSadP4eXl+bmzjPTarTZY19kcS6UqnJnTxEKc5FEpQSxOJcIa5DLDffRiWFpvuYEqa3HytJMtSZpxEbSglXQ26COhtGQ/4kd3ZeItu0nBLZpnOj+XLu/WXZCItRKKGxcxGJc3X+ZLpIpLtCY+eWe14DKo0TlWFCliWxzuJcossGcZn6+MpFbjfefoxUdHneQQIpN/FP52JZTqEDCLeXy4WXSzrT84lWRcCJtXd+22qti5gAWJwca8LOiU5e4pxaG9k5ekPrYKoipUl+065fECM80m6EiXN9zi1xgIhOceG3X9DBtVa+xLkpiW7n6AVrQJ87JZsNugwY9Bkw0rkuXVxuqlPhhZpj8Xvif0iVMtHGIRgPO3VDyqWtSNM4ilEfKjpXO4gWUvmv30uymtZFn31L/O5phA8lvykJbk6Em5YnQ5dFfxtM12lb52c6WFEPzp4N4ewRDBfPYDh7BlvN582sZCjq8N5Ajh7Gg6egX7y+4B0c7U0tVahyvFFd3rFljDHGGKsgFGdpHhoKY/1apn7a5y5DN/NPaCYPh7K23x0fT/uSlGCnJCqhGI56WVtTZbQ1UKhVpslj6/iJvt+qdk2gbBlSZSbIVCiVYmQoxeb6RetEKxn93H8gdWkF9bBe1SJet97sHmOsUpIUopLZzhWuXiHF3kefk5ZbgR6Xm1CPQ3ZGPIz6LFEhTNW85sumU5ZYZmZOlhpyUivxnQH0z/HFA+X/vJT4V6g0UKnsTAcBzOfqfJdVdqJavPAy03nucqVWJJD12anQ56TAIM5vmU6UoMxJFUlT5CUs87UdqMJkKGHvTMluH1PiOzcJbu/kDa2Td14S/G7a/Ti51xMn3+DBpteQZeSkxyM1N2luSqBfEC2IslKjxSkxYlve47WOnrcT557BIsEsDizI9H86pwMIslj7vMt0Lq7LpvvSNfPyQvelgwcFkt/6dHHddDk3GU7X9Rl3fK9jFTJuaAB/3UVERHxXps9HoVSbkuYaB6jVdE4nOkhluqxQamGXfAkn16+BIecWdJQIz7mV19rmbtBBLxoRZHpP6Ui/eUmc8qMDHJQ4d/YMEkl0F49gsf2qeqscdh/J8jH9IRsMkI6eE5UqyuZUNR4ERb1aVWangTHGGGOsWsRlnVtBWdsX+vmrROs73fd/m/pRd2lVYj9qOSsb+oVrIF24Iq6r+neGemA3njfmTj3z6VRFKQN8oH1lEgzrdsG4+5ipQv7iVdF7XVnnzgdWrBknyhljpTJVM7uIHtBlZU4OUgJdJNLznSRDFoz6/MsoyZ4F2Zhb9SySi7crm/NfN1VE3z4VrJ6mxKRRHMmmiR4TE5Pg61cLag1VrFOCmhKD5qQ2JbKpuj03qS2W24nlBa6rtLlV8LeT3JXZBoUOMFDCXJxE8tyUMDfkS6bnLReJ9QxT5X1e1T1V2KtuV+fnq9Q3ty25XbVfsJJftMxRqEQ1MiX185L84qTJ/XzoXFvqyXxQgc4lSYFNm3eg19Ch0GgqriUHBXCiRZCLH2rW7ZW3nBLAaTfC8xLndJ6ZchW6zBu4kbkPN6L2wRrQZ6/WOEOldRKtYtQaOncyXdc4I5g+S0MODIZM00Eqfb5z8fvKgkGfCVnSi+eTJYM4UEWnnFKCgVvxxSzXuogJk6n9ksbeHVoHN2jt3aFxcDed27vl3k7X3fIOcJgPVqTdMFX1p9+4iLSb4ci8FSUmYb0Zc0ic8r9nR7e6ImmevwJd6+hVLSeIYQXR3x7NxCHAAz0BFyfe5owxxhhjFqSs5Qvta5OhX7xBzBdj+GcLpIhoaMYNLFIxLCXegP73lZCTkgGNWsR0qlbFF+Gx6kVB23tkXyibNBAjQ+k7oPt+EdQDukDVt1OVLXjhRDljrGIme8htrWIJer0e69evR9O+Qyo0IVvRKNFMbSqqS6sK2i6wYAKMErqetTqKkxkllSmZa06cZyRHiMSyabZAavlD/7jTOV2/fdm8vLT7iAMWUIgDCpTwvp34ds6X+M5dRtdzE+J0EKI8EoXUCseUOM9NpBtMCfTCiXVdTgbCwiPRqm1XODh55SbBKTHuds89xvMfrPCu26PA552eHHE7eU6J9BvhosVTxs3L4oRLG/PuT+sgqs896kPr4GVKzOeum0Yk7d1ESyJrbn/FykZ8512r1hwCjDHGGGPVlcLBHprHRsK464ipZ/mJUOhiE6GZPAJKX9P+qTE0AvqFq4FsHeDmAu3jo6Gs5WPpVWeVTNWwLpSvPwb9P5tFOxnDxr0wXogQrXyqYn963rNkjDFms6gC2s23hThVN6aKf41orXSnAxjnYtajZv3+FX5giT7vGjWbipOZqD7PSLidOM9Nomfcuip6nyfHHhGn0lCyPC+BnnvKq3jPv8zBdG6a1FUhDorQ6XY/fdNlWVymXvvmfvt6UaGf14tf0pvuk3vZ3J/dPALFNGLFLt91GrFiOnh4e+RK7mVO8jPGGGOMMWttxdKrA5R1/KFbsBpywg3ovlsoemzLqemi7QZ1nFTUC4B2ykiebN2GKZwcoHl0OKQm56FfuQVyZCx0386HekRfqDo2r1IjRnnvjDHGGGMWI6rPnX3FySuwe95yas2UkXxFtMvJzE2a355c1HRZ9FKnKXtzW8vg1rUyvqhS9JcXkb2FUdsZU2uo20l1hcoO9qkZOLVhPVSiRRRNdkxtkDSijZGpJVLR6wrzcvP9853TcmLqoW9uXyXnOzeWfFv+Xv2557SMkvymEREu4kRtusR1O5dyGxnBGGOMMcYsS1m/FuyoFcuitZDCr0L/97q82ygJqn6wPxRqTi/aOgV1FmjXVHxfdNSK5XIUDMs2Qjp/2dS2x9kRVQF/kxljjDFmdShx7OrdWJxKQhXghpy02wn07OQCyXTTstsnui4mTS12olJFvh782tsJ5txlpuu5tytN/fdv9/A3JaGNhhzTvAxGmo8hJ3dehhzTnA25l823mcmSEUap6GSuKgApcVGoqmgS2dvJcxeo7ZzzkuoacT13uUisO5uWaZ3zVd6b5pWgz50T7owxxhhjlkXV4pqnxsKweT+MW/aLFpTqEX2g6taGYzVWgMKjBrTTxsO48wgMG/aIPvc5V2OhGT8IqiYNYO04Uc4YY4yxKokqmqn3PJ2c7maS3GxTJXr+SWdNE9lWTpBvnvDYlDjPTa6bk+yGbOhyMnH0yAG0bknDFKXcti8GSBK1hTG3ezHcbhEjWsHktpChy+bbze1ictvIFOixT+egc+Xtnvri/Stv317K/WgZPa9Bly56zBty0qGnc126qepcMuQeuEi+z09LcbtNjbmdTe7kzKbL+ZYXup2S7TTHg2/QwHLacowxxhhjNj4B+6BuUDVvCKiUeb3KGSvuu6Lu0xHKRnWhX7QOcvx16Of+A6lra6iH9YJCa71zyXGinDHGGGM2Q0yS6+RtNRMea0roG288k4KaDQZUuQmJ6SAATRRrSp6nQU+J9BxTAp2WiWS6uJ67LCd3ee59zNX3t6v+ZdOktIase1ofZ8+GnChnjDHGGCtHyoCall4FVkUoA3ygfWWS6Gdv3H0Mxn0nAIMBmvGDYa2qXKI8JycHH3zwARYuXIjk5GS0aNECn332Gfr373/Hx8bExOCVV17B5s2bIUkSevfujVmzZqF+/fqVsu6MMcYYY9V+0ietkzjB2feenkP0QKeJVXMr7E1V9/na19B5vvY2hW+n28yX7Zx9yv09MsYYY4wxxspGoVFDM7IvlE0awPDfdqgHdoM1q3KJ8ilTpmDFihV4+eWXERwcjPnz52PIkCHYsWMHunUr+cNOT08XifFbt27hf//7n6jQoiR5z549cfLkSXh6elbq+2CMMcYYY0WJ1i65PeCplzmzbnFxcZg9ezYOHTqEo0ePipib4vJevXqV+Tm4mIUxxhhjrHpTNawL5euPQaG07p72VSpRfvjwYSxZsgQzZszA66+/LpZNmjQJzZo1w5tvvon9+/eX+Niff/4ZFy9eFM/Rvn17sWzw4MHisd9++y2++OKLSnsfjDHGGGOMVQdhYWH4+uuvRQFL8+bNceDAgbt6PBezMMYYY4zZBoWVJ8mJElUIVZKrVCo89dRTecvs7e0xdepUEZRHRUWV+lhKkJuT5CQkJAR9+/bFsmXLKnzdGWOMMcYYq27atm2LGzduIDw8HK+++updP95czLJ27VpR+GKuLKdKdSpmYYwxxhhjrLJUqYryEydOoGHDhnB1dS2wvEOHDuKcqk5q165d5HE0hPP06dN4/PHHi9xGj6VgPC0tDS4uLiX2RaeTWWpqat5kW3SqLObXqszXZKXjbWKdeLtYJ94u1om3i/XhbVJ1t4stbrOS4ueyulMxC4/6ZIwxxhhjlaVKJcqpssTPz6/IcvOy2NjYYh938+ZNkei+02MbNWpU7OO//PJLfPzxx0WWU4Ld0dERlW3Lli2V/pqsdLxNrBNvF+vE28U68XaxPrxNqt52yczMrNR1qerup5jFGgpZ+KCWdeLtYp14u1gn3i7Wh7eJdeLtYjuFLFUqUZ6VlQU7O7siy6n9ivn2kh5H7uWx5J133ikwlJQCcapcHzBgQJHq9opEG5d2zvr37y/6NzLL421inXi7WCfeLtaJt4v14W1SdbeLOVnLyuZ+ilmsqZCFD2pZJ94u1om3i3Xi7WJ9eJtYJ94u1b+QpUolyh0cHApUjphlZ2fn3V7S48i9PNacYC8uyU47SZbYgbXU67KS8TaxTrxdrBNvF+vE28X68Dapetulqm8vqvDW6XRlui/FxgrF/U3IdD/FLNZQyMIHtawTbxfrxNvFOvF2sT68TawTbxfbKWSpUolyqiyJiYkptiUL8ff3L/ZxHh4eIgA33+9uHssYY4wxxpgt2L17N3r37l2m+4aGhope4vfjfopZrKmQhQ9qWSfeLtaJt4t14u1ifXibWCfeLtW/kKVKJcpbtWqFHTt2iKMB+StFDh06lHd7cZRKJZo3b46jR48WuY0eW79+/fueiIgxxhhjjLGqjBLf8+bNK9N9i2uXcre4mIUxxhhjjFmTKpUoHzNmDL755hv8+uuveP311/MqUCig79ixoxhuSa5duyZ60OSvcqHHvv322yJZ3q5dO7EsLCwM27dvz3suxhhjjDHGbJWvry+mTJlSaa/HxSyMMcYYY8yaKFGFUDJ87Nixoifhm2++KRLmffr0QWRkJKZPn553v0mTJqFx48YFHvvss8+iQYMGGDp0KGbMmIHvvvtO9LDx8fHBa6+9ZoF3wxhjjDHGmO2gYpYLFy4UWEbFLEeOHCmQLDcXs1DczxhjjDHGWGWpUhXlZMGCBXj//fexcOFCJCcno0WLFli7di169OhR6uOoGmXnzp145ZVX8Nlnn4nJinr16oVZs2bB29u70tafMcYYY4yx6oRia3Lu3DlxTnH63r17xeX33nuvQDHLrl27IMtygWKW3377TRSz0ChP6iM5c+ZMLmZhjDHGGGOVrsolyu3t7UVFOJ1KQgnx4tSqVQvLly+vwLVjjDHGGGPMtlARS35//PFH3uX8ifLicDELY4wxxhizFlUuUc4YY4wxxhizHvkrxEvDxSyMMcYYY8yaVake5YwxxhhjjDHGGGOMMcZYeeNEOWOMMcYYY4wxxhhjjDGbxq1X7mN4aWpqaqW+rl6vR2ZmpnhdmuiIWR5vE+vE28U68XaxTrxdrA9vk6q7XcyxYVlbkbCqHZ/zb9U68XaxTrxdrBNvF+vD28Q68XaxnficE+X3IC0tTZzXrl3b0qvCGGOMMcasMFasUaOGpVfDpnB8zhhjjDHG7jc+V8hc8nLXJElCbGwsXFxcoFAoKu116SgIBf9RUVFwdXWttNdlJeNtYp14u1gn3i7WibeL9eFtUnW3C4XVFIT7+/tDqeQOh9U9PuffqnXi7WKdeLtYJ94u1oe3iXXi7WI78TlXlN8D+mBr1aplsdenjc8/TOvC28Q68XaxTrxdrBNvF+vD26RqbheuJLe9+Jx/q9aJt4t14u1inXi7WB/eJtaJt0v1j8+51IUxxhhjjDHGGGOMMcaYTeNEOWOMMcYYY4wxxhhjjDGbxonyKsTOzg4ffvihOGfWgbeJdeLtYp14u1gn3i7Wh7eJdeLtwgrj74R14u1inXi7WCfeLtaHt4l14u1iO9uFJ/NkjDHGGGOMMcYYY4wxZtO4opwxxhhjjDHGGGOMMcaYTeNEOWOMMcYYY4wxxhhjjDGbxolyxhhjjDHGGGOMMcYYYzaNE+WMMcYYY4wxxhhjjDHGbBonyquAnJwcvPXWW/D394eDgwM6duyILVu2WHq1bNbOnTuhUCiKPR08eNDSq2cz0tPTxezGgwYNgoeHh/j858+fX+x9Q0NDxf2cnZ3FfR999FEkJSVV+jpXd2XdJlOmTCn29xMSEmKR9a7Ojhw5gueffx5NmzaFk5MT6tSpg3HjxiE8PLzIffl3Yn3bhX8rlevcuXMYO3Ys6tevD0dHR3h5eaFHjx5Ys2ZNkfvy78W2cWxufTg+tzyOza0Tx+fWh+Nz68TxufU5Z6HYXF0O684qGP0QV6xYgZdffhnBwcHiH7YhQ4Zgx44d6Natm6VXz2a9+OKLaN++fYFlQUFBFlsfW3P9+nV88skn4h+wli1bih2k4kRHR4s/pjVq1MAXX3whgsVvvvkGZ86cweHDh6HVait93W19mxA7OzvMnTu3wDLaRqx8ff3119i3b58IMFq0aIH4+Hj8+OOPaNOmjUgcNGvWTNyPfyfWuV0I/1Yqz9WrV5GWlobJkyeLBGhmZib++ecfDB8+HL/88gueeuopcT/+vTCOza0Xx+eWw7G5deL43PpwfG6dOD63PlctFZvLzKodOnRIps00Y8aMvGVZWVlygwYN5M6dO1t03WzVjh07xDZZvny5pVfFpmVnZ8txcXHi8pEjR8Q2mTdvXpH7TZs2TXZwcJCvXr2at2zLli3i/r/88kulrnN1V9ZtMnnyZNnJyckCa2h79u3bJ+fk5BRYFh4eLtvZ2ckPP/xw3jL+nVjnduHfiuUZDAa5ZcuWcqNGjfKW8e/FtnFsbp04Prc8js2tE8fn1ofjc+vE8XnVYKiE2Jxbr1g5qlZRqVR5R0qIvb09pk6digMHDiAqKsqi62fr6OiWwWCw9GrYJDqK6+vre8f70RHHBx54QFRRmPXr1w8NGzbEsmXLKngtbUtZt4mZ0WhEampqha6TrevSpUuRI+hU/UhDCml4mhn/Tqxzu5jxb8VyKAarXbs2UlJS8pbx78W2cWxu/Tg+twyOza0Tx+fWh+Nz68TxedWgqoTYnBPlVu7EiRNi47q6uhZY3qFDB3F+8uRJC60Ze+yxx8R2oZ2j3r174+jRo5ZeJVZITEwMEhMT0a5duyK30W+Ifl/MMmjYFP1+aHgU9RB77rnnxBApVvFkWUZCQoLo8Ub4d2Kd28WMfyuVLyMjQwxVv3z5MmbNmoUNGzagb9++4jb+vTCOza0bx+fWjf+GWjeOOSyH43PrxPG5bcbm3KPcysXFxcHPz6/IcvOy2NhYC6yVbaOjjA8++KDoRUl/MM+fPy/6H3Xv3h379+9H69atLb2KLN/vh5T0G7p586aYkIsqLVjloc/+zTffFP3eJEnCxo0b8fPPP+PUqVOib6Jazf80VaRFixaJgIL6VRL+nVjndiH8W7GM1157TfQ9JEqlEqNHjxY9Kgn/XhjH5taJ4/Oqgf+GWi+OOSyL43PrxPG5bcbmvAWtXFZWVrEblKokzLezyh+SQyczmkhgzJgxYsKHd955R/yhZNbB/Pu402+IA4zK9eWXXxa4PmHCBFGd9+6774oh7XSdVYwLFy6IiofOnTuLSVEI/06sc7sQ/q1YBk3QSP+uU8KThmvS0FqdTidu498L49jcOnF8XjXw31DrxTGH5XB8bp04Prfd2Jxbr1g5BwcHcfSjsOzs7LzbmeUFBQVhxIgR2LFjh/jRMutg/n3wb8j6vfLKK+Lo8NatWy29KtUWzdw+dOhQMUTQ3GOX8O/EOrdLSfi3UvFCQkJEX8NJkyZh7dq1YijtsGHDxPBb/r0wjs2rDo7PrQ//Da1aOOaoeByfWyeOz207NudEuZWjoQLmoQT5mZf5+/tbYK1YcWhCATqqRf2TmHUwD78p6TdE/cT4KLx1oH+8PD09xdAoVv5u3bqFwYMHi0lPqKou/78d/Duxzu1SEv6tVD6qYDly5AjCw8P598I4Nq9iOD63Lvw3tGrhmKNicXxunTg+t34VHZtzotzKtWrVSmz8wrPpHjp0KO92Zh0iIiLE0A5nZ2dLrwrLFRAQAG9v72Incjp8+DD/fqxIWlqamKCDthcrX3QknY64078ldAS+SZMmBW7n34l1bpeS8G+l8pmHdNKOE/9eGMfmVQvH59aF/4ZWLRxzVByOz60Tx+dVQ0XH5pworwJHSmio4K+//pq3jIYUzJs3Dx07dhRVEqxyJSUlFVlGEzesXr0aAwYMEENumPWgiZ3oH7moqKi8Zdu2bRP/+I0dO9ai62arwQcFEoV9+umnYujUoEGDLLJe1RX9+zF+/HgcOHAAy5cvFz32isO/E+vbLvxbqXyJiYlFlun1eixYsEBUCpl3lvj3Yts4NrdOHJ9XHfw31PpwzFG5OD63ThyfW59EC8XmCpm2JrNq48aNw7///iv6HlGvvT///FMcGaEN36NHD0uvns3p06eP+FHShEE1a9bE+fPnxc6SRqMRf1QbN25s6VW0GTTTMQ2Jokkd5syZI2Y/bt26tbjthRdeED3F6I8lLXNzc8NLL70k+lnNmDEDtWrVEsN1eMha5W6T5ORkcX3ixImi1xjZtGkT1q9fLwKLdevW8c5sOU98Mnv2bFEZQf+WFPbII4+Ic/6dWN92iYyM5N9KJRs1apSoEqbYiqpTqD/lokWLxGRO3377LV599VVxP/69MI7NrQ/H59aBY3PrxPG5deH43DpxfG59RlkqNqdEObNuWVlZ8uuvvy77+vrKdnZ2cvv27eWNGzdaerVs1uzZs+UOHTrIHh4eslqtlv38/ORHHnlEvnjxoqVXzeYEBgbSgb5iT1euXMm739mzZ+UBAwbIjo6Ospubm/zwww/L8fHxFl13W90mycnJ4vcSFBQktgf9TWvatKn8xRdfyDqdztKrX+307NmzxO1ROATg34l1bRf+rVS+xYsXy/369ZN9fHzEv+/u7u7i+qpVq4rcl38vto1jc+vD8bl14NjcOnF8bl04PrdOHJ9bn8UWis25opwxxhhjjDHGGGOMMcaYTeMxAYwxxhhjjDHGGGOMMcZsGifKGWOMMcYYY4wxxhhjjNk0TpQzxhhjjDHGGGOMMcYYs2mcKGeMMcYYY4wxxhhjjDFm0zhRzhhjjDHGGGOMMcYYY8ymcaKcMcYYY4wxxhhjjDHGmE3jRDljjDHGGGOMMcYYY4wxm8aJcsYYY4wxxhhjjDHGGGM2jRPljDHGGGOMMcYYY4wxxmwaJ8oZY4xZ1Pz586FQKHD06FFLrwpjjDHGGGM2j+Nzxpit4kQ5Y4zZULBb0ungwYOWXkXGGGOMMcZsBsfnjDFmfdSWXgHGGGOV55NPPkG9evWKLA8KCrLI+jDGGGOMMWbLOD5njDHrwYlyxhizIYMHD0a7du0svRqMMcYYY4wxjs8ZY8yqcOsVxhhjQmRkpBjm+c0332DWrFkIDAyEg4MDevbsibNnzxa5//bt29G9e3c4OTnBzc0NI0aMQGhoaJH7xcTEYOrUqfD394ednZ2omJk2bRp0Ol2B++Xk5ODVV1+Ft7e3eM5Ro0YhKSmpQt8zY4wxxhhj1orjc8YYq1xcUc4YYzbk1q1buH79eoFlFHx7enrmXV+wYAHS0tLw3HPPITs7G7Nnz0afPn1w5swZ+Pj4iPts3bpVVL/Ur18fH330EbKysvDDDz+ga9euOH78OOrWrSvuFxsbiw4dOiAlJQVPPfUUQkJCRGC+YsUKZGZmQqvV5r3uCy+8AHd3d3z44Ydip+C7777D888/j6VLl1ba58MYY4wxxlhl4vicMcasByfKGWPMhvTr16/IMqoioYDb7NKlS7h48SICAgLE9UGDBqFjx474+uuvMXPmTLHsjTfegIeHBw4cOCDOyciRI9G6dWsRSP/5559i2TvvvIP4+HgcOnSowJBS6sUoy3KB9aCdgc2bN4sdAyJJEr7//nux81CjRo0K+TwYY4wxxhizJI7PGWPMenCinDHGbMhPP/2Ehg0bFlimUqkKXKeA2hyEE6o4oUB8/fr1IhCPi4vDyZMn8eabb+YF4aRFixbo37+/uJ85kP7vv/8wbNiwYvsumgNuM6poyb+Mho3SENOrV6+K52aMMcYYY6y64ficMcasByfKGWPMhlBQfafJgoKDg4sso+B92bJl4jIFxqRRo0ZF7te4cWNs2rQJGRkZSE9PR2pqKpo1a1amdatTp06B6zTMkyQnJ5fp8YwxxhhjjFU1HJ8zxpj14Mk8GWOMWYXClTNmhYeAMsYYY4wxxioex+eMMVvDFeWMMcYKoP6HhYWHh+dNABQYGCjOw8LCitzvwoUL8PLygpOTExwcHODq6oqzZ89WwlozxhhjjDFWPXF8zhhjlYMryhljjBVAfQtp5nuzw4cPi8l+Bg8eLK77+fmhVatWYkKglJSUvPtRwE2T/QwZMkRcVyqVop/imjVrcPTo0SKvw5UojDHGGGOM3RnH54wxVjm4opwxxmzIhg0bRFVJYV26dBGBMwkKCkK3bt0wbdo05OTk4LvvvhMz3tPkQGYzZswQgXnnzp0xdepUZGVl4YcffkCNGjXw0Ucf5d3viy++EMF5z549xWRA1CORJhtavnw59u7dCzc3t0p654wxxhhjjFkfjs8ZY8x6cKKcMcZsyAcffFDs8nnz5qFXr17i8qRJk0RQTgF4YmKimGDoxx9/FJUqZv369cPGjRvx4YcfiufUaDQi2P76669Rr169vPsFBASIapf3338fixYtEpMH0TIK4h0dHSvhHTPGGGOMMWa9OD5njDHroZB5bA1jjDEAkZGRIoimapTXX3/d0qvDGGOMMcaYTeP4nDHGKhf3KGeMMcYYY4wxxhhjjDFm0zhRzhhjjDHGGGOMMcYYY8ymcaKcMcYYY4wxxhhjjDHGmE3jHuWMMcYYY4wxxhhjjDHGbBpXlDPGGGOMMcYYY4wxxhizaZwoZ4wxxhhjjDHGGGOMMWbTOFHOGGOMMcYYY4wxxhhjzKZxopwxxhhjjDHGGGOMMcaYTeNEOWOMMcYYY4wxxhhjjDGbxolyxhhjjDHGGGOMMcYYYzaNE+WMMcYYY4wxxhhjjDHGbBonyhljjDHGGGOMMcYYY4zZNE6UM8YYY4wxxhhjjDHGGLNpnChnjDHGGGOMMcYYY4wxZtM4Uc4YY4wxxhhjjDHGGGPMpnGinDHGGGOMMcYYY4wxxphN40Q5Y4wxxhhjjDHGGGOMMZvGiXLGGGOMMcYYY4wxxhhjNo0T5YwxxhhjjDHGGGOMMcZsGifKGWOMMcYYY4wxxhhjjNk0TpQzxhhjjDHGGGOMMcYYs2mcKGeMVSvz58+HQqEQ51UBrWuvXr1ga3bu3Cne+0cffQRrULduXXFitvsdYIwxxhirKBTvU9xTGSi2oteiWMua9sesId629GfDGLN+nChnrBqjIIBOSqUSly9fLvF+vXv3zrtv4YBmypQpebeZT05OTmjWrBnefvttJCcnF/ucGRkZ+O6779CnTx/UrFkTWq0Wbm5u6NChA959911ERETcVTIt/4meq1atWhg7diwOHDhwl58KK2sAWdrJFpP75f2Z2tvbIygoCE899RQiIyMtvYqMMcYYY+WicMyjUqng4eEh4kfa15Bl2dKrWGUS6+aTWq2Gu7s7QkJCMG7cOMybNw/p6ekV8trm/b+qGJ9WtaIpxpj1UVt6BRhjFYuCKoPBgN9//x1ffPFFkdsvXrwoktHm+5VkxIgRaNWqlbgcHx+PNWvW4Ouvv8aKFStw+PBhEfyaHTx4EGPGjEFMTIxIaA8ZMgT+/v4ieX7ixAnxuBkzZoj7tWnTpkzvIzAwUARthJ6HHkuvvXLlSnE+atQoVEWhoaFwdHSENerZs2eJCfH7rQahAyb03r28vGBL8n+mN27cwPbt2/Hbb7+J7/ChQ4cQHBxs6VVkjDHGGCsXH374oTjX6/W4dOkS/v33X+zatQtHjx7Fjz/+aOnVqxImT54s4m46uJCWliaKjbZu3Yrly5fjf//7n9jHo32t/J5//nlMmDABderUscg6035Zp06d4OfnB2tj6c+GMWb9OFHOWDXn4+MjghSqOvjkk09EQjy/uXPnivNhw4aJ4LUkI0eOzEtUk2+++QYdO3bE+fPn8cMPP+QFwhcuXMDAgQNFhcNXX32F1157rchrXrlyBW+99RZSU1PL/D4oQCzcooFek94TvUZVTZRTVYi1ooRuRbXFoIMD1vzeK+szlSRJ/PbWr18vDmTR75QxxhhjrDooHEfu27cPPXr0wM8//yzi93r16lls3aoK2v8qXLiSnZ2Nb7/9Fh988IHYB9qyZYv4XM2oEMWSxSg1atQQJ2tk6c+GMWb9uPUKYzbgySefFFXga9euLbCcqjtoWFqXLl3QpEmTu3pOZ2dnUeFAqKLc7IUXXhAJcEqE06lwkpxQULxs2TJ07twZ9+O5557LS7wnJSWVet8dO3aIFhf0Pl1dXeHg4CDax3z88cci2Cytfx1V+1IFNCV3qXKeqhCoWr6kIZJUmU9JT6oOtrOzQ+3atcVnodPpijymuDYm9/La5MiRIxgwYABcXFzEe+zXr59oTVMZvfjM7yM2NhaPPvqoaLdDn3Hbtm3x999/l7k/NVXJ0HailiT0eHrPzZs3xzPPPCMqsPPLyckRB2Podvp86D13795dfLeKQ5U4VL3UtGlT0fYkICBAVJXcunWr1Pe2ePFi0Z6IWgfR4xo3bozPPvtMvP79orZI5gNQtP0Ky8zMxJdffilGc1DLI/rd0e+G1im/sLAw8Xk+/PDDBZbTb8M8ZHfPnj0FbqPvJC2nqvby+J3QdqaDZ7SO+UccJCQkYOrUqeKgHT0fvZc///yzxM/kbr4DjDHGGKs6unbtKgolKCY7duxYkdtpdB2NSvX19RWtFimGfvrpp0V8md/EiRNF/EEjY/OjfRNa3rdv3wLLqRJbo9EUSCZT/EcjXKlNJI2Apdfz9vbG8OHDS2ztaI53ab/qiSeeELEktZXJ3+ZjyZIlIv6lGIbiYYqLC6///aJ4lFpZvvfee2L/4qWXXipwe0mxP8WCVKBB75f2UehzpspvivPyv0dznEb7bOY4Mn9sZ97nodemoqVGjRqJ5zPHtHdqf0KfPcXg9PnRe6G48/vvvy/SkudO89kU7nlO6/XYY4+Jy3Sev3WNuY1MaftF27Ztw6BBg0TsSe+nYcOGotVocfsK97LfxxirGriinDEbQMHkq6++KqrHqTLcbPXq1UhMTBStUGg45N0yBzPmiWkoKUdDASngefPNN+/4eAom7kf+YOpOk+PQe6RqdzooMHToUJH0o6oWCpYoUKL1pkC3MKp4oc+JgmZqm0EB/NKlS3Hq1CmcPHmy2Pfw0EMPiUB08ODBItlI1cLTp08Xn/XdVAzfzWvv3r1bJMmNRiNGjx6NBg0a4MyZMyLBSzsAlYH61dPnSwllCk5TUlJE0pqSt5Tcf+ONN0p9fFxcHNq3by8OtNAQ0gcffFBsJ/peLVy4UATUnp6e4r4UfNLIBRq+SztcdNCEksp0YGH8+PHi8yncaujll18WQTiNsKBELO0wrVq1Snyu9Hy0g1TY448/LrYZ7VDQ+tB7o7Y/77//vgimqYKnuINB94LWJz/6/GjbUbsialFE60IV6Js2bRLfsXPnzomEPaEdFNrZyJ/0JrSO+S/TgYT81+m3Stvsfn8nVNVEnwXtfNF3zrxDcf36dfFclPzu1q2bONF2pqQ3fV/v5zvAGGOMsaqrcNzzxx9/iPiM4luKfSnhSIlw2n+hlo8Uf5nbZVAinBLSFMvkb1tnjnv2798v4geKcwjFi5TQzJ9ApxaAlGym5DnFPNT/+9q1ayL23rBhg3hNSpoWdvPmTZFcpsIAirmp6IGKAcisWbPEPhfFi5MmTRLnFLdRLFQRFdavv/66SPZT3EtxIRWDlGTjxo3ifdK+CX2+FDfSe6HPgfY5zKOD6fy///4T+xuUgKf3QMzn+VGcRoUetM9D+5h0YOBOKOamYh6Kc6kAiK7/888/4rWo8OOnn36658+DEvW0nhTf528bWtL65/fLL79g2rRpojCF5sGi90KxL8XG9F2geLi45yiv/T7GmBWRGWPVFv3EAwICxOWpU6fKKpVKjoqKyrt94MCBsqurq5yRkSG/++674v7z5s0r8ByTJ08udnlaWprcuHFjcdsnn3wili1YsEBc79q1a7m9hx07dojn7NmzZ5Hb3n//fXFb/fr185bReha3vpcvX5YlSSryHO+99564/5IlSwos//DDD8VyFxcX+fTp0wVumzhxorht6dKlBZbTOtLyNm3ayDdu3Mhbnp6eLjdo0EBWKpVyXFxcgccU997u9rWNRqMcFBQklq9fv77A/efMmSOW04k+y7Iwvz6tF10u7nTgwIEi74NOY8eOFetjFhERIbu7u8sajUZsg8LblZ7L7PvvvxfLvvvuuyLrRJ9hZmZm3vUvvvhC3Hfw4MGyXq/PW56QkCAHBgaK2/bt25e3nC7TMtoO+bdNVlaW3KlTJ3EbPS4/83dp1KhRBV47/2dU3LqW9pnmf7/EYDCI3yHd9vzzzxf72/v6668LLKd1pscoFAr5xIkTecsfffRRcf+zZ8/mLZswYYLs5eUlt2rVSu7WrVve8ps3b4rvY58+fcrld+Lo6CgfP368yOOefPJJcfvLL79cYPmRI0dktVp9X98BxhhjjFknc1xY2K5du0T8odVq5djY2LzlYWFhIlakOC06OrrAY7Zu3SoeM3LkyALxCj3/mDFj8pZduHBBLOvfv784p8eZURxCy3bv3p23LCUlRU5KSiqyjrSv5OfnJ4eEhJT4vijmyh9/kitXroj3QHEvXTajuHj06NElfiYlMe9X3Cl+p/iO7vfHH38Uic/yP9a8DidPnizyHIU/B3MMmv99FLduzZs3L/YzLGl/zByj075idnZ23nKKzWl/jm6j70hp+wuFn6+k+L3wa5f22URGRorvJO17hYaGFrj/tGnTxP0ppr3f/T7GWNXArVcYs6H2K1RtTNUa5OrVq6IClKp9yzKZJFUWUFUpnehoO1WwUgUCVS5Tlae5GpRQ9W15o+Fy5tenymSq/vj0009FFQf1S7+T+vXrF1t1/sorr4hzqvYozosvvijaPhT+LAu3nMmPKg/yT25KlQn0OVM1ME1eVFZlfW2qmqERAVTJS9UM+VFlDg0bvBdUfUNDMYs7UVVPYVRpTO+dtokZDdmk90FtfqgiuCxoqGph9BnmX07fY9qeM2fOLFDRTdUfVO2dv/8+MVd0UOVQ/m1DlUbU2qQ4s2fPFs9Nr1V4neg1qLJ50aJFuBtUmWL+HtPnQm1N6LtHQ07N602oxchff/2Fdu3aFRmdQetMnzPtr+Vva2OukspfRU4V5lSVTpU7VDlPE+GaW6zQ97Hw0OR7/Z3Q96x169YFltE2p8+HWgEVHjJL76twm5i7/Q4wxhhjzLqZYx6Kv2jEH8UjFL9Q7J5/osc5c+aIuIFiL6p0zo9iFaqApqpeaqFijleo5QbFM+YRpub4h1qBUExaeFQdxRFUCW5GFd7F9aqm/Rhq/0Ij7KjCvDAagUjrX3hEIcU89B6oDWX+diAUF1PVd/74uDyZP687taE0Ky6Wutee3bQvdi+Ppdg7/8hYis3NcbAlqrAp5qbKdtqnLTyH0ueffy5iWdqPKa7tYnnt9zHGrAe3XmHMRlDvYEq6UtKP+tlREpH+ATcnXu+EhrDRyRxgUQBIQQD1baOhihWNEvvm/nkUmFIPQRruSBMB5W8dURJKEFLwTROWhoeHi0A7f+uWkvp+U0KvMBoKam41Ul6PuZ/nodYchNpaFEZBOX0+9J7vFg29vJvJPGk4bHGTMlEPP9p25vUsCe0E/e9//xNtVCghS61VqJclJZHzJ29p29GBAdoxKG5CUHOrmfyvd/z4cXFOLWwKo8+tcDsRauNCQ04p+P/uu++KXV8K8Olg0d0efKBTfjQslBLo+Yfk0jBWOrBVUl9G2hEj+V/f/L5pZ5CS8GfPnhXDPmkHk743tFNHLXroYIq5RUvhtjz3+juhPvqF0Q4mfY7U7qW44cb0vSjcq7ys3wHGGGOMWb/8va8J/Vv++++/5/WRNjP3BKcYqbg5WyieobiIYhPq/22OYWi/htqO0MF6im0o+U7JcLqPOVFOCWSKiajlW+F2L9ROg+Ieen16jcJ9pSnuMbd7MaN9oOJajJQWa1Jin2Ix2p8pb4VbYZaE9ttWrlwp9gnpoAUV2FCMdT8FTsXFf3dC+3HF7buZ52y60/5CRTBvu+LaVdJ+Ln2/KIam2LZly5YVst/HGLMenChnzIZQUpwSaNR3j47WUxBZuAq0JHR/8wQtJTFXhpSUTLsfFHTe62SUlFSkwIeqsKmCl4JDSrSbg2UK4kuamLG4XnTmChIK2MvrMffzPOZ+0Ob+iIWVtLy8lfQ6NFEQudOkmYGBgWIbUWKY+ihSMG8ONqkHI3138z9P/kqk/MzLqfdhWT4j+kwLV8NQYEs7HrRzVXgn736YDz7QQSr6nVDymvqmjxs3TvwuzdVG5kkraWexuB1Gs/T09LzL9DlRn07ayaTvh3kHkRLltA3o+07LKFFO59RHkfqBl8fvxLyN87vT97K4x5T1O8AYY4wx62dO4tKBeEpG0+TeNE8J/XufPylpjnuo8ro0+eMeim8oUU4xDSUvqbqc5jcx30Z9oikWoQQ6rUfhUXRUFECV4zRSr3///mKULFUDUyxG+xwUTxUX9xQXv5Q17qmIRLl5olCK2UpDBUZr164V88rQ50Y9uQntD1KFN30Gd6ukz6I0FHMXN99NWfcXKsK97FuU934fY8x6cOsVxmwIzbpO1eAUoFKSjtollCdzRTMNM7NEkFMSqoSn5Bsl+mmCy19//VUMo6Nk3NNPP42qjhKeJCEhodjbS1pe3kp6nfj4eHFelkmMGjduLCYspR0m+h599dVXIqlME/xQBVL+5zE/b2HmFkD5X898ubh1pMmdaNLJ/Mz3pwNJtHNV2ule0E4YJX+piol20jZv3owff/yxyOtTy5PSXpt2CvOjnU767VFynXYcaUfUvONHVT80GSftUFFFDLUvyr+jcj+/k+KqmEr7zEvbfmX5DjDGGGOs6qA4hNquUPsUSh5OnjxZjDorHDNQDFNa3JO/WtucaKfYhqrKaWJKczKcbqPXoTjJXDhQuFqYWn1QGxWKNajFJCWQqW0LxT3UYrIkJVVu32vccz9o5N+xY8fEZaoUvxOazJMOHFBBCH0uFGfSJKAPPPAAzp8/f9evfy+j/SjmLi6BXNz+grmAhGL14hSXuL4X97JvwRirvjhRzpgNoSPelJSLjo4WAevEiRPL9fmp7QYFwTTL/J0qQkhJ1anljdp0mCspCivcBqMqMo8K2Lt3b5HbKMFIPcwrA/VxpF7yhZlHApR19IK5EoMqXN566y0sXrxYLKOdGEJ9Ain5Swd7Ll68WOSx5uRxmzZt8paZLxe3velzKxywOzs7o2nTpmLngXa8KhLtmFEbF9o5S01NFcsoqU07B3v27Lmr5zLvIFLbEhoimr96ii6fPn1aJKHz37eififUFofmP6Cd1+IOnN1phEhp3wHGGGOMVT0tWrQQI1xpX2TWrFl5y829w+8m7qEKZGrNRo+hUWj5YxtqKUKxFSWDKTFsbp9ROO6hx9MB+sKxc3Ex9Z2UFmtGREQgKioK5Y32t7KyssRrF34fpaH9QDpwQHP9UMs7ajlDIxvNzIUUFVERTUnv4vZNittfMLf3LO6zo+1XXHx5L+tufs3iYlNKxlMsSyMP7uYzZoxVXZwoZ8zGfPbZZ2KoISXSKOFY3qiNBFU40xA+SgAWVwFACdUJEybk9SOsaOYJdQoHPxS0UhKuqqOdAUocU4I4f5BLqCr4XvqT3wsKSOnzpB0MsytXrojvBCU9H3nkkVIfTxUxxQW85sqc/JPOPv7446KyiCZ2zR8IU5UKTSxkvo+ZuW0QVUjnT3zTQZ3/b+9O4Gyq3weOP7PP2Jcha4hEloQS2YtkSyElWSIVUZYSWaLk52+ttGmx5lfSQkVZ4keypOinKGLImn03+/2/nq/fvd2ZuaMZ5t5z7z2f9+t13DPnnrn3e+457nzPc57zfIcOHeqxPQMHDjQnDvo6njJWNBvHWdPwamjtSz1p1Axq/T+jtPal1pLULCfdHk+d/V27dpnP153Wm9TsnjfeeMN8lu7BcD0h0s9MM7SdP3vz/4mWbNFt0Gyn9HXWdbs8DYSanWMAAAAEHh0rSYPYWn7OWcNZB1HUfoNmOHvqt2p/zFMQXfsympmud+hp+TlnbWi9g7Zu3boyf/5801/S+tfpB9PUfo8mXDhLlyjtJ2mf5Uqyq7XPo9vw2muvpUkc0X6x9lfd+8dXS/uvL7/8sunXala8bv8/0QQKT+dlnvpYOmC98jSYaU7Qvrd7wpT2zfUcVbnXr9ekCz2v1LsetYa8k14cyKwc35W0Xc9RnPvOmTjifueBJrLoOu4DkAIIXtQoB2xGg3LpB6XJSXqlXYPwmrmuNYW146bBuhIlSpj6hDpAog6co8E8XwWp27RpIxUqVDBZE1pSQrMGtPOkdfr0FkRvdQJ9RTv+OjhrixYtzGCI7du3N4FzzR5etmyZqUntXv86qzRgmtlgnnp3wtNPP50hS2jDhg0mC1gHTNLgsp6g6KPWidQ2XY6OJq/1ErWEj66rWSR6cqO36WrH1P399NjSbdKOs9al1JqUeqL08ccfm470s88+m2ZwU72Y0K9fP9MB1vrbenxqh1h/X9/HU01CDZBr4FaDztoeHVhS/+9oZ14D1HrCoZ35t956S66WZvNoWRHNrtJ2av1GLcWiJ3AjR440n41uj9a91BM6HcRTy6toprX7AKr6e7of9P9Z+mC4njDqSZB+PlrHUgf39fb/Ez2J02wuHRBVg+O6DXr7qma16z5btGjRFR8DAAAg8Ohg7FoGUs8RtH+oyTUaENW62dr30jv6tE9bsWJFM36K9j80SK59Fy0d507PMbS/pH2b9HfE6XPOi//p76JTGpTXdmh/R/vO2i/UcxQNkmufSPse2aGBd01GGDRokHlNHetFS3XoeZH2hbV/pn3z7Jo5c6ZrOzT5QBMYtA+q/VHtv+rn5t7nzYwGlvVuTO0Ta1s1wK79XM2411J9msTkpJ+XZqtrIod+NppcpX1/vaBxtbTNGiTX/riet+g+XrBggekf9unTx5QGdNJ9oqX3NGlEP9N7773XBPv1/EbPLXVKz9nf1b6nJqE4a59r/zqz0in6eej6Opi8Zufr2EF6vOndAZrYpcfn+PHjr3rbAQQIB4Cgpf/FS5YsmaV1n3/+ebP+jBkz0izv1q2bx+X/5OzZs47Jkyc7Gjdu7ChSpIgjPDzckS9fPkfNmjUdzz33nGP37t1Zep2VK1ea92/UqFGW1td2emrvn3/+6ejcubOjRIkSjujoaMeNN97oGD9+vCMpKcnj648aNcos1/dPLy4uzjynn407fY3MvlYza1dOvbdav369484773TkyZPHTHfccYfj+++/d/Tt29f8zubNmx1Z4Xz/y01lypTxuB0HDhxwPPTQQ2afR0VFOW6++WbHBx98kOl+1fdyb//jjz/uqF69uqNgwYJmP5UvX97RvXt3x9atWzO8xsWLFx1jx451VKlSxayr23z77bc75s2b53G7UlNTHa+99pqjUqVKjsjISEfx4sUdffr0cZw6dcpsT/ptcvriiy8crVq1MtsUERHhuOaaaxy33HKL+T+zffv2bH2m7tub3sCBA806+uiUkJBg2ly3bl3z/0fbXbp0aUfTpk0dU6ZMcRw7dizT19FjPL3mzZub5+6//36PbcjJ/ydOhw4dcvTo0cMRGxtrXvOmm24y/w9y4hgAAAD+x9lfzMzhw4cduXLlMpPOO/33v/81fdxrr73W9Hm0L6D9vN69eztWrFiR4XVOnjzpCA0NNe81f/78NM9pH9jZjm3btnlsh/ZHtF+i7ShcuLCjXbt2pg2Z9W+yck6i/VDt/2o/WPs+2i/W/vHlzhM8ca7vnMLCwhz58+d33HDDDaYfp20/d+6cx9/11P6PPvrI8cADDzgqVKjgyJ07tyNv3rzmsx02bJjjyJEjGV5j0qRJrj5z+r7/P21LZuc9zv629r21D679TX19fZ9XXnnF9NXT02Xjxo1zXHfddaYfrv3gZ555xnH+/PlM++9Llixx3HbbbWY7nZ+fnkNl9tk4ffPNN45mzZo5ChQoYNqlfVB9Lz3O0ruS8z4AgSFE/7E6WA8A8B7NHNFMby1poTUJvUHvENABlv6p7jQAAAAAAIA/okY5AAQBLTviqY623q6pA+ZoKRRvBckBAAAAAAACne1qlGs9LGe9Vx08RGuF6cARzZo1s7ppAHDFtH6j1u7T7zKtM631+zZv3izfffedqSnoHCQSAAAAAAAAGdkuo7x79+5moDIdlVoHEAkLCzMDimkwCQAClQ7yqN9rOsjjO++8YwaY3Lt3rxlsUgdR1EFWAQAAAAAA4JmtapRv3LhR6tSpY0ZwHjx4sFkWHx9vRlwuWrSoKU8AAAAAAAAAALAXW2WUL1iwwGSQ9+7d27UsOjpaevbsKevWrZN9+/ZZ2j4AAAAAAAAAgO/Zqka51uutWLGi5MuXL83yW2+91Txu2bJFSpcu7bGuuU5OqampcuLECSlcuLCEhIT4oOUAAADwd3qj5tmzZ6VEiRISGmqrfBTLaf/84MGDkjdvXvrnAAAAuKL+ua0C5YcOHZLixYtnWO5cpp1rT8aNGyejR4/2evsAAAAQ+PQuxVKlSlndDFvRfrynhBcAAABgXxb757YKlF+8eFGioqIyLNfyK87nPRk6dKgMHDjQ9fPp06fl2muvlbi4OJO14kuJ/17stddODhH5rlC41D+RLOFeqlwf+WBLv9leX/Cn7WX/Bv82s4+De3vZv8G9vb7Yv/62zb6Q3e29WpqtUq5cOZ/3DyGuz1xPgtLfPYqsSUpKkqVLl0rz5s0lIiLC6ubAYhwPSI9jwocSE0UmTbo0P2iQSGSk+BuOBwTKMXHmzBmTTJHV/rmtAuUxMTFpSqg46YCezuc90eC6pwB7oUKFfN4RT4zO5bXXTgoRyZUrXApdSJYIbwVhChf2m+31BX/aXvZv8G8z+zi4t5f9G9zb64v962/b7AvZ3d6r5TwpoPSH7zk/c+2bEyi/8hPcXLlymc/Pn05wYQ2OB6THMeFj48aJP+N4QKAdE1ntn9uqeKKWWNHyK+k5l2m9GgAAAAAAAACAvdgqUF6jRg3ZsWOHSbt3t2HDBtfzAAAAAAAAgCVSU0V+/fXSpPMAfMZWgfIOHTpISkqKTJ8+3bVMS7HMmDFD6tSpwwBAAAAAAAAAsI6On1e16qUpk7H0AHiHrWqUazC8Y8eOZnDOI0eOSIUKFWTWrFmyZ88eee+996xuHgAAAAAAAADAArYKlKvZs2fLiBEjZM6cOXLy5EmpXr26fPnll9KwYUOrmwYAAAAAAAAAsIDtAuXR0dEyYcIEMwEAAACwF4fDYcoxJicnW90Uv5KUlCTh4eESHx9vPh/4VkREhISFhVndDAAAbM12gXIAAAAA9gyQnzp1So4ePUogOJPPp1ixYrJv3z4JCQmxujm2VKBAAbMP+PwBALAGgXIAAAAAQe/w4cMmUJ4vXz4zafY0Acm/paamyrlz5yRPnjwSGhpqdXNsd5HiwoULZhwtVbx4caubBACALREoBwAAABDUNIP89OnTUqRIEYmNjbW6OX4bKE9MTDSlKgmU+15MTIx51GB50aJFKcMCAIAFCJQDAAAACPr625q1mzt3bqubAmQqV65cruOVQDlgYxERIoMH/z0PwGcIlAMAAACwBUqtwJ9xfAIwIiNFJkywuhWALXFPHQAAAABLrFq1ygQHPU3r16+3unkAAACwETLKAQAAAFiqf//+csstt6RZVqFCBcvaAwCAZVJTRf7889L8tdeKMG4E4DMEygEAAABYqkGDBtKhQwermwEAgPUuXhQpV+7S/LlzIoyvAfgMl6UAAAAAWO7s2bOSnJxsdTMC0syZM10la7777rsMz+tApqVLlzbPt27dWoLFwYMHpUuXLnLDDTdI3rx5pUCBAnLrrbfKrFmzzDa7+/3332XAgAFSr149iY6ONp/Fnj17svxe3bt391giqFKlSmnW++233+TZZ5+VGjVqmDYVL15cWrVqJZs2bcqx7QYAAN5BRjkAAAAAS/Xo0UPOnTsnYWFhJrt8woQJUrt27UzXT0hIMJPTmTNnzGNSUpKZ0tNlGjhNTU01U7BxbpMGgD/44AMTDE5fC37//v0SFRXl+hzScwaWM3veHx05csRsV/v27c2FAL3QsmzZMhPU1oD12LFjXeuuXbtWXn31VbnxxhulcuXKsmXLlmwdD/q56Oc3ffr0NMvz58+f5jXeeecdef/99+W+++6Txx9/3Byb+ju33XabLF68WO68885M30NfR99Hj1f9v2Al5/8jT/+fYE8cEz6UlCQRrtkk87Pdjodjx46ZC+gIHCkpKebxjz/+yPRvmF5Ajo2N9Wm7snuMEigHAAAAYInIyEgT5GzZsqU5cdq2bZtMnDjRBMu///57ufnmmz3+3rhx42T06NEZli9dulRy5cqVYXl4eLgUK1bMBOMTExMl2MTHx5vHZs2ayccffywvvvii2Wan2bNnmwzn48ePm2Cy88KCJ4EUmChbtqx8/vnnaZY9/PDD8sADD8hrr70mgwcPdp2sN2nSxGSQ60m6PqeBcj0eLvdZpD/R1s+0bdu2GZ5zf402bdqYzPU8efK4lmlZoTp16sjIkSNNxntm9Ni8ePGirF692m/urtALD4A7jgnvC4uPF+e9P998842kREeLv+J4QHo7duwQf3LhwoVsrU+gHAAAAIAlNPPZPftZg5AaVKxevboMHTpUvv76a4+/p88NHDgwTaBSM4qbN28u+fLl8xhI3rdvnwleatZ1sHFuk5Yh+fLLL2XDhg1y9913u4KvixYtkueff94EiDXY6/4ZaRazLn/33Xdl165dJkP6nnvuMRcjChYs6Fpv4cKFJltaA8wacC9VqpR069bN7Av3zLGmTZuaTMAPP/xQ+vXrZ9qir6MDtj7zzDNp2v3nn3+aE9j05Uuulg4EqxdN9HOJiYkxy9y32fl56fHg6XjxJCLiUn5n7ty55fz585n+XsOGDTMs03X14s9//vOfy76fHqfaXn0Nq49TvTCgATC9+OLcdtgbx4QPnT/vmr3rrrv8ska5N4+HuLg4GdLnSXmidgMpUaBwjr42vCc1NETibigh5X4/KKGpacufqYOnjsubm9bI+DemSTlnDX4fyOoFcScC5QAAAAD8hgY5NVD76aefmtt4Pd2+qyUwdEpPT9Y9nbDr62g96dDQUDNdLiiRgb6/e9Dycuvqa/8vMJvtda+Cc5uuu+46qVu3rnz00UemLrYzG/H06dPy4IMPmoC483Nweuyxx0yNcy1X0qtXLzl8+LC8/vrrJiCu5Uqcn6dmpWs2tl6g0ADzt99+K6NGjTIZ6Foqx93JkyfNXQJafuT++++XBQsWyHPPPWcugDgD+ErfU4PH6euJZ5dmYWvwWjPE9fV0e/Rz0KC2J/oZOD83j8dDJr+jQX2tg66PGvzXz3T8+PFpsscz89dff5m7Ji73fvqcvk9mx7EV/Kkt8A8cEz7g9vmaz9qPP29vHA/6dz8pMVFK5ysk5WOvydHXhvckhYjEiUj5wkUlwsOf9bBUh9mvun99+R2S3fciUA4AAADAr2h2uGZCXy5zN0ddLtDZsqXIV1/9/XPRonofr+d1GzXSguB//1y2rBZa9byu1mD/4QfJaZ07dzZZ3ho81uxkrVneqFEjKVGiRIZ1deBPzSTXdbRciWZd6eetWeEtWrQwZVz09dS8efNc2dlK62/r9MYbb8hLL72U5sKFDrKpgXUtg6J69uwpZcqUkffeey9NoDynvPLKK2abne644w6ZMWNGjr6HDsqpg3TWrFnTZOHr3Q667T///LOpAe9e6ia9NWvWyLp162T48OE52iYAAJCzCJQDAAAA8Cu7d+82pSeykqmLtDSD++mnnzYlWDTYrY86iKUnGgjXUit667xz4DS9QFGrVi3z2a9cudIVKHcPkut6OpiqlhN5++23zcCZN910k+t5/V0tA+Nei15rc+t+dacB5pygmd06+OvRo0fN9mr2tl4oyElaisadXlioWLGiKWmjGfP6c2YDjupnqLeZa6AdAP6RXnjr0+fveQA+w/84AAAAAJbQwGaRIkXSLNMMXa2prZnHWS2LcdXOncv8ufSlX44cyXzd9O3dsyfr6+YQ/TzvvPNOkwGuJUK07IzWffdk586dpixLUc2SzyTI6/Trr7+ajGgtuZK+3qe+hjutX+4sb+KkpUr++9//XtE2aTkYdxrcdw/ca7a6Ts6gee/evc1n8Pvvv6dZL6fpoJ0jRoyQ5cuXewyU6x0RrVu3NhcWNHufCz8AskTv0Hn9datbAdgSgXIAAAAAlujUqZMJZOqAnhqs3bZtm0yfPl1y5col//rXv3zXkOwMlOatdXOQZjA/+uijJsCsFxy0rrYnWkJEP3ctvaLzGljXz955gcJ5EePUqVOmfIuWZRkzZoyUL1/eZPz/9NNPMmTIEPO77jzVlVdXWotcy56407IqWt88M3phQAceXb169aWB8LxEj93ChQvLiRMnMjynmflao10vDmid+KpVq3qtHQAAIGcQKAcAAABgiXbt2pkg7eTJk02WsgZmNbiog0TqoJ64Mvfee68ZpHP9+vVmYM/MaMBbs6Fvv/12U2PcWaM8fSa/lkg5fvy4GWC1YcOGruVxcTpsl/ctW7Yszc9VqlS57PrOsivpM91zmmaKa8ma9HdF6IWDrl27yooVK2T+/PnmIgMAZJleVHSObxEbq6MJW90iwDYIlAMAAACwRP/+/c2EnKUlPt58803Zs2ePtGnT5rL1zHVAyhdffNEMyOkuOTlZzp07Z7LRnRni7hnhmjGtv3s1/vzzT5PFXqlSpcuup2VUslq6R+mgoVr6RQfevBK7du1yXUhQ8fHxkpSUJHnz5k2znn5u+ploLXh3/fr1MxcotH67XvgBgGzRAaOdJbG0NJhFdycBdkSgHAAAAACCTLdu3f5xHc101sxzHahy8+bNJltcg8F//PGHGejzlVdeMWVMtDSO1hjX19QLGxqEnjNnzhWXUnHSrOv//Oc/V/w6Y8eOlbVr15pA9bXXXmtKoHzyySfyww8/mGC1+10Jml3+2muvmXn9HTVt2jRzIUCnJ5980rXuHXfcYR71QoPSEjY333yzqX/uDOprOZXFixeb977nnntcvzt16lRzAaFu3bqmjM3cuXMzZPvnJugFAIBfIlAOAAAAADb11ltvSa1atUz2s2ZIh4eHS9myZaVLly6mJIvSOtxffvmlDBo0yAzoqUFzfV4Dyt6sAf5PWrVqZbK/33//fZNdrnXTq1evbmqYp79QcPLkSTPwprtJkyaZRx0I1D1Qnp4G0nVQTi0BM2vWLDNAqgbhX375ZRk8eHCaUjVbtmwxj+vWrTNTelquhkA5AAD+iUA5AAAAAAQwHdjycoNbOjkzpNPTgT979uyZaY1ypVnlngK/6bPBtZ65JzNnzsywLLN1s6pZs2ZmygoN/mc1cz3956SBcs2gzwrdTk/bCgAA/F/GHhAAAAAAAAAAADZCoBwAAAAAAAAAYGsEygEAAAAAAAAAtkaNcgAAAAAAAMAfhIeLOAck1nkAPsP/OAAAAAAAAMAfREXpyMBWtwKwJUqvAAAAAAAAAABsjYxyAAAAALbgcDisbgKQKY5PAIZ+F1y4cGk+Vy6RkBCrWwTYBhnlAAAAAIJaRESEhISEyPnz561uCpCpC/8LjOnxCsDG9LsgT55LkzNgDsAnyCgHAAAAENTCwsIkf/78cvToUUlISJB8+fJJeHi4CZ7jktTUVElMTJT4+HgJDSWfyteZ5BokP3LkiBQoUMAcrwAAwPcIlAMAAAAIesWKFZOYmBgTjDxz5ozVzfHLYO3FixfNZ8QFBGtokFyPUwAAYA0C5QAAAACCngZ/NRCpmeUpKSmSnJxsdZP8SlJSkqxevVoaNmxI6Q8L6GdOJjkAANYiUA4AAADAVgFzLbuiE/6mQVq9eBAdHU2gHAAA2BLF5wAAAAAAAAAAtkagHAAAAAAAAABga9xvCAAAAAAAAPgDHa+gQ4e/5wH4DIFyAAAAAAAAwB9ER4t8/LHVrQBsidIrAAAAAAAAAABbI1AOAAAAAAAAALA1AuUAAAAAAACAPzh/XiQk5NKk8wB8hkA5AAAAAAAAAMDWCJQDAAAAAAAAAGyNQDkAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAABsLdzqBgAAAAAAAAAQkbAwkZYt/54H4DMEygEAAAAAAAB/EB0t8tVXVrcCsCVKrwAAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAP7g/HmR3LkvTToPwGeoUQ4AAAAAAAD4iwsXrG4BYEtklAMAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAABsjUA5AAAAAAAAAMDWCJQDAAAAAAAAAGwt3OoGAAAAAAAAANCU1lCRRo3+ngfgMwTKAQAAAAAAAH8QEyOyapXVrQBsiUtTAAAAAAAAAABbI1AOAAAAAAAAALA1AuUAAAAAAACAPzh/XqRIkUuTzgPwGWqUAwAAAAAAAP7i2DGrWwDYEhnlAAAAAAAAAABbI1AOAAAAAAAAALA1AuUAAAAAAAAAAFsL+ED5oUOH5LnnnpMmTZpI3rx5JSQkRFatWpXp+t9//73Ur19fcuXKJcWKFZP+/fvLuXPnfNpmAAAAAAAAAID/CPhA+e+//y7jx4+XAwcOSLVq1S677pYtW+SOO+6QCxcuyOTJk6VXr14yffp06dixo8/aCwAAAAAAAADwL+ES4GrVqiXHjx+XQoUKyYIFCy4b9B42bJgULFjQZJzny5fPLCtbtqw8+uijsnTpUmnevLkPWw4AAAAAAAC4CQ0VqV3773kAPhPw/+O03IoGyf/JmTNnZNmyZdKlSxdXkFx17dpV8uTJI/Pnz/dySwEAAAAAAIDLiIkR+eGHS5POA/CZgM8oz6qtW7dKcnKy1HZelfufyMhIqVGjhmzevDnT301ISDCTe9BdJSUlmcmXkkK899rJIWkfvSEkm5+XN7fXF/xpe9m/wb/N7OPg3l72b3Bvry/2r79tsy9kd3uvlq/7hQAAAAByjm0C5TropypevHiG53TZmjVrMv3dcePGyejRozMs13ItOiioT8V6f5etKuzF91i82O+216v8cHvZv8G/zezj4N5e9m9wb69X96+fbrNfbe9V0nFwAAAAAAQmvzr7SU1NlcTExCytGxUVJSEhWU9zunjxouv30ouOjnY978nQoUNl4MCBaTLKS5cubWqau5dx8YXE2Yu89tqaxaYn6I2PJ0u4wzvvEdm1rd9sry/40/ayf4N/m9nHwb297N/g3l5f7F9/22ZfyO72Xi3nXYcAAABXTC+833jjpflt20R8naAJ2JhfBcpXr14tTZo0ydK627dvl0qVKmX5tWP+V9fJvYSKU3x8vOt5TzS47inAHhERYSZfcnjx5NlJT9AjvPQ+2f28fLG93uSP28v+Df5tZh8H9/ayf4N7e725f/11m73J1/00X78fAAAIQtoB27v373kA9gyUa+B7xowZWVrXUwmVrKzvLMHiTpeVKFEiW68HAAAAAAAAAAgOfhUoL1asmHTv3t0rr121alUJDw+XTZs2yf333+9arqVetmzZkmYZAAAAAAAAAMA+QsUm8ufPL3feeafMnTtXzp4961o+Z84cOXfunHTs2NHS9gEAAAAAAAAArOFXGeVX6qWXXjKPv/76qyv4/d1335n54cOHu9YbO3as1KtXTxo1aiS9e/eW/fv3y6RJk8ygnC1atLCo9QAAAAAAAAAAKwVFoHzEiBFpfn7//fdd8+6B8po1a8ry5ctlyJAhMmDAAMmbN6/07NlTxo0b59P2AgAAAAAAAAD8R1AEyh3ZGAW4fv36snbtWq+2BwAAAAAAAMi2kBCRG2/8ex6Az9imRjkAAAAA/6alEkNCQqRq1apWNwUAAGvkyqW1hS9NOg/AZwiUAwAAALCcjh/08ssvS+7cua1uCgAAAGwoKEqvAAAAAAhsgwcPlttuu01SUlLk2LFjVjcHAAAANkNGOQAAAABLrV69WhYsWCBTp061uikAAFjrwgWRKlUuTToPwGfIKAcAAABgGc0g79evn/Tq1UuqVauWpd9JSEgwk9OZM2fMY1JSkpmQfc7Pjc8PiuMB6XFM+FBiokRs22ZmkxITRSIixE7Hg/YLIiIjJSU0RJIYyzRgJIekfUxP96fZrykpPv0eye57ESgHAAAAYJm33npL9u7dK8uXL8/y74wbN05Gjx6dYfnSpUslFwOfXZVly5ZZ3QT4EY4HpMcx4X1h8fHS+n/z33zzjaRER4vdjofu/frKLhEzIbCsKpxJqDm2pHSv3Fe2b99uJl+5kM27MgiUAwAAALDE8ePHZeTIkTJixAgpUqRIln9v6NChMnDgwDQZ5aVLl5bmzZtLvnz5vNTa4KYZVxrwaNasmUT4YfYifIvjAelxTPjQ+fOu2bvuukvEDwe59ubxEBcXJ0P6PCkv3tlOyhW5JkdfG96THHIpSN74eLKEOzI+H3f0Lxmx/HMZ/8Y0KVeunM/a5bzrMKsIlAMAAACwxPDhw6VQoUKm9Ep2REVFmSk9PVkngHN1+AzhjuMB6XFM+IDb52s+az/+vL1xPISFhZmSM2GpDonwEHCFfwt3iMf9pvvT7NewMJ9+h2T3vQiUAwAAAPC5nTt3yvTp080AngcPHnQtj4+PN5lqe/bsMdnhGkgHAAAAvC3U6+8AAAAAAOkcOHBAUlNTpX///uYWXOe0YcMG2bFjh5kfM2aM1c0EAACATZBRDgAAAMDnqlatKp999pnHcixnz56VV155RcqXL29J2wAAsExIiEiZMn/PA/AZAuUAAAAAfC42NlbatWuXYbmWYlGengMAIOjlyiWyZ4/VrQBsidIrAAAAAAAAAABbI6McAAAAgN9YtWqV1U0AAACADZFRDgAAAAAAAPiDixdFbrnl0qTzAHyGjHIAAAAAAADAH6Smimza9Pc8AJ8hoxwAAAAAAAAAYGsEygEAAAAAAAAAtkagHAAAAAAAAABgawTKAQAAAAAAAAC2RqAcAAAAAAAAAGBr4VY3AAAAAAAAAMD/xMZa3QLAlgiUAwAAAAAAAP4gd26Ro0etbgVgS5ReAQAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAA/MHFiyKNG1+adB6Az1CjHAAAAAAAAPAHqaki//nP3/MAfIaMcgAAAAAAAACArREoBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAAAAgK2FW90AAAAAAAAAAP+TK5fVLQBsiUA5AAAAAAAA4A9y5xY5f97qVgC2ROkVAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAADAH8THi7RqdWnSeQA+Q41yAAAAAAAAwB+kpIgsXvz3PACfIaMcAAAAAAAAAGBrBMoBAAAAAAAAALZGoBwAAAAAAAAAYGsEygEAAAAAAAAAtkagHAAAAAAAAABgawTKAQAAAAAAAAC2Fm51AwAAAAAAAACISO7cIg6H1a0AbImMcgAAAAAAAACArREoBwAAAAAAAADYGoFyAAAAAAAAwB/Ex4t07Hhp0nkAPkOgHAAAAAAAAPAHKSkiCxZcmnQegM8QKAcAAAAAAAAA2BqBcgAAAAAAAACArREoBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAAAAgK2FW90AAAAAAAAAACKSK5fIuXN/zwPwGQLlAAAAAAAAgD8ICRHJndvqVgC2ROkVAAAAAAAAAICtESgHAAAAAAAA/EFCgkj37pcmnQfgMwTKAQAAAAAAAH+QnCwya9alSecB+FeN8jFjxmT7hUNCQmTEiBFX0iYAAAAAAAAAAPwrUP7CCy94DIQrh8ORYbkuI1AOAAAAAAAAAAia0iupqalppn379km1atXkwQcflI0bN8rp06fNtGHDBnnggQfkpptuMusAAAAAAAAAABCUNcr79u0r119/vcydO1dq164tefPmNdMtt9wiH3zwgZQvX96sAwAAAAAAAABAUAbKv/32W2natGmmz99xxx2yYsWKq2kXAAAAAAAAAAD+GyiPjo6WdevWZfr8999/b9YBAAAAAAAAACAoA+UPPfSQKbHSv39/2blzp6t2uc7369dP5s2bZ9YBAAAAAAAAkEW5cokcOXJp0nkA/h0oHz9+vHTu3FmmTZsmlSpVkqioKDPp/Ouvv24G9NR1fEFLvDzyyCNSsWJFyZUrl1x33XXSq1cvOXToUKbZ7vXr1zfrFitWzAT7z50755O2AgAAAAAAAJkKCREpUuTSpPMAfCb8Sn4pMjJS5syZI88884wsXrxY9u7da5aXKVNG7r77brnpppvEV4YMGSInTpyQjh07mgFGd+/ebQL4X375pWzZssUEw530Z62fXrlyZZk8ebLs379fJk6caDLhlyxZ4rM2AwAAAAAAAAACOFB+4cIF6dKli7Rv396UV6levbpYSQPemiEeGvp3cnyLFi2kUaNGJmD+0ksvuZYPGzZMChYsKKtWrZJ8+fKZZWXLlpVHH31Uli5dKs2bN7dkGwAAAAAAAABJSBAZOPDS/OTJIlFRVrcIsI1sl17RkiXLly83AXN/0LBhwzRBcueyQoUKyfbt213Lzpw5I8uWLTNBfmeQXHXt2lXy5Mkj8+fP92m7AQAAgECTWXlDAACQQ5KTRd5449Kk8wD8u/SKZnCvW7fOZGL7I605rlNsbKxr2datWyU5OVlq166doYxMjRo1ZPPmzZm+XkJCgpncg+4qKSnJTL6U5MXyVMkhaR+9ISSbn5c3t9cX/Gl72b/Bv83s4+DeXvZvcG+vL/avv22zL2R3e6+Wr/uFVihdurQ0bdpUHn74Ybnvvvskd+7cVjcJAAAAsC5QriVN7rrrLhk+fLg8/vjjUqpUKfEnU6dOlcTEROnUqVOG7JfixYtnWF+XrVmzJtPXGzdunIwePTrDci3Xohn2PhV7RbssW1YV9uJ7LF7sd9vrVX64vezf4N9m9nFwby/7N7i316v710+32a+29yr5yx2X3jRmzBiZN2+edOvWTZ544glp166duWNTSximv8sTAAAACCRXdPajg3VqdrYGkHUKDw+XqHQ1k0JCQuT06dPZet3U1FQT4M4KfT99j/RWr15tgtr333+/yXZxunjxouv30ouOjnY978nQoUNloLM+1P8yyjWbRk8I3Mu4+ELi7EVee23NYtMT9MbHkyXc4Z33iOza1m+21xf8aXvZv8G/zezj4N5e9m9wb68v9q+/bbMvZHd7r5bzrsNgpmP+6KR3Y37wwQfy4YcfmsB50aJF5cEHHzRjGKW/gxMAAAAI2kC5DuTpKUh9tTTI3aRJkyytq/XHK1WqlGbZb7/9Jvfee69UrVpV3n333TTPxcTEmEf3EipO8fHxruc90eC6pwB7RESEmXzJ4cWTZyc9QY/w0vtk9/PyxfZ6kz9uL/s3+LeZfRzc28v+De7t9eb+9ddt9iZf99N8/X5Wuvnmm800YcIE+fbbb02wfMaMGfLqq6/KDTfcYLLMdbr22mutbioAAADgvUD5zJkzxRs08K0d7KxIX0Jl3759JsM7f/78snjxYsmbN6/H9T0NQKTLSpQocVVtBwAAAOxGk2caNGggp06dkgMHDpjShDt37pQXXnhBRo4caZJYNHjuqfwhAAAA4E/8qvBksWLFpHv37tn+vePHj5sguWaLr1ixwmNHXLPMtUTMpk2bTFkWJy31smXLljTLAAAAAFzeypUrTfmVTz75xJSdqVatmkycONGUX9F+tybAvPzyy2bgz+XLl3t8jV9//dUE1X/88Uc5fPiwGf/nxhtvlGeeeUbatGnj820CAACAfV1VoHz//v2mPqHWItf64ul17dpVvO38+fPSsmVLk8GinfXrr7/e43qaaX7nnXfK3LlzZcSIEa6M8zlz5si5c+ekY8eOXm8rAAAAEMh+/vlnExz/97//LQcPHjSJLr169TL9fg2Uuxs8eLAZC0gfM7N37145e/asGRxU7/DUAVE18N62bVt5++23pXfv3j7YKgAA/IiWBo6L+3segH8HyrWmt3ZmtROrAXK95dLxvyKW7rXLfREo14yVjRs3yiOPPGLqluvklCdPHmnXrp3r57Fjx0q9evWkUaNGptOtgf5JkyaZbPQWLVp4va0AAABAINO65Dq2j/axta/frFkzCQ0NzXT9KlWqSN26dTN9XhNedHL35JNPSq1atWTy5MkEygEA9qN/V8uWtboVgC1dUaBcR7r/9NNPTeBZO76NGzeWWbNmmZInU6dONdkls2fPFl/Qsinq/fffN5O7MmXKpAmU16xZ09z2OWTIEBkwYIDJKu/Zs6eMGzfOJ20FAAAAApn2tzt06GASUrKiSZMmZsqOsLAwKV26tPzwww9X2EoAAADAR4HyBQsWSI8ePUzAWeuDq5IlS0rTpk1NeRN9fP311+XNN98Ub9uzZ0+21q9fv76sXbvWa+0BAAAAgtWVjCeU1XKKFy9eNCUdFy1aJEuWLJFOnTplur6OTaSTk9ZIV0lJSWZC9jk/Nz4/KI4HpMcx4UOJiRI6cqSZTR0zRiQyUux0PKSkpEhEZKSkhIZI0t9FK+DnkkPSPqan+9Ps15QUn36PZPe9rihQfuTIEbn11lvNvN566ezcOrVv317GjBnjk0A5AAAAAN949dVX5auvvpJvvvnG4/N33323qS/+xBNPZOt1Bw0aZGqSKy3lct9998m0adMyXV/vCB09enSG5UuXLjUDguLKLVu2zOomwI9wPCA9jgnvC4uPl9aTJ5v5JbfeKinR0WK346F7v76yS8RMCCyrCmcSao4tKd0r981QNtvbdPwbrwfKr7nmGlcmuXZECxYsKL///rtrZHrN6NA65gAAAACCx3vvvWfuHs3MjTfeKNOnT892oPzpp582JV20hOP8+fNNtlFiYmKm6w8dOlQGDhzo+lnPP7Rci449lC9fvmy9N/7OuNKAh9adj4iIsLo5sBjHA9LjmPAht0TUu+66SyR3brHT8RAXFydD+jwpL97ZTsoVuSZHXxvekxxyKUje+HiyhF8axjKNuKN/yYjln8v4N6ZJuXLlfNYu512HXg2U16lTR7777jtTekVpgHzChAmmRrkO7jllyhS57bbbruSlAQAAAPipXbt2Sd++fTN9vlKlSvLOO+9k+3X193RSOkioBrz1HGPDhg0SEpLxHt6oqCgzpacn6wRwrg6fIdxxPCA9jgkfcPt8zWftx5+3N44HHaskKTFRwlIdEuEh4Ar/Fu4Qj/tN96fZr2FhPv0Oye57ZT5E/WX0799frrvuOlddwBdffFEKFCggDz/8sHTr1k3y589vbssEAAAAEDwiIyPl8OHDmT5/6NAhUzrlaml2uQ7muWPHjqt+LQAAAMBrGeU6IKZOTnqbo9aX2bp1q7kyoNkg4eFX9NIAAAAA/JTeNTpz5kwZMGCA5M2bN81zOhDnjBkzcuTOUh3Y0/maAAAAgC/kWDRbM0duuummnHo5AAAAAH5m1KhR0qhRI6lRo4apK16lShWz/JdffpGpU6eajPJ58+Zl+fWOHDkiRYsWzVD3dPbs2RITE2NqngMAAAB+GygvUaKENGjQwDURIAcAAACCn45V9MUXX8hjjz0mTz31lKt+uMPhMAMzLVq0SOrWrZvl19PX0UGWGjZsKCVLljRlXT744AP57bffZNKkSZInTx4vbg0AAABwlYHye+65xwzmuWDBAvOzjixfr14908HVwPktt9zC4A4AAABAEGrWrJn88ccfsnnzZjO4pypfvrzUrFnT48Cbl9OpUyd577335M0335Tjx4+bci61atWS8ePHS9u2bb20BQAA+LGYGL1V6+95AP4dKNeOrDp58qSsWbPGTBo4HzlypCQnJ5sR6DXbZOXKlTndXgAAAAAW07KLGtDW6Wo88MADZgIAAP+jg2L/r7QZgACqUV6wYEGT6aHTvn37ZMmSJTJ58mQzOv3q1atzrpUAAAAA/Ma2bdtk9+7dJnFGy66k17VrV0vaBQAAAPg8UL59+3ZXNrlOGijPnz+/qUnYo0cPU4IFAAAAQPDQUitdunSRjRs3egyQKy2/QqAcAIArlJgo8vLLl+aHDROJjLS6RYBtXFGgvEiRInLixAkzQr0GxAcNGuQa1DO7dQkBAAAABAYdfHPr1q0ydepU0//XO0wBAEAOSkoSGT360vwzzxAoB/w9UK4D7WhdwkqVKknlypXNdP311xMkBwAAAILY2rVrZdiwYdKvXz+rmwIAAABYHyg/evSoGbxTS658/fXXMm7cOLO8Ro0aJrNEp/r160tsbGzOthYAAACAZbR/r+UWAQAAgGATeiW/VLhwYbnnnntk4sSJsmHDBjl16pQZyLNly5bmsX379lKsWLGcby0AAAAAyzz++OMyd+5cSUlJsbopAAAAgH8M5um0c+dOk1m+evVq8xgXF+eqYw4AAAAgeFSsWNEEyXVsokceeURKly4tYWFhGda77777LGkfAAAA4NNA+bRp00xgXMuv/PXXX2bE+3LlypmSK1qzUB+1Ew0AAAAgeHTq1Mk1P3jwYI/r6LhFZJwDAADAFoHyp59+WqpWrWpKrDhrkhcvXjznWwcAAADAb6xcudLqJgAAAAD+Eyg/fvw4g/gAAAAANtOoUSOrmwAAQHCLjhbZuPHveQD+HSh3D5IfOnRIjhw5IhUqVJDcuXPnZNsAAAAA+KGEhAT56aefzHnA7bffLrGxsVY3CQCA4KBjf9xyi9WtAGwp9Ep/ceHChVKpUiUpVaqU1KxZUzZs2GCWHzt2TG6++Wb5/PPPc7KdAAAAAPzAq6++asou1q9f3wza+d///td1HqAB8/fff9/qJgIAAAC+CZR/8cUXplOsHeFRo0aZwTyddFnJkiVlxowZV/LSAAAAAPyU9vF1vKIWLVrIe++9l+E8oGnTpvLhhx9a2kYAAAJaYqLIhAmXJp0H4N+B8jFjxkjDhg3lu+++k759+2Z4vm7durJ58+acaB8AAAAAPzFp0iS55557ZN68edKmTZsMz9eqVUt+/fVXS9oGAEBQSEoSefbZS5POA/DvQPkvv/wi999/f6bPX3PNNaZeIQAAAIDg8ccff8jdd9+d6fOFChWS48eP+7RNAAAAgGWB8ly5csn58+czfX737t1SuHDhq2kXAAAAAD9ToEABU4s8M9u2bZNixYr5tE0AAACAZYHyJk2ayKxZsyQ5OTnDc4cPH5Z33nlHmjdvnhPtAwAAAOAnWrZsKdOnT5dTp05leE5Lruh5QNu2bS1pGwAAAODzQPnYsWNl//79csstt8jbb78tISEh8s0338jw4cOlWrVqZlAfHeQTAAAAQPB46aWXJCUlRapWrWr6/noeoAk0Xbp0kdq1a0vRokVl5MiRVjcTAAAA8E2g/IYbbjADeWp5lREjRpjA+IQJE+Tll182gfI1a9ZI2bJlr+SlAQAAAPipEiVKyI8//igtWrSQjz76yJwHzJkzR7744gt58MEHZf369RIbG2t1MwEAAIBsC5crVKVKFVm+fLmcPHnSDOqTmpoq1113nRQpUsQ8r51mzTABAAAAEDw0a/zdd98109GjR815gJ4DhIZeUQ4OAAAAENiBcqeCBQuaEixOiYmJMnPmTJk4caLs2LHjal8eAADAL0T2au+11w5JShJZvFgiu7aViIgIr70PkNOcSTIAACCHREeLrFz59zwA/wyUaxB80aJFsmvXLhMgb926tbn9Ul24cEGmTZsmU6dONQN6li9f3lttBgAAAGCBMWPG/OM6eleplmcEAABXICxMpHFjq1sB2FKWA+UHDx6Uxo0bmyC5llVRMTExJnAeGRkpnTt3lgMHDsitt94qr732mtx3333ebDcAAAAAH3vhhRcuGyB3ll8kUA4AAICgDZQ///zzEhcXJ88++6w0aNDAzGtGSe/eveXYsWOmZvncuXOlUaNG3m0xAAAAAEtoPXJPy/bu3Suvv/66rF69WpYsWWJJ2wAACApakm/69EvzvXuLUJYP8L9A+bJly6RHjx4ybtw417JixYpJx44dpVWrVrJw4UIG8AEAAABsRs8BypUrZ8Yoeuihh6Rfv34yb948q5sFAEBgSkwUefLJS/PduxMoB3woy5Htv/76S2677bY0y5w/P/LIIwTJAQAAAJtr2LChLF682OpmAAAAANmW5eh2SkqKRKcbbdf5c/78+bP/zgAAAACCyqZNm0igAQAAQHCXXlF79uyRn376yfXz6dOnzePOnTulQIECGdavWbNmTrQRAAAAgB+YPXu2x+WnTp0y9ck//fRT6dWrl8/bBQAAAPg0UK6j13sawb5Pnz5pfnaOdq9Z6AAAAACCQ3etlZqJ2NhYee6552TkyJE+bRMAAADg00D5jBkzcuQNAQAAAASmuLi4DMs0QaZgwYKSN29eS9oEAAAA+DRQ3q1btxx5QwAAAACBqUyZMlY3AQAAALC+9AoAAAAAAAAAL4mKEvnyy7/nAfgMgXIAAAAAWRIaGmpKrWSHrp+cnOy1NgEAEFTCw0VatbK6FYAtESgHAAAAkCU6UOfnn38uv/76q9x1111yww03mOW//fabLF26VKpWrSrt2rWzupkAAABAthEoDzCRvdp77bVDkpJEFi+WyK5tJSIiwmvvAwAAgMBUokQJOXLkiPzyyy+uILnT9u3bpWnTpmadRx991LI2AgAQ0DQ288EHl+YfekiE+AzgM6G+eysAAAAAgWzChAny5JNPZgiSq8qVK5vn/u///s+StgEAEBQSE0V69Lg06TwAnyFQDgAAACBL9u/ff9k7D/U5XQcAAAAIytIrq1evvqIXb9iw4RX9HgAAAIK75BsCk9Ygf+ONN6Rz585SsmTJNM9pgFyfq1atmmXtAwAAALwaKG/cuHG2Rrd3OBxm/ZSUlCtuGAAAAAD/MmXKFDOIZ8WKFeXee++VChUqmOU7d+40g3zqecDcuXOtbiYAAADgnUD5ypUrs//KQA4gkw0AAMB/1K9fXzZs2CAjRoyQzz77TC5evGiWx8TEmAD66NGjySgHAABA8AbKGzVq5P2WAAAAAAiI8isaJE9NTZWjR4+aZUWKFJHQUIY/AgAAQJAHygEAAADAnQbGo6OjJU+ePATJAQAAYN9AeXx8vHzyySfy008/yenTp01GiTutUf7ee+/lRBsBAAAA+IlNmzbJ8OHDZfXq1ZKYmChLly6Vpk2byrFjx6Rnz54yYMAAM8YRAAC4AlFRIvPn/z0PwL8D5Xv37pUmTZrInj17pECBAiZQXqhQITl16pQZwDM2NtZklgAAAAAIHt9//70JipcsWVK6dOki7777rus5PQfQ84K3336bQDkAAFcqPFykY0erWwHY0hXdI/nMM8+YTvD69etlx44dZnT7jz76SM6dOyfjx483g/l88803Od9aAAAAAJYZNmyYVK5cWbZt2yYvv/xyhuc1mUYH+wQAAABsESj/9ttvpU+fPnLrrbe66hFqsDwqKsoE0e+44w55+umnc7qtAAAAACz0ww8/SI8ePUy/X0stpqeZ5ocPH7akbQAABIXkZJGPP7406TwA/y69cuHCBSlbtqyZz5cvn+kka4a5U926dWXw4ME510rAJiJ7tffaa4ckJYksXiyRXdtKRESE194HAAAEL+1DpB+byN2BAwcowQgAwNVISBC5//5L8+fOXSrFAsB/M8qvvfZa2b9/v5kPDw83mSNahsVJb8WMjo7OuVYCAAAAsNxtt90mCxYs8Pjc+fPnZcaMGdKoUSOftwsAAAC4Wld0WUoH8Fm4cKGMGjXK/Ny9e3cZN26cnDx50mSYzJkzR7p27XrVjQMAAADgP0aPHm0C4a1atZIHH3zQLPv5559l9+7dMnHiRDl69KiMGDHC6mYCAAAAvgmUP/fcc6Y+YUJCgqlPqIP6HDx40GSXhIWFSefOnWXSpElX8tIAAAAA/FSdOnVk8eLF8sQTT7gSYwYNGmQey5cvb56rXr26xa0EAAAAfBQo19IrOjlpmZV3333XTAAAAACCj8PhkLNnz0q9evXk999/ly1btsjOnTvNHaUaJK9Vq5bHAT4BAACAoK1R/sgjj8iGDRsyfX7jxo1mHQAAAADBITExUQoVKiSvvvqq+blGjRrSsWNH6dSpk9SuXZsgOQAAAOwXKJ85c6bs2rUr0+fj4uJk1qxZV9MuAAAAAH5ESy4WK1bMPAIAAADB5ooC5f9E65XHxMR446UBAAAAWKR79+4ye/Zsk10OAAC8IDJSZMaMS5POA/C/GuULFy40k9P06dNl+fLlGdY7deqUWX7LLbfkXCsBAAAAWK5atWry+eefS5UqVUzQvGzZsh4TZO677z5L2gcAQMCLiNAr01a3ArClLAfKt23bJh9//LGZ1/qDWqP8xx9/TLOOLs+dO7c0bNhQJk+enPOtBQAAAGCZBx980DU/YsQIj+voOUFKSooPWwUAAAD4MFA+dOhQM6nQ0FB57733pHPnzjnQBAAAAAD+atiwYfLAAw9I9erVZeXKlVY3BwCA4JacLPLNN5fm77pLJDzLoTsAV+mK/relpqZe7fsCAAAACAD/+te/pGrVqiZQ3qhRIzl+/LgULVpUli1bJk2bNrW6eQAABJeEBJHWrS/NnztHoBwIlME84+Li5I033pAhQ4aYSed1mS+tXr1a2rZtK6VLl5bo6GgpVqyYtGjRQtauXetx/e+//17q168vuXLlMuv2799fzukXDwAAAIAscTgcVjcBAAAAyFFXfFlq0KBB8sorr2TILteyLE8//bRMnDhRfGHHjh3mPR9//HET+D558qTMnTvX1En/6quvTNDcacuWLXLHHXdI5cqVTQ31/fv3m3bu3LlTlixZ4pP2AgAAAAAAAACCIFA+adIkmTJlinTo0MEEzDXwrLZv326W61SyZEkZMGCAeFuvXr3M5K5Pnz5y3XXXydSpU9MEyrW+YsGCBWXVqlWSL18+s6xs2bLy6KOPytKlS6V58+Zeby8AAMEisld7q5sAAAAAAIB1gfJ33nnHlDuZP39+muV16tSRDz/8UOLj4+Xtt9/2SaDcEy2rUqRIETl16pRr2ZkzZ0wdRW2TM0iuunbtapbpthAoBwAAADLas2eP/PTTT2b+9OnT5lHvyixQoIDH9WvWrOnT9gEAAACWBMq1o/zUU09l+vxdd90lX3/9tfiSBsITExPl2LFjMnv2bPnll19MBrnT1q1bJTk5WWrXrp3m9yIjI6VGjRqyefPmTF87ISHBTO7vpZKSkswULJzbEkzbBP/ev0khEvBCsvl5enObk0PSPgb79vqCP22vP+5fBPd3NLIvmPffiBEjzJT+Lk5PtctDQkIkJSUlS6/7ww8/yKxZs2TlypXmHKNw4cJy2223yUsvvSQVK1bMsfYDAAAAXgmU6yj3P//8c6bP63Oa0e1L999/v3zzzTeu4Pdjjz2WpjN/6NAh81i8ePEMv6vL1qxZk+lrjxs3TkaPHp1huZZr0ez1YKOZ9whefrV/Y4Ng9O7Fi/1um1cVDrfV9nqVH26vX+1fBPd3NLLtwoULEoxmzJjhtdceP368rF27Vjp27CjVq1eXw4cPy7Rp00xG+vr166Vq1apee28AAADAXZbPtlevXm1qkWsAXDuyOpCn1vfu16+f5M6d26xz/vx507F99913zYCe2aUDg2pWeFZERUWZbBWnf/3rX6Ze+r59+0xWir6OZpA7Xbx40fV76UVHR7ue92To0KEycODANBnlpUuXNqVa3Mu4BEMWlJ6gN2vWTCIiIqxuDmywfxNnL5JAF9m1rd9ss2YaaxC18fFkCXcE//b6gj9trz/uXwT3dzSyz3nXYbDp1q2b115b+9jz5s0ziS5OnTp1kmrVqpn+/dy5c7323gAA+CX9mzht2t/zAPwvUN6kSROZM2eOdO7cWV588UXZsmWLKW0ycuRIKVGihFnn4MGDJjit644ZMybbjdFgvP5uVujAoZUqVXL9rOVTnLp06WKyULp37y4LFiwwy2JiYsyjewkVJ62p7nzeEw2uewqw64lsMJ7MBut2wf/2r8NLwT5fyu5n6Ytt1iBqhMM+2+tN/ri9/rR/Edzf0cg+9l321atXL8Oy66+/XqpUqWL6+wAA2I72J/r2tboVgC1lOVCu9QadtNzIihUrZOHChbJkyRLZu3evWd6iRQtp2bKltGnTJk22d1Zp4Durt3Z6KqHipBkpOtioZqFoprgGwZ3rO0uwuNNlzmA/AAAAAOvoecdff/1lguV2H0PIlxgrAcF+POh4ZmfPnrW6GQHLOfbEH3/8IWFhYeIvtJqA+11JCPzjQStFhISGSkpoSMCPeWUnyf8wppbuz4jISHPs+PJvS3bf66oKnd5zzz1myinFihUzWeA5QQPk2snWP4QaKNf6huHh4bJp0yZTz9z9S1Wz492XAQAAALDGBx98IAcOHLjsHap2G0PIlxgrAe44HpDejh07rG5C8EtJkcLbtpnZ4zfeKOJHFyZ8dTz0GvCU7BIxEwLLqszG1IotKd0r9zV3DPryrsHsjiGUrUD5lWSJe9uRI0fM4KLuTp06JZ988ompI+58Ln/+/HLnnXeaOoc6yGfevHnNci0nc+7cOVN3HQAAAIB1fvvtN+nbt6/UrVv3srXR7TKGkC8xVgKC+XiIi4uTIX2elCdqN5ASBQpb3ZyAlBoaInE3lJByvx+U0FT/qK/4494/ZMqShTKm3YNyXbHgqRIQkpggVUaNMPO/jp4sjsiMpYCD+Xhw7td3u/eRyqXL5uhrQywbUyvu6F8yYvnnMv6NaVKuXDm/HUMoW4Fyrf2tU1aD6u6DaXrL3XffLaVKlZI6deqYoPiff/5pyrdovfSPPvoozbpjx441dRAbNWokvXv3lv3798ukSZNMh1rLxgAAAACwxuHDh6VVq1YmwUXHGbrcrdx2G0PIl/gMEYzHg36fJCUmSul8haR87DVWNycgaQmMOBEpX7io18bLya4DR49IQny8lMqXXyoG035NiHfNXl+4qEhUtNjpeHDu19DUVL851nD1Y2qFpTrM97B+H/vy70p23ytbgXLNyK5YsaL4k0ceeUQ+/PBDmTJliskkL1iwoNx2220yb948adCgQZp1dYDP5cuXy5AhQ2TAgAEmq7xnz57m1k0AAAAA1jh9+rRJgNH+/Jo1axg/CAAAAD6XrUC53v7YuXNn8Sd6a6ZOWVW/fn1Zu3atV9sEAAAAIGvi4+OlTZs2ps6pJrXcqPVYAQAAAB+7qsE8AQAAAOBKpaSkSKdOnWTdunWycOFCU5scAAAAsAKBcgAAAACWGDRokCxatMhklJ84cULmzp2b5vmsjo8EAAAAXC0C5QAAAAAssWXLFvP4xRdfmCk9AuUAAADwu0B5amqqd1sCAAAAwFZWrVpldRMAAPAvYWGS3OFh1zwA3yGjHAAAAAAAAPAH4RGSetc9VrcCsKVQqxsAAAAAAAAAAICVyCgHAAAAAAAA/EFqioTsjTOzjjLlREIpvwL4CoFyAAAAAAAAwB8kJUnEy8+Z2cRpc0WiCJQDvkLpFQAAAAAAAACArREoBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAAAAgK0RKAcAAAAAAAAA2Fq41Q0AAAAAAAAAICJhYZLSpqNrHoDvECgHAAAAAAAA/EF4hKS07WR1KwBbovQKAAAAAAAAAMDWyCgHAAAAAAAA/EFqqoQcOmBmHcVLioSS4wr4CoFyAIDXRPZqb3UTAAAAACBwJCVKxAsDzGzitLkiUdFWtwiwDS5LAQAAAAAAAABsjUA5AAAAAAAAAMDWCJQDAAAAAAAAAGyNQDkAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQAAAAAAAADA1sKtbgAAAAAAAAAAEQkLk5TmbV3zAHyHQDkAAAAAAADgD8IjJKVjV6tbAdgSpVcAAAAAAAAAALZGRjkAAAAAAADgD1JTRU4cuzRfKFYklBxXwFcIlAMAAAAAAAD+IClRIof2MbOJ0+aKREVb3SLANrgsBQAAAAAAAACwNQLlAAAAAAAAAABbI1AOAAAAAAAAALA1AuUAAAAAAAAAAFsjUA4AAAAAAAAAsDUC5QAAAAAAAAAAWwu3ugEAYCeRvdp77bVDkpJEFi+WyK5tJSIiwmvvAwAAAADwktAwSWl8l2segO8QKAcAAAAAAAD8QUSEpDz0qNWtAGyJ0isAAAAAAAAAAFsjoxwAAAAAAADwBw6HyLkzl+bz5BMJCbG6RYBtECgHAAAAAAAA/EFigkQO7Hlpdtpckahoq1sE2AalVwAAAAAAAAAAtkagHAAAAAAAAABgawTKAQAAAAAAAAC2RqAcAAAAAAAAAGBrBMoBAAAAAAAAALYWbnUDANhXZK/2VjcBAAAAAAAAIFAOAAAAAAAA+IXQMEmp29g1D8B3CJQDAAAAAAAA/iAiQlIeedLqVgC2RI1yAAAAAAAAAICtkVEOAAAAAAAA+AOHQyQx4dJ8ZJRISIjVLQJsg4xyAAAAAAAAwB8kJkjkk13M5AqYA/AJAuUAAAAAAAAAAFsjUA4AAAAAAAAAsDUC5QAAAAAAAAAAWyNQDgAAAAAAAACwNQLlAAAAAAAAAABbI1AOAAAAAAAAALC1cKsbAAAAAAAAAEBTWkMltdZtrnkAvkOgHAAAAAAAAPAHEZGS/Phgq1sB2BKXpgAAAAAAAAAAtkagHAAAAAAAAABgawTKAQAAAAAAAH+QEC+Rj3Ywk84D8B0C5QAAAAAAAAAAWyNQDgAAAAAAAACwNQLlAAAAAAAAAABbI1AOAAAAwBLnzp2TUaNGSYsWLaRQoUISEhIiM2fOtLpZAAAAsKGgC5Q/+uijpoPdunVrj88vWrRIatasKdHR0XLttdeajnlycrLP2wkAAADY3bFjx2TMmDGyfft2uemmm6xuDgAAAGwsqALlmzZtMhkoGgT3ZMmSJdKuXTspUKCAvPbaa2b+pZdekn79+vm8rQAAAIDdFS9eXA4dOiR79+6VCRMmWN0cAAAA2Fi4BAmHwyH9+/eXrl27yooVKzyuM3jwYKlevbosXbpUwsMvbXq+fPnk5ZdflqeeekoqVark41YDAAAA9hUVFSXFihWzuhkAAPiP0FBJrVbTNQ/Ad4ImUD5nzhz55Zdf5NNPP/UYKN+2bZuZXn/9dVeQXPXp00fGjh0rCxYskOHDh/u41QAAAACyKyEhwUxOZ86cMY9JSUlm8mXpmLNnz0owSElJMY9//PGHhIWFiZ3lzZtXYmNjxc6c/498+f/J28d3RGSkpISGSFKI1a0JTMkhaR/9gSMsVKKioyU1NDS49mtkpCQ9NUzsejwE7X4Ncsn/cEzo96/5Hk5J8enfluy+V1AEyrVzOmTIEBk2bFimGSmbN282j7Vr106zvESJElKqVCnX8/7cEfe2YOsMIS32b/BjH1vPmx05X5ychHDsWIb/v8GB/ec748aNk9GjR2dYrneO5sqVy5I2BYsdO3ZY3QT4kWXLlkmw6N6vr+wSMROu3KrCfhRGir1JRt8+WQ6ImAlBcjywX4PzmIgtKd0r9zXj0ujkKxcuXMjW+n70DXfldACgmJgYGTBgQKbraO1DZx3E9HTZwYMHM/1du3XEg6kzhIzYv8GPfWyh2PDAPjlZvNh7r40s4f9vYMtuRxxXbujQoTJw4MA0iSylS5eW5s2bm9KKvhAXFydD+jwpT9RuICUKFJZAlxoaInE3lJByvx+U0FSH2NXBU8flzU1rZPwb06RcuXJi5wt/+jepWbNmEhERIYHO+f/1xTvbSbki11jdnICkyRraD218PFnC/eQrYs3vv8pz82fJu937SOXSZa1ujq1483hgvwbnMRF39C8Zsfxzn/99dSY7B2SgPDU1VRITE7NczzAkJMRkPLzyyivy73//2yzLzMWLF12/l54O/nm5D84fOuK+EGydIaTF/g1+7GPrJc5eFNAnJ5Fd23rnhfGP+P8bHLLbEceV0z69p369/v/x1f8hLU+SlJgopfMVkvKx1wTFXVFxIlK+cFGJ8JMgmBXCUh1mv+r+5fvYt/+nfPH/VfevnY/vnKD9UH/5DENSUiUhPl5CU1P9pk05IiFeIgb2NLNJk98TiYoWOx0PQbtfbSI8k2PCqr+v2X0vvwqUr169Wpo0aZKldTVNXwff1EE469WrJ+3bt7/s+ppxrtxLqDjFx8e7nvfXjrgvBet24RL2b/BjH1vH4QjskxOOG+vx/zewse8AAEBOCEnMGLsC4H1+FSjXwPeMGTOytK6WS/n222/l66+/NgN47tmzx/VccnKyySDXZYUKFTJZ386SK1qCRbPB3emyW2+9NYe3BgAAAAAAAAAQCPwqUK4DcXbv3j3L6//555/m8b777svw3IEDB0zNmylTpsjTTz8tNWrUMMs3bdqUJiiutcn3798vvXv3zpFtAAAAAAAAAAAEFr8KlGdX06ZN5bPPPsuwXIPeZcqUkeeff16qVatmllWpUsVkrE+fPl0ee+wxUxNHvfnmm6bWeYcOHXzefgAAAMDupk2bJqdOnTIJLOqLL74wiSyqX79+kj9/fotbCAAAADsI6ED5tddea6b0NIP8mmuukXbt2qVZPmHCBGnbtq0ZhPOBBx6QX375xXTMe/XqJZUrV/ZhywEAAACoiRMnyt69e10/a1lFnVSXLl0IlAMAAMAnQsVGWrdubTrdJ06cMNkpOj9s2DB5/fXXrW4aAAAAYEs6rpDD4fA4lS1b1urmAQAAwCYCOqM8M+4De6anWebpM80BAAAAAAAAy4WESGrFG13zAHwnKAPlAAAAAAAAQMCJjJLkZ8ZY3QrAlmxVegUAAAAAAAAAgPQIlAMAAAAAAAAAbI1AOQAAAAAAAOAPEuIlYsAjZtJ5AL5DjXIAAAAAAADAT4ScO2N1EwBbIqMcAAAAAAAAAGBrBMoBAAAAAAAAALZGoBwAAAAAAAAAYGsEygEAAAAAAAAAtkagHAAAAAAAAABga+FWNwAAAAAAAACAiISESGqZ8q55AL5DoBwAAAAAAADwB5FRkjx8vNWtAGyJ0isAAAAAAAAAAFsjUA4AAAAAAAAAsDUC5QAAAAAAAIA/SEiQiOeeMJPOA/AdapQDAAAAAAAAfsEhIcePuuYB+A4Z5QAAAAAAAAAAWyNQDgAAAAAAAACwNQLlAAAAAAAAAABbI1AOAAAAAAAAALA1AuUAAAAAAAAAAFsLt7oBAAAAAAAAAFSIpBYv5ZoH4DsEygEAAAAAAAB/EBUlyWOmWt0KwJYovQIAAAAAAAAAsDUC5QAAAAAAAAAAWyNQDgAAAAAAAPiDhAQJH/m0mXQegO9QoxwAAAAAAADwCw4JPbTfNQ/Ad8goBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAAAAgK0RKAcAAAAAAAAA2Fq41Q0AAAAAAAAAoELEUbiIax6A7xAoBwAAAAAAAPxBVJQk/etNq1sB2BKlVwAAAAAAAAAAtkagHAAAAAAAAABgawTKAQAAAAAAAH+QmCDhLw0xk84D8B1qlAMAAAAAAAD+wOGQ0L27XPMAfIeMcgAAAAAAAACArREoBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgagXIAAAAAAAAAgK2FW90AAAAAAAAAAJc48uSzugmALREoBwAAAAAAAPxBVLQkTXnf6lYAtkTpFQAAAAAAAACArREoBwAAAAAAAADYGqVXAADIIZG92nvttUOSkkQWL5bIrm0lIiLCa+8DAAAAwEKJCRL+ylgzm/zU8yKRUVa3CLANAuUAAAAAAACAP3A4JHTHNtc8AN+h9AoAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAABsjUA5AAAAAAAAAMDWwq1uAAAAAAAAAIBLHJFRVjcBsCUC5QAAAAAAAIA/iIqWpNc/sLoVgC1RegUAAAAAAAAAYGsEygEAAAAAAAAAtkbpFQAAAAAAAMAfJCVK+JsTzWzyE4NFIiKtbhFgGwTKAQAAAAAAAH+QmiqhW39yzQPwHUqvAAAAAAAAAABsjUA5AAAAAMskJCTIkCFDpESJEhITEyN16tSRZcuWWd0sAAAA2AyBcgAAAACW6d69u0yePFkeeugheeWVVyQsLExatmwp3333ndVNAwAAgI1QoxwAAACAJTZu3CgffvihTJgwQQYPHmyWde3aVapWrSrPPvusfP/991Y3EQAAADZBRjkAAAAASyxYsMBkkPfu3du1LDo6Wnr27Cnr1q2Tffv2Wdo+AAAA2AcZ5VfA4XCYxzNnzkgwSUpKkgsXLpjtioiIsLo5yGHs3+DHPg5u7N/gxv4NDs6+obOviH+2efNmqVixouTLly/N8ltvvdU8btmyRUqXLu2xrrlOTqdPnzaPJ06cMP+ffMG8Z2io/Hb0oJxOjJdAlxoaIhdyFZefDxyS0FT7HsOHTp+QxJQU+fXXX13HlR2lpKSYv0v6f1AvZgW6/fv3S3KqI2j+v1rBH78j4k4dlfDISNlx9IgkhgZPHmhIYqJU/t/89gN/iiMyUux0PATrfg12qf9wTOjfV+036d/W48eP+6xdZ8+ezVb/PMRBT/6K/sh66rADAAAAmgVdqlQpq5sRELTEyjXXXCMrVqxIs3zbtm1SpUoVeeutt+Sxxx7L8HsvvPCCjB492octBQAAQLD3z8kovwIlSpQwH3DevHklJCREgikLSi8A6Lalz+pB4GP/Bj/2cXBj/wY39m9w0PwTzVrRviKy5uLFixIVFZVhuZZfcT7vydChQ2XgwIGun1NTU002eeHChYOqf+5LfA/BHccD0uOYgDuOBwTKMZHd/jmB8isQGhoa1FlCekD700GNnMX+DX7s4+DG/g1u7N/Alz9/fqubEFBiYmLSlFBxio+Pdz3viQbX0wfYCxQo4KVW2gvfQ3DH8YD0OCbgjuMBgXBMZKd/TrEfAAAAAJYoXry4HDp0KMNy5zKy8wEAAOArBMoBAAAAWKJGjRqyY8cO10CoThs2bHA9DwAAAPgCgXK46O2ro0aN8lgnEoGP/Rv82MfBjf0b3Ni/sKsOHTpISkqKTJ8+3bVMS7HMmDFD6tSpY2pdwjf4HoI7jgekxzEBdxwPCNZjIsShVc0BAAAAwAL333+/fPbZZzJgwACpUKGCzJo1SzZu3CgrVqyQhg0bWt08AAAA2ASBcgAAAACW0YE7R4wYIXPnzpWTJ09K9erV5cUXX5S77rrL6qYBAADARgiUAwAAAAAAAABsjRrlAAAAAAAAAABbI1AOAAAAAAAAALA1AuWQhIQEGTJkiJQoUUJiYmKkTp06smzZMqubhRzwww8/yJNPPilVqlSR3Llzy7XXXmsGzNqxY4fVTYOXjB07VkJCQqRq1apWNwU56KeffpK2bdtKoUKFJFeuXGb/vvrqq1Y3Czlg586d8sADD0ipUqXMvq1UqZKMGTNGLly4YHXTANjUo48+avoSrVu3zvBc2bJlzXPpp8cff9yStsL6Y0ItWrRIatasKdHR0eZ8Y9SoUZKcnOzzdsI7Vq9ebfqhpUuXNvu4WLFi0qJFC1m7dm2GdRs3buzxO0LXhz2PCfX9999L/fr1TV9X1+3fv7+cO3fO5+2Gd6xYsUIeeeQRqVixotnH1113nfTq1UsOHToUkN8R4VY3ANbr3r27LFiwQJ5++mm5/vrrZebMmdKyZUtZuXKl+TJD4Bo/frz5Y9WxY0czMNbhw4dl2rRppiO7fv16gqlBZv/+/fLyyy+biyIIHkuXLpU2bdrIzTffbAa7y5Mnj+zatcvsbwS2ffv2ya233ir58+c3FzX1Qsi6detMgOHHH3+UhQsXWt1EADazadMmcy6ggY/M1KhRQwYNGpRmmZ4cw57HxJIlS6Rdu3Ym+PHaa6/J1q1b5aWXXpIjR47Im2++6fP2IudpklVoaKi5IKZBTh10WQdfbtiwoXz11VcZAlx68X/cuHFplmlSHux5TGzZskXuuOMOqVy5skyePNmcw0ycONEki+j3BwLfkCFD5MSJEybupDHF3bt3m7jTl19+afa/HiOB9B3BYJ42t3HjRpNBPmHCBBk8eLBZFh8fbwKoRYsWNVf+ELh0/9WuXVsiIyNdy/QPUrVq1aRDhw7mjxmCh2alHj16VFJSUuTYsWPyyy+/WN0kXKUzZ86Y4EO9evXMBU3tkCJ46IWt559/3vxf1Tt/nLp16yazZ882Hc6CBQta2kYA9qGnhbfffrsJZmh2mJ4P6Elu+oxyT8th32NC/35FRESYgHp4+KU8vOHDh5u/cdu2bTN3SiH46J1vmjWqF86+/vpr13K9YMJ5iD1ldkxoEqYGS3/77TfJly+fWfbuu++aO1W++eYbad68uYWtRk7dYVC/fv0056q6rFGjRuZcRy+eBtJ3BGfcNqeBl7CwMOndu7drmWYL9OzZ02S1abYbApcG19yD5Eqv8GmHdvv27Za1CzlP/xDp/+epU6da3RTkoHnz5slff/1lSupox+P8+fOSmppqdbOQgxdC1DXXXJNmefHixc3+Tv/9DQDeNGfOHHPiqn9z/kliYqL5mwR7HxMaCNdJzyWdQXLVp08fE2TXvimCk5ZXKFKkiJw6dcrj81p6h9Ia9uLpmNC+rpb17dKliytIrrp27Wrukp0/f75FrUVOatiwYYaELl2md8tmFnfy5+8IAuU2t3nzZpOt6P6lpfRWcKVX/hBctNOqgbfY2Firm4Icohnk/fr1M3XA9G4BBI/ly5eb7+cDBw7IDTfcYDqU+vMTTzxh7v5BYNOMCqUXp/XvrV6c/uijj8yt6lq7kTJKAHzl7Nmz5tbpYcOGZbhFOr1vv/3WBET0b5JmmL/yyis+ayf865jQc0mld7Cmv4Veb613Po/goEFPzQTVzGA9LvQiipbU8FSWQ/swefPmNceOlg5MSkqypM2w9pjQUkwaEE3/HaHJIJp5zndE8Dp37pyZPMWd/P07ghrlNqfF9TVzLT3nsoMHD1rQKnjTBx98YIJuOlgcgsNbb70le/fuNUFVBBctlaSdy3vuuccEU7WW26pVq0wNUM3W+Pe//211E3EVtH7jiy++aG5P14HQnNLfoggA3qb9wpiYGBkwYMBl19Mxb/T2ar14e/z4cVO7Wsc50nMGHRsH9jomnAO1ZXY+yblkcLn//vtNqQxnoPOxxx4zAS535cuXlyZNmpjkHb3rRO8q0D6NBsY0GQD2Oib+6TtizZo1PmwtfGnq1Knm7rNOnToF3HcEgXKbu3jxokRFRWVY7hysRZ9H8NArvX379pW6deuaGrgIfHqSOnLkSNMh0VvdEFz0KrzW+9OBcl599VWz7L777jOdjrffftucxGo5JQQuzcbUWxPbt28vhQsXNgMgaeBcsyt0gE8AyA4tz6V/I7JCzwFCQkLMyalmhevFV0/nBe7cL+qpHj16yN13320GaNO72zSLGPY5JpznipmdTzpLjCGwjwenf/3rX2YgX70DbtasWeZ1NKHD3XvvvZfm54cfftiU5nnnnXfMRZfbbrsth7YEgXBM/NN3BPGm4Doe3MvCjh492lxIadq0qQTadwSlV2xOswQSEhIyLHfe0q/PIzgcPnxYWrVqJfnz53fVpkfg08GStPaXnpwi+Di/gx988ME0yzt37mwedSwJBK4PP/zQdAydAxrpRRDtPOqFTL3dXS+EAUB26Mmp/u3IyvT777+b33nqqafMuDZ6wS679ARZT2w1MKJ3PMFex4Szn5LZ+STnksFxPDhpqYxmzZrJI488YupOb9y4Ubp37/6P76mBVMXdr/Y7JviOsNfx4EzOvPfee83gz3qOkxX+9h1BRrnN6e0uWoYjPectMlpfDoHv9OnTJttHSzXo7U3s1+ApyzF9+nRzW5P7ra3a6dAaX3v27DH1rDWQjsCk/1d//fXXDIM9Fi1a1DyePHnSopYhJ7zxxhty8803Z8jAbNu2rSlnoHUb77zzTsvaByDwVKpUSWbMmJHl8wCtN/7111/Lp59+avoNThr41kw/Xab9iPTjGbkrXbq0eTxx4kQObAEC6ZhwllPQc0fnceCky5zjXiFwj4fMaJkN7a9oRrEeF5cLePIdYd9jwv07Ij1dRlwiuI6Hffv2SfPmzU1y5uLFi00N8qzwt+8IAuU2p1cAV65caW6Lc+8Ab9iwwfU8ApsGTdu0aWNuodQrdDfeeKPVTUIO0YtcemuUDvqnU3rlypUzGUEaSEdgqlWrlsnOcA7m6eS8MEK5ncCmAysXLFgww3LnYDbpb2cGgH+iZZuykuHp9Oeff5pHvaMlPf3bo32JKVOmmDrkmdm9e7d55G+S/Y4J57nipk2b0gTFtZ+yf/9+c9cUAvt4uBwNhjocDjPw6+UC5XxH2PeY0Kzi8PBw8x2hZTictLSHDmTvvgyBfTwcP37cBMn17oEVK1Zc9qKKv39HhDj0KIZtaUBcawBNmDBBBg8ebJbpga1faFordf369VY3EVchJSXFdHL1at7ChQulZcuWVjcJOUhHGP/uu+88lmPRzonWltTBMnSgDAQmzSiuWbOmKbWiA/E66c8ff/yxGcSVTIzApRcxly5dKlu3bpWKFSu6luvtiloHWLMy2L8AvEmDoj/99FOG5RrgLFOmjBlcWPsR2p/QTC/NEnMv36cX9nRQrh9++MH8TdITbNjnmFCVK1c2dWp//PFH17GhY+eMHTvW3BWnzyOwHTlyxHU3o5PeqayD+7pfXNHkOz0W3OtRa7hJSwjqIH16jGi/FvY5JpTe2f7zzz+bMh3ODGMtNdirVy9ZsmSJGdwege38+fOmFvn27dtNIq4me3kSKN8RZJTbXJ06daRjx44ydOhQ82VXoUIFMwiD3lKXvsg+Ao/WetJgiwZj9ORm7ty5aZ7v0qWLZW3D1YuNjZV27dplWO7MIPf0HAKLluXQmn/vv/++yS5u1KiRqQGrQXL93iaIGtieeeYZc4LQoEEDM3CnXqD+8ssvzTI9eWD/AvC2a6+91kzpabawlv1y70ton/Kll16SDh06mKxi7VvOmzdPfvnlF9cgxLDXMaE04UrLLWgm4QMPPGCOh2nTppm/YwTJg4MGOrVMnMYONDiqQVAtzaB3Dmhwy0kvsGjASyeNK2h28WeffSZr1641F1r8IQAG3x4TSi+a6ZgHeh6jx4HebTJp0iTznUGQPDg89NBDpj69nrdqsFwnpzx58rj+bgTMd4RmlMPeLl686Bg8eLCjWLFijqioKMctt9zi+Prrr61uFnJAo0aN9I6RTCcE736vUqWK1c1ADklMTHS88MILjjJlyjgiIiIcFSpUcEyZMsXqZiGHbNiwwXH33Xebv8G6fytWrOgYO3asIykpyeqmAbAx/ZvTqlWrNMs2bdrkaNOmjaNkyZKOyMhIR548eRz169d3zJ8/37J2wtpjwumzzz5z1KhRw5xLlipVyjF8+HDTf0FwmDZtmvm/Hhsb6wgPD3cUKVLEfBesXr06zXq7d+92dOzY0VG2bFlHdHS0I1euXI5atWo53nrrLUdqaqpl7Yd1x4TTmjVrHPXq1TPHha7bt29fx5kzZ3zebnjv74NkEnPS5wLtO4LSKwAAAAAAAAAAWwu1ugEAAAAAAAAAAFiJQDkAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAABsjUA5AAAAAAAAAMDWCJQDAAAAAAAAAGyNQDkAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQDAoxdeeEFCQkJ8+p579uwx7zlz5kyfvi8AAACQGfrFgaN79+5StmxZq5sBIEARKAeAIKGdaO1MZzatX7/e6iYCAAAAXkWfOHPpP4t8+fJJo0aN5KuvvrK6aQDgF8KtbgAAIGeNGTNGypUrl2F5hQoVsvU6w4cPl+eeey4HWwYAAAAEVp842PrFzZo1k65du4rD4ZC9e/fKm2++KW3atJElS5bIXXfdZXXzAMBSBMoBIMjcfffdUrt27at+nfDwcDMBAAAAdu0TB1u/uGLFitKlSxfXz+3bt5cbb7xRXnnllYAIlMfHx0tkZKSEhlIgAUDO45sFAGzEWetw4sSJMmXKFClTpozExMSYWy5/+eWXf6zFuGzZMqlfv74UKFBA8uTJIzfccIMMGzYszTpHjhyRnj17yjXXXCPR0dFy0003yaxZszK05dSpU6aGYP78+c3rdevWzSzz5LfffpMOHTpIoUKFzGvqSc+iRYty5DMBAACA/dAvvqRy5coSGxsru3btSrM8ISFBRo0aZTLwo6KipHTp0vLss8+a5U733Xef1KxZM83vaXa6flbubdqwYYNZplnr6sSJEzJ48GCpVq2a+ey0BIxe2Pj555/TvNaqVavM73344Ycmq79kyZKSK1cuOXPmjHn+888/l6pVq5rPQR8/++yzK/4cAEAFxyVRAIDL6dOn5dixY2mWaQezcOHCrp9nz54tZ8+elb59+5qsDM0gadq0qWzdutV05D359ddfpXXr1lK9enVzK6t2mP/44w9Zu3ata52LFy9K48aNzfInn3zS3O768ccfm46/dvafeuops57e6nnPPffId999J48//rjpoGvHVk8KPL3v7bffbjrGestr7ty5Zf78+dKuXTv55JNP5N57783BTw8AAAB26RMru/eL9XM6efKklC9f3rUsNTVV2rZta9rUu3dv0yb9PPSCwo4dO0yAWjVo0EAWLlxoAtca7NZt0c9As73XrFljXkPpvC7Ttqvdu3eb1+jYsaP5XP766y95++23zUWKbdu2SYkSJdK08cUXXzRZ5Bpc10C9zi9dutSVDT9u3Dg5fvy49OjRQ0qVKpXtzwAAXBwAgKAwY8YMh36te5qioqLMOnFxcebnmJgYx/79+12/u2HDBrN8wIABrmWjRo0yy5ymTJlifj569GimbZg6dapZZ+7cua5liYmJjrp16zry5MnjOHPmjFn2+eefm/X+7//+z7VecnKyo0GDBma5bovTHXfc4ahWrZojPj7etSw1NdVRr149x/XXX3+VnxoAAADs1ie2a79YX69nz56m3UeOHHFs2rTJ0aJFC7N8woQJrvXmzJnjCA0NdaxZsybN77/11ltm3bVr15qff/jhB/Pz4sWLzc///e9/zc8dO3Z01KlTx/V7bdu2ddx8882un7X9KSkpaV5b94funzFjxriWrVy50rzedddd57hw4UKa9WvUqOEoXry449SpU65lS5cuNeuXKVPmHz8LAPCE0isAEGRef/11cyuo++S8zdFJs040E8Xp1ltvlTp16sjixYszfV29DVRp1ohmmXiiv1+sWDF58MEHXcsiIiKkf//+cu7cOfnPf/7jWk/rPD7xxBOu9cLCwqRfv35pXk9vy/z222/l/vvvN5k+mhWkk2aMaA3FnTt3yoEDB7L9GQEAACC4ZaVPbMd+8XvvvSdFihSRokWLmrItK1asMCVVBg4c6FpHM981i7xSpUqu99FJM+3VypUrzePNN99sSqesXr3alTmuGd06WOhPP/0kFy5cMFnmmpmu2edOmoHvrDGekpJitsFZvkZ/Lz3NrteyOE6HDh2SLVu2mOVarsZ9oFLNMAeAK0XpFQAIMtq5/6eBi66//nqPA/vorZuZ6dSpk7z77rvSq1cvc6vnHXfcYeoSao1EZ0d379695rXTD66jHW3n887H4sWLmw6xO+0cu9NbVbVzPWLECDN5orUf3U9uAAAAgKz0ie3YL9YyL1oKJjExUX744Qd5+eWXTUDbvZ0adN++fbsJqGf2Ps6Aft26dU2AXOmjBsS1drsGwNevX2/K12iQ3z1QrhcXtMTNG2+8IXFxcWZdp/SlcZSWZ3Hn/Ow87bvMgu0AkBUEygEAWaJZHJotohkkX331lXz99dfy0UcfmcwSrRGoHeWc5szQ0XqEminjiQ4wBAAAAPhKIPeLNeP7zjvvNPMtW7Y0A3lq4LxJkyYm2O98Lx1oc/LkyR5fQwf2dNKg+NixY019dw2UP//88ybjXgfX1J+ddd7dA+UanNdg/yOPPGLqj+vApBqof/rppz1m6LtnkwOANxEoBwAb0iyR9HRgnrJly17297QDqxkzOmnHWTu52hnWkwTtcJcpU0b++9//mg6ue1bKb7/9Zh71eeej3uapt526Z8/8/vvvad7vuuuuc92m6uzQAwAAADnF7v3ixx57zAzSOXz4cDMYqA54qgN7/vzzz2bb9OfL0QC4Zqf/+9//NqVfnAHxhg0bugLlmqHvPjDqggULTGBey8C400FONXD/T5yfnad9l/5zA4DsoEY5ANiQjjLvXsNw48aNsmHDBrn77rsz/R29ZTK9GjVqmEcdfd6ZlXL48GGTUeOUnJwsr732mun460j2zvV0+ZtvvulaT2+51PXcae3Exo0by9tvv21qEaZ39OjRbG45AAAA8De794u1PvqgQYNMqRWtua60Drp+Ju+8806G9S9evCjnz593/az13DV4P378eJMZXqVKFbNcA+ZaekVrsbtnkyvNuL80tqikqYue1bGHtFSNft6zZs2S06dPu5ZrHfpt27Zl8xMAgL+RUQ4AQUYHKXJmqrirV6+eK5tFb8vU2yR10CDtzE+dOtXUA9SBfDIzZswYc4tpq1atTBaH1ibUuoJ6+6a+lurdu7fpvHfv3l1+/PFHk4mjGSNr164175E3b16zXps2beT22283NR337NljBt359NNP03R03Qdi0tfX2z8fffRRk03z119/ybp162T//v0m2wUAAADIap/YmZ2t6BeLaePIkSNNsFsHN3344YdNjfbHH3/cZMhr+zR4r5+nLv/mm29c9d9z5coltWrVMkFx3RZnBrpmlGtAXaf0gfLWrVubz7BHjx5mf2zdulU++OCDNPvln4wbN858/vp5aAkXvXihFxc0UK/Z+QBwRRwAgKAwY8YMTcvIdNLn4+LizPyECRMckyZNcpQuXdoRFRXlaNCggePnn39O83qjRo0y6zqtWLHCcc899zhKlCjhiIyMNI8PPvigY8eOHWl+76+//nL06NHDERsba9arVq2aee/0jh8/7nj44Ycd+fLlc+TPn9/Mb9682dVWd7t27XJ07drVUaxYMUdERISjZMmSjtatWzsWLFiQ458jAAAAgrtPrOzYL9bX69u3r8fnXnjhBfP8ypUrzc+JiYmO8ePHO6pUqWI+l4IFCzpq1arlGD16tOP06dNpfveZZ54xv6vru6tQoYJZrm12Fx8f7xg0aJCjePHijpiYGMftt9/uWLdunaNRo0ZmctK26O9//PHHHtv8ySefOCpXrmzad+ONNzo+/fRTR7du3RxlypT5x88CADwJ0X+uLMQOAAg0mqWio8ZPmDDBDAQEAAAA2BH9YgBAetQoBwAAAAAAAADYGoFyAAAAAAAAAICtESgHAAAAAAAAANgaNcoBAAAAAAAAALZGRjkAAAAAAAAAwNYIlAMAAAAAAAAAbI1AOQAAAAAAAADA1giUAwAAAAAAAABsjUA5AAAAAAAAAMDWCJQDAAAAAAAAAGyNQDkAAAAAAAAAwNYIlAMAAAAAAAAAxM7+HwTTMD+dvtIWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Exercise 1 Complete!\n",
      "Key learnings:\n",
      "- World models can learn environment dynamics from observation sequences\n",
      "- MPC planning uses learned models for lookahead decision making\n",
      "- RSSM balances deterministic and stochastic state evolution\n",
      "- Imagination enables sample-efficient learning through internal simulation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_world_model_environment():\n",
    "    \"\"\"Create a simple continuous control environment for world model training\"\"\"\n",
    "    \n",
    "    class ContinuousControlEnv:\n",
    "        def __init__(self, state_dim=4, action_dim=2):\n",
    "            self.state_dim = state_dim\n",
    "            self.action_dim = action_dim\n",
    "            self.max_steps = 200\n",
    "            self.reset()\n",
    "        \n",
    "        def reset(self):\n",
    "            self.state = np.random.uniform(-1, 1, self.state_dim)\n",
    "            self.steps = 0\n",
    "            return self.state.copy()\n",
    "        \n",
    "        def step(self, action):\n",
    "            action = np.clip(action, -1, 1)\n",
    "            \n",
    "            next_state = np.zeros_like(self.state)\n",
    "            next_state[0] = self.state[0] + 0.1 * action[0] + 0.05 * np.sin(self.state[1])\n",
    "            next_state[1] = self.state[1] + 0.1 * action[1] + 0.02 * self.state[0] * self.state[2]\n",
    "            next_state[2] = 0.9 * self.state[2] + 0.1 * np.tanh(action[0] + action[1])\n",
    "            next_state[3] = 0.95 * self.state[3] + 0.1 * np.random.normal(0, 0.1)\n",
    "            \n",
    "            next_state += np.random.normal(0, 0.02, self.state_dim)\n",
    "            \n",
    "            reward = -np.sum(next_state**2) - 0.01 * np.sum(action**2)\n",
    "            \n",
    "            self.steps += 1\n",
    "            done = self.steps >= self.max_steps or np.linalg.norm(next_state) > 3\n",
    "            \n",
    "            self.state = next_state\n",
    "            return next_state.copy(), reward, done, {}\n",
    "    \n",
    "    return ContinuousControlEnv()\n",
    "\n",
    "def collect_random_data(env, n_episodes=100):\n",
    "    \"\"\"Collect random interaction data for world model training\"\"\"\n",
    "    \n",
    "    data = {\n",
    "        'observations': [],\n",
    "        'actions': [],\n",
    "        'rewards': [],\n",
    "        'dones': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Collecting {n_episodes} episodes of random data...\")\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_obs = [obs]\n",
    "        episode_actions = []\n",
    "        episode_rewards = []\n",
    "        episode_dones = []\n",
    "        \n",
    "        while True:\n",
    "            action = np.random.uniform(-1, 1, env.action_dim)\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_obs.append(next_obs)\n",
    "            episode_actions.append(action)\n",
    "            episode_rewards.append(reward)\n",
    "            episode_dones.append(done)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        data['observations'].append(np.array(episode_obs))\n",
    "        data['actions'].append(np.array(episode_actions))\n",
    "        data['rewards'].append(np.array(episode_rewards))\n",
    "        data['dones'].append(np.array(episode_dones))\n",
    "        \n",
    "        if episode % 20 == 0:\n",
    "            print(f\"Episode {episode}/{n_episodes}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_training_batches(data, batch_size=32, seq_length=20):\n",
    "    \"\"\"Create training batches from collected data\"\"\"\n",
    "    \n",
    "    batches = []\n",
    "    \n",
    "    for episode_obs, episode_actions, episode_rewards in zip(\n",
    "        data['observations'], data['actions'], data['rewards']\n",
    "    ):\n",
    "        episode_length = len(episode_actions)\n",
    "        \n",
    "        for start_idx in range(0, episode_length - seq_length + 1, seq_length // 2):\n",
    "            end_idx = start_idx + seq_length\n",
    "            \n",
    "            batch_obs = episode_obs[start_idx:end_idx+1]  # +1 for next obs\n",
    "            batch_actions = episode_actions[start_idx:end_idx]\n",
    "            batch_rewards = episode_rewards[start_idx:end_idx]\n",
    "            \n",
    "            batches.append({\n",
    "                'observations': torch.FloatTensor(batch_obs).to(device),\n",
    "                'actions': torch.FloatTensor(batch_actions).to(device),\n",
    "                'rewards': torch.FloatTensor(batch_rewards).unsqueeze(-1).to(device)\n",
    "            })\n",
    "    \n",
    "    grouped_batches = []\n",
    "    for i in range(0, len(batches), batch_size):\n",
    "        batch_group = batches[i:i+batch_size]\n",
    "        if len(batch_group) == batch_size:\n",
    "            \n",
    "            obs_batch = torch.stack([b['observations'] for b in batch_group])\n",
    "            action_batch = torch.stack([b['actions'] for b in batch_group])\n",
    "            reward_batch = torch.stack([b['rewards'] for b in batch_group])\n",
    "            \n",
    "            grouped_batches.append({\n",
    "                'observations': obs_batch,\n",
    "                'actions': action_batch,\n",
    "                'rewards': reward_batch\n",
    "            })\n",
    "    \n",
    "    return grouped_batches\n",
    "\n",
    "def train_world_model(world_model, batches, n_epochs=50, lr=1e-3):\n",
    "    \"\"\"Train the world model on collected data\"\"\"\n",
    "    \n",
    "    optimizer = torch.optim.Adam(world_model.parameters(), lr=lr)\n",
    "    \n",
    "    losses = {'total': [], 'reconstruction': [], 'kl': [], 'reward': []}\n",
    "    \n",
    "    print(f\"Training world model for {n_epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = {'total': 0, 'reconstruction': 0, 'kl': 0, 'reward': 0}\n",
    "        \n",
    "        for batch_idx, batch in enumerate(batches):\n",
    "            obs_seq = batch['observations']  # [batch, seq_len+1, obs_dim]\n",
    "            action_seq = batch['actions']    # [batch, seq_len, action_dim]\n",
    "            reward_seq = batch['rewards']    # [batch, seq_len, 1]\n",
    "            \n",
    "            output = world_model.observe_sequence(obs_seq[:, :-1], action_seq)\n",
    "            \n",
    "            recon_loss = F.mse_loss(\n",
    "                output['reconstructions'], \n",
    "                obs_seq[:, 1:]  # Target is next observations\n",
    "            )\n",
    "            \n",
    "            kl_loss = output['kl_losses'].mean() if output['kl_losses'] is not None else 0\n",
    "            \n",
    "            reward_loss = F.mse_loss(output['rewards'], reward_seq)\n",
    "            \n",
    "            total_loss = recon_loss + 0.1 * kl_loss + reward_loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(world_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses['total'] += total_loss.item()\n",
    "            epoch_losses['reconstruction'] += recon_loss.item()\n",
    "            epoch_losses['kl'] += kl_loss.item() if isinstance(kl_loss, torch.Tensor) else kl_loss\n",
    "            epoch_losses['reward'] += reward_loss.item()\n",
    "        \n",
    "        for key in epoch_losses:\n",
    "            epoch_losses[key] /= len(batches)\n",
    "            losses[key].append(epoch_losses[key])\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Total={epoch_losses['total']:.4f}, \"\n",
    "                  f\"Recon={epoch_losses['reconstruction']:.4f}, \"\n",
    "                  f\"KL={epoch_losses['kl']:.4f}, \"\n",
    "                  f\"Reward={epoch_losses['reward']:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def evaluate_world_model_planning(env, world_model, planner, n_episodes=10):\n",
    "    \"\"\"Evaluate world model with MPC planning\"\"\"\n",
    "    \n",
    "    print(f\"Evaluating MPC planning for {n_episodes} episodes...\")\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_length = 0\n",
    "        \n",
    "        state = world_model.rssm.initial_state(1)\n",
    "        \n",
    "        while True:\n",
    "            obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "            embed = world_model.encode(obs_tensor)\n",
    "            \n",
    "            dummy_action = torch.zeros(1, env.action_dim).to(device)\n",
    "            state = world_model.rssm.observe(embed, dummy_action, state)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action_tensor = planner.plan(state)\n",
    "                action = action_tensor.cpu().numpy()[0]\n",
    "            \n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            episode_length += 1\n",
    "            obs = next_obs\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(episode_length)\n",
    "        \n",
    "        if episode % 5 == 0:\n",
    "            print(f\"Episode {episode}: Reward={episode_reward:.2f}, Length={episode_length}\")\n",
    "    \n",
    "    print(f\"Average reward: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}\")\n",
    "    print(f\"Average length: {np.mean(episode_lengths):.1f} Â± {np.std(episode_lengths):.1f}\")\n",
    "    \n",
    "    return episode_rewards\n",
    "\n",
    "print(\"ðŸš€ Starting Exercise 1: World Models Training and Evaluation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = create_world_model_environment()\n",
    "print(f\"Environment: {env.state_dim}D state, {env.action_dim}D action\")\n",
    "\n",
    "random_data = collect_random_data(env, n_episodes=50)\n",
    "print(f\"Collected {len(random_data['observations'])} episodes\")\n",
    "\n",
    "training_batches = create_training_batches(random_data, batch_size=16, seq_length=15)\n",
    "print(f\"Created {len(training_batches)} training batches\")\n",
    "\n",
    "world_model = WorldModel(\n",
    "    obs_dim=env.state_dim,\n",
    "    action_dim=env.action_dim,\n",
    "    state_dim=20,\n",
    "    hidden_dim=100,\n",
    "    embed_dim=256\n",
    ").to(device)\n",
    "\n",
    "print(f\"World model parameters: {sum(p.numel() for p in world_model.parameters()):,}\")\n",
    "\n",
    "training_losses = train_world_model(world_model, training_batches, n_epochs=30)\n",
    "\n",
    "planner = MPCPlanner(\n",
    "    world_model=world_model,\n",
    "    action_dim=env.action_dim,\n",
    "    horizon=8,\n",
    "    n_candidates=500,\n",
    "    n_iterations=5,\n",
    "    n_elite=50\n",
    ")\n",
    "\n",
    "planning_rewards = evaluate_world_model_planning(env, world_model, planner, n_episodes=10)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "ax1.plot(training_losses['total'], label='Total Loss')\n",
    "ax1.plot(training_losses['reconstruction'], label='Reconstruction')\n",
    "ax1.plot(training_losses['reward'], label='Reward Prediction')\n",
    "ax1.set_title('World Model Training Losses')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(training_losses['kl'])\n",
    "ax2.set_title('KL Divergence Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('KL Loss')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.bar(range(len(planning_rewards)), planning_rewards, alpha=0.7)\n",
    "ax3.set_title('MPC Planning Episode Rewards')\n",
    "ax3.set_xlabel('Episode')\n",
    "ax3.set_ylabel('Total Reward')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax4.hist(planning_rewards, bins=5, alpha=0.7, edgecolor='black')\n",
    "ax4.axvline(np.mean(planning_rewards), color='red', linestyle='--', \n",
    "           label=f'Mean: {np.mean(planning_rewards):.2f}')\n",
    "ax4.set_title('Reward Distribution')\n",
    "ax4.set_xlabel('Episode Reward')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Exercise 1 Complete!\")\n",
    "print(\"Key learnings:\")\n",
    "print(\"- World models can learn environment dynamics from observation sequences\")\n",
    "print(\"- MPC planning uses learned models for lookahead decision making\")\n",
    "print(\"- RSSM balances deterministic and stochastic state evolution\")\n",
    "print(\"- Imagination enables sample-efficient learning through internal simulation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f2979",
   "metadata": {},
   "source": [
    "# Part II: Multi-Agent Deep Reinforcement Learning\n",
    "\n",
    "## ðŸ‘¥ Theoretical Foundation\n",
    "\n",
    "### Introduction to Multi-Agent RL\n",
    "\n",
    "**Multi-Agent Reinforcement Learning (MARL)** extends single-agent RL to environments with multiple learning agents. This creates fundamentally new challenges due to **non-stationarity** - each agent's environment changes as other agents learn and adapt their policies.\n",
    "\n",
    "### Core Challenges in MARL\n",
    "\n",
    "#### 1. Non-Stationarity Problem\n",
    "- **Single-Agent RL**: Environment is stationary (fixed transition dynamics)\n",
    "- **Multi-Agent RL**: Environment is non-stationary (other agents change their behavior)\n",
    "- **Consequence**: Standard RL convergence guarantees no longer hold\n",
    "\n",
    "#### 2. Credit Assignment Problem\n",
    "- **Challenge**: Which agent is responsible for team success/failure?\n",
    "- **Example**: In cooperative tasks, global reward must be decomposed\n",
    "- **Solutions**: Difference rewards, counterfactual reasoning, attention mechanisms\n",
    "\n",
    "#### 3. Scalability Issues\n",
    "- **Joint Action Space**: Grows exponentially with number of agents\n",
    "- **Joint Observation Space**: Exponential growth in state complexity\n",
    "- **Communication**: Bandwidth limitations, partial observability\n",
    "\n",
    "#### 4. Coordination vs Competition\n",
    "- **Cooperative**: Agents share common objectives (team sports, rescue operations)\n",
    "- **Competitive**: Agents have opposing objectives (adversarial games, auctions)\n",
    "- **Mixed-Motive**: Combination of cooperation and competition (negotiation, markets)\n",
    "\n",
    "### Game Theoretic Foundations\n",
    "\n",
    "#### Nash Equilibrium\n",
    "A strategy profile where no agent can unilaterally improve by changing strategy:\n",
    "\n",
    "$$\\pi^*_i \\in \\arg\\max_{\\pi_i} J_i(\\pi_i, \\pi^*_{-i})$$\n",
    "\n",
    "where $\\pi^*_{-i}$ represents the strategies of all agents except $i$.\n",
    "\n",
    "#### Solution Concepts\n",
    "1. **Nash Equilibrium**: Stable but not necessarily optimal\n",
    "2. **Pareto Optimal**: Efficient outcomes that cannot be improved for all agents\n",
    "3. **Correlated Equilibrium**: Allows for coordination through external signals\n",
    "4. **Stackelberg Equilibrium**: Leader-follower dynamics\n",
    "\n",
    "### MARL Algorithm Categories\n",
    "\n",
    "#### 1. Independent Learning (IL)\n",
    "Each agent treats others as part of the environment:\n",
    "- **Pros**: Simple, scalable, no communication needed\n",
    "- **Cons**: No convergence guarantees, ignores other agents' adaptation\n",
    "- **Examples**: Independent Q-learning, Independent Actor-Critic\n",
    "\n",
    "#### 2. Joint Action Learning (JAL)  \n",
    "Agents learn joint action-value functions:\n",
    "- **Pros**: Can achieve coordination, theoretically sound\n",
    "- **Cons**: Exponential complexity in number of agents\n",
    "- **Examples**: Multi-Agent Q-learning, Nash-Q learning\n",
    "\n",
    "#### 3. Agent Modeling (AM)\n",
    "Agents maintain models of other agents:\n",
    "- **Pros**: Handles non-stationarity explicitly\n",
    "- **Cons**: Computational overhead, modeling errors\n",
    "- **Examples**: MAAC, MADDPG with opponent modeling\n",
    "\n",
    "#### 4. Communication-Based\n",
    "Agents can exchange information:\n",
    "- **Pros**: Direct coordination, shared knowledge\n",
    "- **Cons**: Communication overhead, protocol design\n",
    "- **Examples**: CommNet, I2C, TarMAC\n",
    "\n",
    "### Deep MARL Algorithms\n",
    "\n",
    "#### 1. Multi-Agent Deep Deterministic Policy Gradient (MADDPG)\n",
    "\n",
    "**Key Idea**: Centralized training, decentralized execution\n",
    "- **Training**: Critics have access to all agents' observations and actions\n",
    "- **Execution**: Actors only use local observations\n",
    "\n",
    "**Actor Update**: \n",
    "$$\\nabla_{\\theta_i} J_i = \\mathbb{E}[\\nabla_{\\theta_i} \\mu_i(o_i) \\nabla_{a_i} Q_i^{\\mu}(x, a_1, ..., a_N)|_{a_i=\\mu_i(o_i)}]$$\n",
    "\n",
    "**Critic Update**:\n",
    "$$Q_i^{\\mu}(x, a_1, ..., a_N) = \\mathbb{E}[r_i + \\gamma Q_i^{\\mu'}(x', a'_1, ..., a'_N)]$$\n",
    "\n",
    "where $x$ is the global state and $a_i$ are individual actions.\n",
    "\n",
    "#### 2. Multi-Agent Actor-Critic (MAAC)\n",
    "\n",
    "Extends single-agent AC to multi-agent setting:\n",
    "- **Centralized Critic**: Uses global information during training\n",
    "- **Decentralized Actors**: Use only local observations\n",
    "- **Attention Mechanism**: Selectively focus on relevant agents\n",
    "\n",
    "#### 3. Counterfactual Multi-Agent Policy Gradient (COMA)\n",
    "\n",
    "Addresses credit assignment through counterfactual reasoning:\n",
    "\n",
    "**Counterfactual Advantage**:\n",
    "$$A_i(s, a) = Q(s, a) - \\sum_{a'_i} \\pi_i(a'_i|o_i) Q(s, (a_{-i}, a'_i))$$\n",
    "\n",
    "This measures how much better the taken action is compared to marginalizing over all possible actions.\n",
    "\n",
    "### Communication in MARL\n",
    "\n",
    "#### 1. Communication Protocols\n",
    "- **Broadcast**: All-to-all communication\n",
    "- **Targeted**: Agent-specific messages\n",
    "- **Hierarchical**: Tree-structured communication\n",
    "\n",
    "#### 2. Communication Learning\n",
    "- **What to Communicate**: Message content learning\n",
    "- **When to Communicate**: Communication scheduling\n",
    "- **Who to Communicate With**: Network topology learning\n",
    "\n",
    "#### 3. Differentiable Communication\n",
    "\n",
    "**Gumbel-Softmax Trick** for discrete communication:\n",
    "$$\\text{softmax}\\left(\\frac{\\log(\\pi_i) + G_i}{\\tau}\\right)$$\n",
    "\n",
    "where $G_i$ are Gumbel random variables and $\\tau$ is temperature.\n",
    "\n",
    "### Cooperative Multi-Agent RL\n",
    "\n",
    "#### 1. Team Reward Structure\n",
    "- **Global Reward**: Same reward for all agents\n",
    "- **Local Rewards**: Individual agent rewards\n",
    "- **Shaped Rewards**: Carefully designed to promote cooperation\n",
    "\n",
    "#### 2. Value Decomposition Methods\n",
    "\n",
    "**VDN (Value Decomposition Networks)**:\n",
    "$$Q_{tot}(s, a) = \\sum_{i=1}^n Q_i(s_i, a_i)$$\n",
    "\n",
    "**QMIX**: Monotonic value decomposition\n",
    "$$\\frac{\\partial Q_{tot}}{\\partial Q_i} \\geq 0$$\n",
    "\n",
    "#### 3. Policy Gradient Methods\n",
    "- **Multi-Agent Policy Gradient (MAPG)**\n",
    "- **Trust Region Methods**: MADDPG-TR\n",
    "- **Proximal Policy Optimization**: MAPPO\n",
    "\n",
    "### Competitive Multi-Agent RL\n",
    "\n",
    "#### 1. Self-Play Training\n",
    "Agents learn by playing against copies of themselves:\n",
    "- **Advantages**: Always improving opponents, no human data needed\n",
    "- **Challenges**: Exploitability, strategy diversity\n",
    "\n",
    "#### 2. Population-Based Training\n",
    "Maintain population of diverse strategies:\n",
    "- **League Play**: Different skill levels and strategies\n",
    "- **Diversity Metrics**: Behavioral diversity, policy diversity\n",
    "- **Meta-Game Analysis**: Strategy effectiveness matrix\n",
    "\n",
    "#### 3. Adversarial Training\n",
    "- **Minimax Objective**: $\\min_{\\pi_1} \\max_{\\pi_2} J(\\pi_1, \\pi_2)$\n",
    "- **Nash-AC**: Nash equilibrium seeking\n",
    "- **PSRO**: Policy Space Response Oracles\n",
    "\n",
    "### Theoretical Guarantees\n",
    "\n",
    "#### 1. Convergence Results\n",
    "- **Independent Learning**: Generally no convergence guarantees\n",
    "- **Joint Action Learning**: Convergence to Nash under restrictive assumptions\n",
    "- **Two-Timescale Algorithms**: Convergence through different learning rates\n",
    "\n",
    "#### 2. Sample Complexity\n",
    "Multi-agent sample complexity often exponentially worse than single-agent due to:\n",
    "- Larger state-action spaces\n",
    "- Non-stationarity\n",
    "- Coordination requirements\n",
    "\n",
    "#### 3. Regret Bounds\n",
    "**Multi-Agent Regret**: \n",
    "$$R_i(T) = \\max_{\\pi_i} \\sum_{t=1}^T J_i(\\pi_i, \\pi_{-i}^t) - \\sum_{t=1}^T J_i(\\pi_i^t, \\pi_{-i}^t)$$\n",
    "\n",
    "### Applications\n",
    "\n",
    "#### 1. Robotics\n",
    "- **Multi-Robot Systems**: Coordination and task allocation\n",
    "- **Swarm Robotics**: Large-scale coordination\n",
    "- **Human-Robot Interaction**: Mixed human-AI teams\n",
    "\n",
    "#### 2. Autonomous Vehicles\n",
    "- **Traffic Management**: Intersection control, highway merging\n",
    "- **Platooning**: Vehicle following and coordination\n",
    "- **Mixed Autonomy**: Human and autonomous vehicles\n",
    "\n",
    "#### 3. Game Playing\n",
    "- **Real-Time Strategy Games**: StarCraft, Dota\n",
    "- **Board Games**: Multi-player poker, diplomacy\n",
    "- **Sports Simulation**: Team coordination\n",
    "\n",
    "#### 4. Economics and Finance\n",
    "- **Algorithmic Trading**: Multi-agent market making\n",
    "- **Auction Design**: Bidding strategies\n",
    "- **Resource Allocation**: Cloud computing, network resources\n",
    "\n",
    "### Key Research Papers\n",
    "\n",
    "1. **MADDPG** (Lowe et al., 2017)\n",
    "2. **COMA** (Foerster et al., 2018)\n",
    "3. **QMIX** (Rashid et al., 2018)\n",
    "4. **CommNet** (Sukhbaatar et al., 2016)\n",
    "5. **OpenAI Five** (OpenAI, 2019)\n",
    "6. **AlphaStar** (Vinyals et al., 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014f01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-Agent RL Implementation Complete!\n",
      "Components implemented:\n",
      "- MultiAgentReplayBuffer: Experience storage for multi-agent systems\n",
      "- Actor/Critic: Individual agent networks with centralized training\n",
      "- AttentionCritic: Attention mechanism for selective agent focus\n",
      "- CommunicationNetwork: Neural communication between agents\n",
      "- MADDPGAgent: Complete MADDPG implementation with extensions\n",
      "- MultiAgentEnvironment: Configurable multi-agent test environment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MultiAgentReplayBuffer:\n",
    "    \"\"\"Replay buffer for multi-agent experiences\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity: int, n_agents: int, obs_dim: int, action_dim: int):\n",
    "        self.capacity = capacity\n",
    "        self.n_agents = n_agents\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.observations = np.zeros((capacity, n_agents, obs_dim))\n",
    "        self.actions = np.zeros((capacity, n_agents, action_dim))\n",
    "        self.rewards = np.zeros((capacity, n_agents, 1))\n",
    "        self.next_observations = np.zeros((capacity, n_agents, obs_dim))\n",
    "        self.dones = np.zeros((capacity, n_agents, 1))\n",
    "        \n",
    "        self.ptr = 0\n",
    "        self.size = 0\n",
    "    \n",
    "    def add(self, obs: np.ndarray, actions: np.ndarray, rewards: np.ndarray,\n",
    "            next_obs: np.ndarray, dones: np.ndarray):\n",
    "        \"\"\"Add experience to buffer\"\"\"\n",
    "        \n",
    "        self.observations[self.ptr] = obs\n",
    "        self.actions[self.ptr] = actions\n",
    "        self.rewards[self.ptr] = rewards.reshape(self.n_agents, 1)\n",
    "        self.next_observations[self.ptr] = next_obs\n",
    "        self.dones[self.ptr] = dones.reshape(self.n_agents, 1)\n",
    "        \n",
    "        self.ptr = (self.ptr + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "    \n",
    "    def sample(self, batch_size: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Sample batch of experiences\"\"\"\n",
    "        \n",
    "        indices = np.random.choice(self.size, batch_size, replace=False)\n",
    "        \n",
    "        return {\n",
    "            'observations': torch.FloatTensor(self.observations[indices]).to(device),\n",
    "            'actions': torch.FloatTensor(self.actions[indices]).to(device),\n",
    "            'rewards': torch.FloatTensor(self.rewards[indices]).to(device),\n",
    "            'next_observations': torch.FloatTensor(self.next_observations[indices]).to(device),\n",
    "            'dones': torch.FloatTensor(self.dones[indices]).to(device)\n",
    "        }\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Individual agent actor network\"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, action_dim: int, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(obs)\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Centralized critic for MADDPG\"\"\"\n",
    "    \n",
    "    def __init__(self, total_obs_dim: int, total_action_dim: int, \n",
    "                 hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(total_obs_dim + total_action_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs: torch.Tensor, actions: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.cat([obs, actions], dim=-1)\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class AttentionCritic(nn.Module):\n",
    "    \"\"\"Critic with attention mechanism for multi-agent focus\"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, action_dim: int, n_agents: int,\n",
    "                 hidden_dim: int = 256, attention_dim: int = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.attention_dim = attention_dim\n",
    "        \n",
    "        self.query_net = nn.Linear(obs_dim + action_dim, attention_dim)\n",
    "        self.key_net = nn.Linear(obs_dim + action_dim, attention_dim)\n",
    "        self.value_net = nn.Linear(obs_dim + action_dim, attention_dim)\n",
    "        \n",
    "        self.critic_net = nn.Sequential(\n",
    "            nn.Linear(attention_dim + obs_dim + action_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, observations: torch.Tensor, actions: torch.Tensor,\n",
    "                agent_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        observations: [batch, n_agents, obs_dim]\n",
    "        actions: [batch, n_agents, action_dim]\n",
    "        \"\"\"\n",
    "        batch_size = observations.shape[0]\n",
    "        \n",
    "        obs_act = torch.cat([observations, actions], dim=-1)  # [batch, n_agents, obs_dim + action_dim]\n",
    "        \n",
    "        own_obs_act = obs_act[:, agent_idx]  # [batch, obs_dim + action_dim]\n",
    "        \n",
    "        queries = self.query_net(own_obs_act).unsqueeze(1)  # [batch, 1, attention_dim]\n",
    "        keys = self.key_net(obs_act)  # [batch, n_agents, attention_dim]\n",
    "        values = self.value_net(obs_act)  # [batch, n_agents, attention_dim]\n",
    "        \n",
    "        attention_scores = torch.bmm(queries, keys.transpose(1, 2))  # [batch, 1, n_agents]\n",
    "        attention_weights = F.softmax(attention_scores / np.sqrt(self.attention_dim), dim=-1)\n",
    "        \n",
    "        attended_values = torch.bmm(attention_weights, values).squeeze(1)  # [batch, attention_dim]\n",
    "        \n",
    "        critic_input = torch.cat([attended_values, own_obs_act], dim=-1)\n",
    "        \n",
    "        return self.critic_net(critic_input)\n",
    "\n",
    "\n",
    "class CommunicationNetwork(nn.Module):\n",
    "    \"\"\"Neural network for agent communication\"\"\"\n",
    "    \n",
    "    def __init__(self, obs_dim: int, message_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.message_dim = message_dim\n",
    "        \n",
    "        self.message_encoder = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, message_dim)\n",
    "        )\n",
    "        \n",
    "        self.message_processor = nn.Sequential(\n",
    "            nn.Linear(obs_dim + message_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, obs_dim)\n",
    "        )\n",
    "    \n",
    "    def generate_message(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Generate message from observation\"\"\"\n",
    "        return self.message_encoder(obs)\n",
    "    \n",
    "    def process_messages(self, obs: torch.Tensor, \n",
    "                        messages: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process received messages with observation\"\"\"\n",
    "        avg_message = messages.mean(dim=1)\n",
    "        \n",
    "        combined = torch.cat([obs, avg_message], dim=-1)\n",
    "        \n",
    "        enhanced_obs = self.message_processor(combined)\n",
    "        \n",
    "        return enhanced_obs\n",
    "\n",
    "\n",
    "class MADDPGAgent:\n",
    "    \"\"\"Multi-Agent Deep Deterministic Policy Gradient Agent\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_idx: int, obs_dim: int, action_dim: int,\n",
    "                 n_agents: int, lr_actor: float = 1e-3, lr_critic: float = 1e-3,\n",
    "                 use_attention: bool = False, use_communication: bool = False):\n",
    "        \n",
    "        self.agent_idx = agent_idx\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.n_agents = n_agents\n",
    "        self.use_attention = use_attention\n",
    "        self.use_communication = use_communication\n",
    "        \n",
    "        self.actor = Actor(obs_dim, action_dim).to(device)\n",
    "        self.actor_target = Actor(obs_dim, action_dim).to(device)\n",
    "        \n",
    "        if use_attention:\n",
    "            self.critic = AttentionCritic(obs_dim, action_dim, n_agents).to(device)\n",
    "            self.critic_target = AttentionCritic(obs_dim, action_dim, n_agents).to(device)\n",
    "        else:\n",
    "            total_obs_dim = obs_dim * n_agents\n",
    "            total_action_dim = action_dim * n_agents\n",
    "            self.critic = Critic(total_obs_dim, total_action_dim).to(device)\n",
    "            self.critic_target = Critic(total_obs_dim, total_action_dim).to(device)\n",
    "        \n",
    "        if use_communication:\n",
    "            self.comm_network = CommunicationNetwork(obs_dim, message_dim=32).to(device)\n",
    "        \n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr_critic)\n",
    "        \n",
    "        if use_communication:\n",
    "            self.comm_optimizer = torch.optim.Adam(self.comm_network.parameters(), lr=lr_actor)\n",
    "        \n",
    "        self.hard_update(self.actor_target, self.actor)\n",
    "        self.hard_update(self.critic_target, self.critic)\n",
    "        \n",
    "        self.noise_std = 0.2\n",
    "        self.noise_decay = 0.995\n",
    "        self.min_noise = 0.01\n",
    "    \n",
    "    def act(self, obs: torch.Tensor, messages: torch.Tensor = None,\n",
    "            explore: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Select action and generate message\"\"\"\n",
    "        \n",
    "        if self.use_communication and messages is not None:\n",
    "            obs = self.comm_network.process_messages(obs, messages)\n",
    "        \n",
    "        action = self.actor(obs)\n",
    "        \n",
    "        if explore:\n",
    "            noise = torch.randn_like(action) * self.noise_std\n",
    "            action = torch.clamp(action + noise, -1, 1)\n",
    "        \n",
    "        message = None\n",
    "        if self.use_communication:\n",
    "            message = self.comm_network.generate_message(obs)\n",
    "        \n",
    "        return action, message\n",
    "    \n",
    "    def update(self, batch: Dict[str, torch.Tensor], other_actors: List[nn.Module],\n",
    "               gamma: float = 0.99, tau: float = 0.01):\n",
    "        \"\"\"Update actor and critic networks\"\"\"\n",
    "        \n",
    "        obs = batch['observations']  # [batch, n_agents, obs_dim]\n",
    "        actions = batch['actions']  # [batch, n_agents, action_dim]\n",
    "        rewards = batch['rewards']  # [batch, n_agents, 1]\n",
    "        next_obs = batch['next_observations']  # [batch, n_agents, obs_dim]\n",
    "        dones = batch['dones']  # [batch, n_agents, 1]\n",
    "        \n",
    "        batch_size = obs.shape[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_actions = torch.zeros_like(actions)\n",
    "            for i, actor in enumerate(other_actors):\n",
    "                if i == self.agent_idx:\n",
    "                    next_actions[:, i] = self.actor_target(next_obs[:, i])\n",
    "                else:\n",
    "                    next_actions[:, i] = actor(next_obs[:, i])\n",
    "            \n",
    "            if self.use_attention:\n",
    "                target_q = self.critic_target(next_obs, next_actions, self.agent_idx)\n",
    "            else:\n",
    "                next_obs_flat = next_obs.view(batch_size, -1)\n",
    "                next_actions_flat = next_actions.view(batch_size, -1)\n",
    "                target_q = self.critic_target(next_obs_flat, next_actions_flat)\n",
    "            \n",
    "            target_q = rewards[:, self.agent_idx] + gamma * (1 - dones[:, self.agent_idx]) * target_q\n",
    "        \n",
    "        if self.use_attention:\n",
    "            current_q = self.critic(obs, actions, self.agent_idx)\n",
    "        else:\n",
    "            obs_flat = obs.view(batch_size, -1)\n",
    "            actions_flat = actions.view(batch_size, -1)\n",
    "            current_q = self.critic(obs_flat, actions_flat)\n",
    "        \n",
    "        critic_loss = F.mse_loss(current_q, target_q)\n",
    "        \n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 1.0)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        current_actions = actions.clone()\n",
    "        current_actions[:, self.agent_idx] = self.actor(obs[:, self.agent_idx])\n",
    "        \n",
    "        if self.use_attention:\n",
    "            actor_loss = -self.critic(obs, current_actions, self.agent_idx).mean()\n",
    "        else:\n",
    "            obs_flat = obs.view(batch_size, -1)\n",
    "            current_actions_flat = current_actions.view(batch_size, -1)\n",
    "            actor_loss = -self.critic(obs_flat, current_actions_flat).mean()\n",
    "        \n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 1.0)\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        self.soft_update(self.actor_target, self.actor, tau)\n",
    "        self.soft_update(self.critic_target, self.critic, tau)\n",
    "        \n",
    "        self.noise_std = max(self.noise_std * self.noise_decay, self.min_noise)\n",
    "        \n",
    "        return {\n",
    "            'critic_loss': critic_loss.item(),\n",
    "            'actor_loss': actor_loss.item(),\n",
    "            'q_value': current_q.mean().item(),\n",
    "            'noise_std': self.noise_std\n",
    "        }\n",
    "    \n",
    "    def soft_update(self, target: nn.Module, source: nn.Module, tau: float):\n",
    "        \"\"\"Soft update target network\"\"\"\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "    \n",
    "    def hard_update(self, target: nn.Module, source: nn.Module):\n",
    "        \"\"\"Hard update target network\"\"\"\n",
    "        target.load_state_dict(source.state_dict())\n",
    "\n",
    "\n",
    "class MultiAgentEnvironment:\n",
    "    \"\"\"Multi-agent environment for testing\"\"\"\n",
    "    \n",
    "    def __init__(self, n_agents: int = 3, obs_dim: int = 6, action_dim: int = 2,\n",
    "                 env_type: str = 'cooperative'):\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.env_type = env_type\n",
    "        self.max_steps = 200\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self) -> np.ndarray:\n",
    "        \"\"\"Reset environment\"\"\"\n",
    "        self.agent_states = np.random.uniform(-2, 2, (self.n_agents, self.obs_dim))\n",
    "        self.steps = 0\n",
    "        \n",
    "        return self.get_observations()\n",
    "    \n",
    "    def get_observations(self) -> np.ndarray:\n",
    "        \"\"\"Get observations for all agents\"\"\"\n",
    "        observations = np.zeros((self.n_agents, self.obs_dim))\n",
    "        \n",
    "        for i in range(self.n_agents):\n",
    "            obs = self.agent_states[i].copy()\n",
    "            \n",
    "            obs += np.random.normal(0, 0.1, self.obs_dim)\n",
    "            observations[i] = obs\n",
    "        \n",
    "        return observations\n",
    "    \n",
    "    def step(self, actions: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict]:\n",
    "        \"\"\"Environment step\"\"\"\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "        \n",
    "        for i in range(self.n_agents):\n",
    "            if self.obs_dim >= 4:\n",
    "                self.agent_states[i, 2:4] += 0.1 * actions[i, :2]\n",
    "                self.agent_states[i, 2:4] *= 0.9  # Friction\n",
    "                \n",
    "                self.agent_states[i, :2] += 0.1 * self.agent_states[i, 2:4]\n",
    "            else:\n",
    "                self.agent_states[i, :2] += 0.1 * actions[i, :2]\n",
    "            \n",
    "            self.agent_states[i] += np.random.normal(0, 0.02, self.obs_dim)\n",
    "        \n",
    "        rewards = self.compute_rewards()\n",
    "        \n",
    "        self.steps += 1\n",
    "        dones = np.array([self.steps >= self.max_steps] * self.n_agents)\n",
    "        \n",
    "        for i in range(self.n_agents):\n",
    "            if np.linalg.norm(self.agent_states[i, :2]) > 5:\n",
    "                dones[i] = True\n",
    "        \n",
    "        observations = self.get_observations()\n",
    "        \n",
    "        return observations, rewards, dones, {}\n",
    "    \n",
    "    def compute_rewards(self) -> np.ndarray:\n",
    "        \"\"\"Compute rewards based on environment type\"\"\"\n",
    "        rewards = np.zeros(self.n_agents)\n",
    "        \n",
    "        if self.env_type == 'cooperative':\n",
    "            center = np.mean(self.agent_states[:, :2], axis=0)\n",
    "            \n",
    "            for i in range(self.n_agents):\n",
    "                center_reward = -np.linalg.norm(self.agent_states[i, :2])\n",
    "                \n",
    "                cohesion_reward = 0\n",
    "                for j in range(self.n_agents):\n",
    "                    if i != j:\n",
    "                        dist = np.linalg.norm(self.agent_states[i, :2] - self.agent_states[j, :2])\n",
    "                        cohesion_reward += -0.1 * dist\n",
    "                \n",
    "                rewards[i] = center_reward + 0.5 * cohesion_reward\n",
    "        \n",
    "        elif self.env_type == 'competitive':\n",
    "            target = np.array([0, 0])  # Shared resource at origin\n",
    "            \n",
    "            distances = [np.linalg.norm(self.agent_states[i, :2] - target) \n",
    "                        for i in range(self.n_agents)]\n",
    "            closest_agent = np.argmin(distances)\n",
    "            \n",
    "            for i in range(self.n_agents):\n",
    "                if i == closest_agent:\n",
    "                    rewards[i] = 1.0  # Winner gets reward\n",
    "                else:\n",
    "                    rewards[i] = -0.1  # Others get penalty\n",
    "        \n",
    "        elif self.env_type == 'mixed':\n",
    "            team_size = self.n_agents // 2\n",
    "            \n",
    "            for i in range(self.n_agents):\n",
    "                team_id = i // team_size\n",
    "                \n",
    "                team_reward = 0\n",
    "                for j in range(self.n_agents):\n",
    "                    if j // team_size == team_id and i != j:\n",
    "                        dist = np.linalg.norm(self.agent_states[i, :2] - self.agent_states[j, :2])\n",
    "                        team_reward += -0.1 * dist\n",
    "                \n",
    "                comp_reward = 0\n",
    "                for j in range(self.n_agents):\n",
    "                    if j // team_size != team_id:\n",
    "                        dist = np.linalg.norm(self.agent_states[i, :2] - self.agent_states[j, :2])\n",
    "                        comp_reward += 0.05 * max(0, 2 - dist)  # Reward for keeping distance\n",
    "                \n",
    "                rewards[i] = team_reward + comp_reward\n",
    "        \n",
    "        return rewards\n",
    "\n",
    "\n",
    "print(\"âœ… Multi-Agent RL Implementation Complete!\")\n",
    "print(\"Components implemented:\")\n",
    "print(\"- MultiAgentReplayBuffer: Experience storage for multi-agent systems\")\n",
    "print(\"- Actor/Critic: Individual agent networks with centralized training\")\n",
    "print(\"- AttentionCritic: Attention mechanism for selective agent focus\")\n",
    "print(\"- CommunicationNetwork: Neural communication between agents\")\n",
    "print(\"- MADDPGAgent: Complete MADDPG implementation with extensions\")\n",
    "print(\"- MultiAgentEnvironment: Configurable multi-agent test environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1f25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Multi-Agent RL Training...\n",
      "\n",
      "==================================================\n",
      "Training: Cooperative Environment\n",
      "==================================================\n",
      "Training agents...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 196\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining agents...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m episode_rewards, losses = \u001b[43mtrain_maddpg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced for demo\u001b[39;49;00m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating agents...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_maddpg\u001b[39m\u001b[34m(env, agents, buffer, episodes, batch_size, update_interval)\u001b[39m\n\u001b[32m     35\u001b[39m         agent_messages = torch.cat([messages[:, :i], messages[:, i+\u001b[32m1\u001b[39m:]], dim=\u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m     action_tensor, _ = agent.act(obs_tensor, agent_messages, explore=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     actions[i] = \u001b[43maction_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Environment step\u001b[39;00m\n\u001b[32m     41\u001b[39m next_obs, rewards, dones, _ = env.step(actions)\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "\n",
    "def train_maddpg(env: MultiAgentEnvironment, agents: List[MADDPGAgent],\n",
    "                 buffer: MultiAgentReplayBuffer, episodes: int = 1000,\n",
    "                 batch_size: int = 64, update_interval: int = 4):\n",
    "    \"\"\"Train MADDPG agents\"\"\"\n",
    "    \n",
    "    episode_rewards = []\n",
    "    losses = {f'agent_{i}': {'actor': [], 'critic': []} for i in range(env.n_agents)}\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = np.zeros(env.n_agents)\n",
    "        done = False\n",
    "        step = 0\n",
    "        \n",
    "        while not done:\n",
    "            messages = []\n",
    "            if agents[0].use_communication:\n",
    "                for i, agent in enumerate(agents):\n",
    "                    obs_tensor = torch.FloatTensor(obs[i]).unsqueeze(0).to(device)\n",
    "                    _, message = agent.act(obs_tensor, explore=True)\n",
    "                    messages.append(message)\n",
    "                messages = torch.stack(messages, dim=1)  # [1, n_agents, message_dim]\n",
    "            \n",
    "            actions = np.zeros((env.n_agents, env.action_dim))\n",
    "            for i, agent in enumerate(agents):\n",
    "                obs_tensor = torch.FloatTensor(obs[i]).unsqueeze(0).to(device)\n",
    "                \n",
    "                agent_messages = None\n",
    "                if agent.use_communication:\n",
    "                    agent_messages = torch.cat([messages[:, :i], messages[:, i+1:]], dim=1)\n",
    "                \n",
    "                action_tensor, _ = agent.act(obs_tensor, agent_messages, explore=True)\n",
    "                actions[i] = action_tensor.cpu().numpy()[0]\n",
    "            \n",
    "            next_obs, rewards, dones, _ = env.step(actions)\n",
    "            \n",
    "            buffer.add(obs, actions, rewards, next_obs, dones)\n",
    "            \n",
    "            episode_reward += rewards\n",
    "            obs = next_obs\n",
    "            done = np.all(dones)\n",
    "            step += 1\n",
    "            \n",
    "            if buffer.size >= batch_size and step % update_interval == 0:\n",
    "                batch = buffer.sample(batch_size)\n",
    "                \n",
    "                target_actors = [agent.actor_target for agent in agents]\n",
    "                \n",
    "                for i, agent in enumerate(agents):\n",
    "                    update_info = agent.update(batch, target_actors)\n",
    "                    losses[f'agent_{i}']['actor'].append(update_info['actor_loss'])\n",
    "                    losses[f'agent_{i}']['critic'].append(update_info['critic_loss'])\n",
    "        \n",
    "        episode_rewards.append(episode_reward.copy())\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            mean_reward = np.mean([np.sum(r) for r in episode_rewards[-100:]])\n",
    "            print(f\"Episode {episode}, Mean Reward: {mean_reward:.2f}\")\n",
    "            for i in range(env.n_agents):\n",
    "                noise_std = agents[i].noise_std\n",
    "                print(f\"  Agent {i}: Noise={noise_std:.3f}\")\n",
    "    \n",
    "    return episode_rewards, losses\n",
    "\n",
    "\n",
    "def evaluate_maddpg(env: MultiAgentEnvironment, agents: List[MADDPGAgent],\n",
    "                   episodes: int = 100) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate trained MADDPG agents\"\"\"\n",
    "    \n",
    "    episode_rewards = []\n",
    "    coordination_scores = []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = np.zeros(env.n_agents)\n",
    "        positions_history = []\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            messages = []\n",
    "            if agents[0].use_communication:\n",
    "                for i, agent in enumerate(agents):\n",
    "                    obs_tensor = torch.FloatTensor(obs[i]).unsqueeze(0).to(device)\n",
    "                    _, message = agent.act(obs_tensor, explore=False)\n",
    "                    messages.append(message)\n",
    "                messages = torch.stack(messages, dim=1)\n",
    "            \n",
    "            actions = np.zeros((env.n_agents, env.action_dim))\n",
    "            for i, agent in enumerate(agents):\n",
    "                obs_tensor = torch.FloatTensor(obs[i]).unsqueeze(0).to(device)\n",
    "                \n",
    "                agent_messages = None\n",
    "                if agent.use_communication:\n",
    "                    agent_messages = torch.cat([messages[:, :i], messages[:, i+1:]], dim=1)\n",
    "                \n",
    "                action_tensor, _ = agent.act(obs_tensor, agent_messages, explore=False)\n",
    "                actions[i] = action_tensor.cpu().numpy()[0]\n",
    "            \n",
    "            next_obs, rewards, dones, _ = env.step(actions)\n",
    "            \n",
    "            episode_reward += rewards\n",
    "            positions_history.append(env.agent_states[:, :2].copy())\n",
    "            obs = next_obs\n",
    "            done = np.all(dones)\n",
    "        \n",
    "        episode_rewards.append(episode_reward.copy())\n",
    "        \n",
    "        positions = np.array(positions_history)\n",
    "        mean_positions = np.mean(positions, axis=1)  # [timesteps, 2]\n",
    "        agent_variances = []\n",
    "        \n",
    "        for t in range(len(positions)):\n",
    "            distances_from_center = [\n",
    "                np.linalg.norm(positions[t, i] - mean_positions[t])\n",
    "                for i in range(env.n_agents)\n",
    "            ]\n",
    "            agent_variances.append(np.var(distances_from_center))\n",
    "        \n",
    "        coordination_scores.append(np.mean(agent_variances))\n",
    "    \n",
    "    results = {\n",
    "        'mean_total_reward': np.mean([np.sum(r) for r in episode_rewards]),\n",
    "        'std_total_reward': np.std([np.sum(r) for r in episode_rewards]),\n",
    "        'mean_individual_reward': np.mean(episode_rewards),\n",
    "        'coordination_score': np.mean(coordination_scores),\n",
    "        'success_rate': np.mean([np.sum(r) > 0 for r in episode_rewards])\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"ðŸš€ Starting Multi-Agent RL Training...\")\n",
    "\n",
    "env_configs = [\n",
    "    {'env_type': 'cooperative', 'name': 'Cooperative'},\n",
    "    {'env_type': 'competitive', 'name': 'Competitive'},\n",
    "    {'env_type': 'mixed', 'name': 'Mixed'}\n",
    "]\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for config in env_configs[:1]:  # Train on cooperative first\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training: {config['name']} Environment\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    env = MultiAgentEnvironment(\n",
    "        n_agents=3,\n",
    "        obs_dim=6,\n",
    "        action_dim=2,\n",
    "        env_type=config['env_type']\n",
    "    )\n",
    "    \n",
    "    agents = []\n",
    "    for i in range(env.n_agents):\n",
    "        agent = MADDPGAgent(\n",
    "            agent_idx=i,\n",
    "            obs_dim=env.obs_dim,\n",
    "            action_dim=env.action_dim,\n",
    "            n_agents=env.n_agents,\n",
    "            use_attention=True,\n",
    "            use_communication=True\n",
    "        )\n",
    "        agents.append(agent)\n",
    "    \n",
    "    buffer = MultiAgentReplayBuffer(\n",
    "        capacity=50000,\n",
    "        n_agents=env.n_agents,\n",
    "        obs_dim=env.obs_dim,\n",
    "        action_dim=env.action_dim\n",
    "    )\n",
    "    \n",
    "    print(\"Training agents...\")\n",
    "    episode_rewards, losses = train_maddpg(\n",
    "        env, agents, buffer,\n",
    "        episodes=500,  # Reduced for demo\n",
    "        batch_size=64\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating agents...\")\n",
    "    eval_results = evaluate_maddpg(env, agents, episodes=50)\n",
    "    \n",
    "    results_summary[config['name']] = {\n",
    "        'training_rewards': episode_rewards,\n",
    "        'evaluation': eval_results,\n",
    "        'losses': losses\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nResults for {config['name']} Environment:\")\n",
    "    print(f\"Mean Total Reward: {eval_results['mean_total_reward']:.3f} Â± {eval_results['std_total_reward']:.3f}\")\n",
    "    print(f\"Mean Individual Reward: {eval_results['mean_individual_reward']:.3f}\")\n",
    "    print(f\"Coordination Score: {eval_results['coordination_score']:.3f}\")\n",
    "    print(f\"Success Rate: {eval_results['success_rate']:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Multi-Agent Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056b8b2",
   "metadata": {},
   "source": [
    "# Part III: Causal Reinforcement Learning\n",
    "\n",
    "## Theoretical Foundations\n",
    "\n",
    "### Introduction to Causality in RL\n",
    "\n",
    "Causal Reinforcement Learning represents a paradigm shift from traditional correlation-based learning to understanding cause-effect relationships in sequential decision making. This approach addresses fundamental limitations in standard RL:\n",
    "\n",
    "**Key Limitations of Standard RL:**\n",
    "- **Spurious Correlations**: Agents may learn policies based on correlations that don't reflect true causal relationships\n",
    "- **Distribution Shift**: Policies trained on specific environments may fail when deployed in different conditions\n",
    "- **Sample Inefficiency**: Without causal understanding, agents require extensive exploration\n",
    "- **Interpretability**: Standard RL policies are often black boxes without clear causal reasoning\n",
    "\n",
    "### Causal Inference Framework\n",
    "\n",
    "#### 1. Structural Causal Models (SCMs)\n",
    "\n",
    "A Structural Causal Model is defined by a tuple $(U, V, F, P(U))$:\n",
    "\n",
    "- **U**: Set of exogenous (external) variables\n",
    "- **V**: Set of endogenous (internal) variables\n",
    "- **F**: Set of functions $f_i$ where $V_i = f_i(PA_i, U_i)$\n",
    "- **P(U)**: Probability distribution over exogenous variables\n",
    "\n",
    "**Causal Graph Representation:**\n",
    "```\n",
    "Exogenous Variables (U) â†’ Endogenous Variables (V)\n",
    "      â†“                           â†“\n",
    "Environmental Factors    â†’    Agent States/Actions\n",
    "```\n",
    "\n",
    "#### 2. Causal Hierarchy (Pearl's Ladder)\n",
    "\n",
    "**Level 1: Association** ($P(y|x)$)\n",
    "- \"What is the probability of Y given that we observe X?\"\n",
    "- Standard statistical/ML approaches operate here\n",
    "- Example: \"What's the probability of success given this policy?\"\n",
    "\n",
    "**Level 2: Intervention** ($P(y|do(x))$)\n",
    "- \"What is the probability of Y if we set X to a specific value?\"\n",
    "- Requires understanding of causal mechanisms\n",
    "- Example: \"What happens if we force the agent to take action A?\"\n",
    "\n",
    "**Level 3: Counterfactuals** ($P(y_x|x', y')$)\n",
    "- \"What would have happened if X had been different?\"\n",
    "- Enables reasoning about alternative scenarios\n",
    "- Example: \"Would the agent have succeeded if it had chosen a different action?\"\n",
    "\n",
    "### Causal RL Mathematical Framework\n",
    "\n",
    "#### 1. Causal Markov Decision Process (Causal-MDP)\n",
    "\n",
    "A Causal-MDP extends traditional MDPs with causal structure:\n",
    "\n",
    "**Causal-MDP Definition:**\n",
    "$$\\mathcal{M}_C = \\langle \\mathcal{S}, \\mathcal{A}, \\mathcal{G}, T_C, R_C, \\gamma \\rangle$$\n",
    "\n",
    "Where:\n",
    "- $\\mathcal{G}$: Causal graph over state variables\n",
    "- $T_C$: Causal transition function respecting $\\mathcal{G}$\n",
    "- $R_C$: Causal reward function\n",
    "\n",
    "**Causal Factorization:**\n",
    "$$P(s_{t+1}|s_t, a_t) = \\prod_{i=1}^{|\\mathcal{S}|} P(s_{t+1}^i | PA_C(s_{t+1}^i), a_t)$$\n",
    "\n",
    "#### 2. Interventional Policy Learning\n",
    "\n",
    "**Interventional Value Function:**\n",
    "$$V^{\\pi}_{do(X=x)}(s) = \\mathbb{E}\\left[\\sum_{t=0}^{\\infty} \\gamma^t R_t | S_0 = s, do(X=x), \\pi\\right]$$\n",
    "\n",
    "**Causal Policy Gradient:**\n",
    "$$\\nabla_\\theta J(\\theta) = \\mathbb{E}_{s \\sim d^\\pi, a \\sim \\pi_\\theta}\\left[\\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot \\frac{\\partial Q^{\\pi}(s,a)}{\\partial do(\\pi_\\theta)}\\right]$$\n",
    "\n",
    "#### 3. Counterfactual Reasoning in RL\n",
    "\n",
    "**Counterfactual Q-Function:**\n",
    "$$Q_{CF}(s, a, s', a') = \\mathbb{E}[R | S=s, A=a, S'_{do(A=a')} = s']$$\n",
    "\n",
    "This captures: \"What would the Q-value be if we had taken action $a'$ instead of $a$?\"\n",
    "\n",
    "### Causal Discovery in RL\n",
    "\n",
    "#### 1. Structure Learning\n",
    "\n",
    "**Constraint-Based Methods:**\n",
    "- Use conditional independence tests\n",
    "- Build causal graph from statistical dependencies\n",
    "- Example: PC Algorithm adapted for sequential data\n",
    "\n",
    "**Score-Based Methods:**\n",
    "- Optimize causal graph structure score\n",
    "- Balance model fit with complexity\n",
    "- Example: BIC score with causal constraints\n",
    "\n",
    "#### 2. Causal Effect Estimation\n",
    "\n",
    "**Backdoor Criterion:**\n",
    "For estimating causal effect of action $A$ on reward $R$:\n",
    "$$P(R|do(A)) = \\sum_z P(R|A,Z) P(Z)$$\n",
    "\n",
    "Where $Z$ blocks all backdoor paths from $A$ to $R$.\n",
    "\n",
    "**Front-door Criterion:**\n",
    "When backdoor adjustment isn't possible:\n",
    "$$P(R|do(A)) = \\sum_m P(M|A) \\sum_{a'} P(R|A',M) P(A')$$\n",
    "\n",
    "### Advanced Causal RL Techniques\n",
    "\n",
    "#### 1. Causal World Models\n",
    "\n",
    "**Causal Representation Learning:**\n",
    "Learn latent representations that respect causal structure:\n",
    "$$z_{t+1} = f_c(z_t, a_t, u_t)$$\n",
    "\n",
    "Where $f_c$ respects the causal graph structure.\n",
    "\n",
    "**Interventional Consistency:**\n",
    "$$\\mathbb{E}[z_{t+1} | do(z_t^i = v)] = \\mathbb{E}[f_c(z_t^{-i}, v, a_t, u_t)]$$\n",
    "\n",
    "#### 2. Causal Meta-Learning\n",
    "\n",
    "**Task-Invariant Causal Features:**\n",
    "Learn features that are causally relevant across tasks:\n",
    "$$\\phi^*(s) = \\arg\\min_\\phi \\sum_{T} L_T(\\phi(s)) + \\lambda \\cdot \\text{Causal-Reg}(\\phi)$$\n",
    "\n",
    "**Causal Transfer:**\n",
    "Transfer causal knowledge between domains:\n",
    "$$\\pi_{new}(a|s) = \\pi_{old}(a|\\phi_{causal}(s))$$\n",
    "\n",
    "#### 3. Confounded RL\n",
    "\n",
    "**Hidden Confounders:**\n",
    "When unobserved variables affect both states and rewards:\n",
    "$$H_t \\rightarrow S_t, H_t \\rightarrow R_t$$\n",
    "\n",
    "**Instrumental Variables:**\n",
    "Use variables correlated with actions but not directly with outcomes:\n",
    "$$IV \\rightarrow A_t \\not\\rightarrow R_t$$\n",
    "\n",
    "### Applications and Benefits\n",
    "\n",
    "#### 1. Robust Policy Learning\n",
    "- Policies that generalize across environments\n",
    "- Reduced sensitivity to spurious correlations\n",
    "- Better performance under distribution shift\n",
    "\n",
    "#### 2. Sample Efficient Exploration\n",
    "- Focus exploration on causally relevant factors\n",
    "- Avoid learning from misleading correlations\n",
    "- Faster convergence to optimal policies\n",
    "\n",
    "#### 3. Interpretable Decision Making\n",
    "- Understand why certain actions are taken\n",
    "- Provide causal explanations for policy decisions\n",
    "- Enable human oversight and validation\n",
    "\n",
    "#### 4. Safe RL Applications\n",
    "- Predict consequences of interventions\n",
    "- Avoid actions with negative causal effects\n",
    "- Enable counterfactual safety analysis\n",
    "\n",
    "### Research Challenges\n",
    "\n",
    "#### 1. Causal Discovery\n",
    "- Identifying causal structure from observational RL data\n",
    "- Handling non-stationarity and temporal dependencies\n",
    "- Scalability to high-dimensional state spaces\n",
    "\n",
    "#### 2. Identifiability\n",
    "- When can causal effects be estimated from data?\n",
    "- Addressing unmeasured confounders\n",
    "- Validation of causal assumptions\n",
    "\n",
    "#### 3. Computational Complexity\n",
    "- Efficient inference in causal graphical models\n",
    "- Scalable algorithms for large state spaces\n",
    "- Real-time causal reasoning during policy execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CausalGraph:\n",
    "    \"\"\"Represents causal relationships between variables\"\"\"\n",
    "    \n",
    "    def __init__(self, variables: List[str]):\n",
    "        self.variables = variables\n",
    "        self.n_vars = len(variables)\n",
    "        self.var_to_idx = {var: i for i, var in enumerate(variables)}\n",
    "        \n",
    "        self.adj_matrix = np.zeros((self.n_vars, self.n_vars), dtype=int)\n",
    "        \n",
    "    def add_edge(self, from_var: str, to_var: str):\n",
    "        \"\"\"Add causal edge from_var -> to_var\"\"\"\n",
    "        from_idx = self.var_to_idx[from_var]\n",
    "        to_idx = self.var_to_idx[to_var]\n",
    "        self.adj_matrix[from_idx][to_idx] = 1\n",
    "    \n",
    "    def get_parents(self, var: str) -> List[str]:\n",
    "        \"\"\"Get parent variables of var\"\"\"\n",
    "        var_idx = self.var_to_idx[var]\n",
    "        parent_indices = np.where(self.adj_matrix[:, var_idx] == 1)[0]\n",
    "        return [self.variables[i] for i in parent_indices]\n",
    "    \n",
    "    def get_children(self, var: str) -> List[str]:\n",
    "        \"\"\"Get children variables of var\"\"\"\n",
    "        var_idx = self.var_to_idx[var]\n",
    "        child_indices = np.where(self.adj_matrix[var_idx, :] == 1)[0]\n",
    "        return [self.variables[i] for i in child_indices]\n",
    "    \n",
    "    def is_d_separated(self, x: str, y: str, z: List[str]) -> bool:\n",
    "        \"\"\"Check if x and y are d-separated given z (simplified)\"\"\"\n",
    "        x_idx = self.var_to_idx[x]\n",
    "        y_idx = self.var_to_idx[y]\n",
    "        z_indices = [self.var_to_idx[var] for var in z]\n",
    "        \n",
    "        return not self._has_unblocked_path(x_idx, y_idx, z_indices)\n",
    "    \n",
    "    def _has_unblocked_path(self, start: int, end: int, blocking: List[int]) -> bool:\n",
    "        \"\"\"Simplified path checking (DFS-based)\"\"\"\n",
    "        if start == end:\n",
    "            return True\n",
    "        \n",
    "        visited = set()\n",
    "        stack = [start]\n",
    "        \n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if current in visited or current in blocking:\n",
    "                continue\n",
    "                \n",
    "            visited.add(current)\n",
    "            \n",
    "            for next_node in range(self.n_vars):\n",
    "                if (self.adj_matrix[current][next_node] == 1 or \n",
    "                    self.adj_matrix[next_node][current] == 1):\n",
    "                    if next_node == end:\n",
    "                        return True\n",
    "                    stack.append(next_node)\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Simple text visualization of the graph\"\"\"\n",
    "        print(\"Causal Graph Structure:\")\n",
    "        for i, var in enumerate(self.variables):\n",
    "            children = self.get_children(var)\n",
    "            if children:\n",
    "                print(f\"{var} -> {', '.join(children)}\")\n",
    "\n",
    "\n",
    "class CausalDiscovery:\n",
    "    \"\"\"Causal structure discovery from data\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05):\n",
    "        self.alpha = alpha  # Significance level for independence tests\n",
    "    \n",
    "    def pc_algorithm(self, data: np.ndarray, var_names: List[str]) -> CausalGraph:\n",
    "        \"\"\"PC Algorithm for causal discovery\"\"\"\n",
    "        n_vars = len(var_names)\n",
    "        \n",
    "        skeleton = np.ones((n_vars, n_vars)) - np.eye(n_vars)\n",
    "        \n",
    "        for order in range(n_vars - 2):\n",
    "            for i in range(n_vars):\n",
    "                for j in range(i + 1, n_vars):\n",
    "                    if skeleton[i][j] == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    neighbors = [k for k in range(n_vars) \n",
    "                                if k != i and k != j and skeleton[i][k] == 1]\n",
    "                    \n",
    "                    if len(neighbors) >= order:\n",
    "                        from itertools import combinations\n",
    "                        for cond_set in combinations(neighbors, order):\n",
    "                            if self._test_independence(data, i, j, list(cond_set)):\n",
    "                                skeleton[i][j] = skeleton[j][i] = 0\n",
    "                                break\n",
    "        \n",
    "        graph = CausalGraph(var_names)\n",
    "        oriented = self._orient_edges(skeleton, data)\n",
    "        \n",
    "        for i in range(n_vars):\n",
    "            for j in range(n_vars):\n",
    "                if oriented[i][j] == 1:\n",
    "                    graph.add_edge(var_names[i], var_names[j])\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def _test_independence(self, data: np.ndarray, i: int, j: int, \n",
    "                          cond_set: List[int]) -> bool:\n",
    "        \"\"\"Test conditional independence using correlation (simplified)\"\"\"\n",
    "        \n",
    "        if len(cond_set) == 0:\n",
    "            corr = np.corrcoef(data[:, i], data[:, j])[0, 1]\n",
    "            return abs(corr) < 0.1  # Simplified threshold\n",
    "        \n",
    "        from scipy.stats import pearsonr\n",
    "        \n",
    "        X = data[:, [i] + cond_set]\n",
    "        Y = data[:, j]\n",
    "        \n",
    "        if len(cond_set) == 1:\n",
    "            r_ij = np.corrcoef(data[:, i], data[:, j])[0, 1]\n",
    "            r_ik = np.corrcoef(data[:, i], data[:, cond_set[0]])[0, 1]\n",
    "            r_jk = np.corrcoef(data[:, j], data[:, cond_set[0]])[0, 1]\n",
    "            \n",
    "            partial_corr = (r_ij - r_ik * r_jk) / np.sqrt((1 - r_ik**2) * (1 - r_jk**2))\n",
    "            return abs(partial_corr) < 0.1\n",
    "        \n",
    "        return False  # Simplified - assume dependent if complex conditioning\n",
    "    \n",
    "    def _orient_edges(self, skeleton: np.ndarray, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Orient edges to create DAG (simplified)\"\"\"\n",
    "        n_vars = skeleton.shape[0]\n",
    "        oriented = np.zeros_like(skeleton)\n",
    "        \n",
    "        for i in range(n_vars):\n",
    "            for j in range(n_vars):\n",
    "                if skeleton[i][j] == 1:\n",
    "                    var_i = np.var(data[:, i])\n",
    "                    var_j = np.var(data[:, j])\n",
    "                    \n",
    "                    if var_i > var_j:\n",
    "                        oriented[i][j] = 1\n",
    "                    else:\n",
    "                        oriented[j][i] = 1\n",
    "        \n",
    "        return oriented\n",
    "\n",
    "\n",
    "class InterventionalDataset:\n",
    "    \"\"\"Dataset with interventional data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.observational_data = []\n",
    "        self.interventional_data = {}  # {intervention: data}\n",
    "    \n",
    "    def add_observational(self, data: Dict[str, np.ndarray]):\n",
    "        \"\"\"Add observational data\"\"\"\n",
    "        self.observational_data.append(data)\n",
    "    \n",
    "    def add_interventional(self, intervention: str, data: Dict[str, np.ndarray]):\n",
    "        \"\"\"Add interventional data\"\"\"\n",
    "        if intervention not in self.interventional_data:\n",
    "            self.interventional_data[intervention] = []\n",
    "        self.interventional_data[intervention].append(data)\n",
    "\n",
    "\n",
    "class CausalWorldModel(nn.Module):\n",
    "    \"\"\"World model with causal structure\"\"\"\n",
    "    \n",
    "    def __init__(self, causal_graph: CausalGraph, state_dims: Dict[str, int],\n",
    "                 action_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.causal_graph = causal_graph\n",
    "        self.state_dims = state_dims\n",
    "        self.action_dim = action_dim\n",
    "        self.variables = causal_graph.variables\n",
    "        \n",
    "        self.predictors = nn.ModuleDict()\n",
    "        \n",
    "        for var in self.variables:\n",
    "            parents = causal_graph.get_parents(var)\n",
    "            parent_dim = sum(state_dims[p] for p in parents)\n",
    "            \n",
    "            input_dim = parent_dim + action_dim\n",
    "            output_dim = state_dims[var]\n",
    "            \n",
    "            self.predictors[var] = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, output_dim)\n",
    "            )\n",
    "    \n",
    "    def forward(self, states: Dict[str, torch.Tensor], \n",
    "                actions: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Predict next states following causal structure\"\"\"\n",
    "        \n",
    "        predictions = {}\n",
    "        \n",
    "        for var in self.variables:\n",
    "            parents = self.causal_graph.get_parents(var)\n",
    "            \n",
    "            parent_values = []\n",
    "            for parent in parents:\n",
    "                parent_values.append(states[parent])\n",
    "            \n",
    "            if parent_values:\n",
    "                parent_input = torch.cat(parent_values, dim=-1)\n",
    "                model_input = torch.cat([parent_input, actions], dim=-1)\n",
    "            else:\n",
    "                model_input = actions\n",
    "            \n",
    "            predictions[var] = self.predictors[var](model_input)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def intervene(self, states: Dict[str, torch.Tensor], actions: torch.Tensor,\n",
    "                  interventions: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Predict under interventions\"\"\"\n",
    "        \n",
    "        modified_states = {k: v.clone() for k, v in states.items()}\n",
    "        for var, value in interventions.items():\n",
    "            modified_states[var] = value\n",
    "        \n",
    "        predictions = {}\n",
    "        \n",
    "        for var in self.variables:\n",
    "            if var in interventions:\n",
    "                predictions[var] = interventions[var]\n",
    "            else:\n",
    "                parents = self.causal_graph.get_parents(var)\n",
    "                parent_values = [modified_states[p] for p in parents]\n",
    "                \n",
    "                if parent_values:\n",
    "                    parent_input = torch.cat(parent_values, dim=-1)\n",
    "                    model_input = torch.cat([parent_input, actions], dim=-1)\n",
    "                else:\n",
    "                    model_input = actions\n",
    "                \n",
    "                predictions[var] = self.predictors[var](model_input)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "class CausalPolicyGradient:\n",
    "    \"\"\"Policy gradient with causal regularization\"\"\"\n",
    "    \n",
    "    def __init__(self, policy: nn.Module, causal_graph: CausalGraph,\n",
    "                 lr: float = 3e-4, causal_weight: float = 0.1):\n",
    "        \n",
    "        self.policy = policy\n",
    "        self.causal_graph = causal_graph\n",
    "        self.causal_weight = causal_weight\n",
    "        self.optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "        \n",
    "    def update(self, states: Dict[str, torch.Tensor], actions: torch.Tensor,\n",
    "               rewards: torch.Tensor, causal_world_model: CausalWorldModel):\n",
    "        \"\"\"Update policy with causal regularization\"\"\"\n",
    "        \n",
    "        log_probs = self.policy.get_log_prob(states, actions)\n",
    "        policy_loss = -(log_probs * rewards).mean()\n",
    "        \n",
    "        causal_loss = self._compute_causal_regularization(\n",
    "            states, actions, causal_world_model\n",
    "        )\n",
    "        \n",
    "        total_loss = policy_loss + self.causal_weight * causal_loss\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            'policy_loss': policy_loss.item(),\n",
    "            'causal_loss': causal_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "    \n",
    "    def _compute_causal_regularization(self, states: Dict[str, torch.Tensor],\n",
    "                                     actions: torch.Tensor,\n",
    "                                     causal_world_model: CausalWorldModel) -> torch.Tensor:\n",
    "        \"\"\"Compute causal regularization term\"\"\"\n",
    "        \n",
    "        consistency_loss = 0\n",
    "        n_interventions = 0\n",
    "        \n",
    "        for var in self.causal_graph.variables:\n",
    "            intervention_value = torch.randn_like(states[var])\n",
    "            interventions = {var: intervention_value}\n",
    "            \n",
    "            pred_intervened = causal_world_model.intervene(states, actions, interventions)\n",
    "            \n",
    "            modified_states = {k: v.clone() for k, v in states.items()}\n",
    "            modified_states[var] = intervention_value\n",
    "            pred_modified = causal_world_model(modified_states, actions)\n",
    "            \n",
    "            for other_var in self.causal_graph.variables:\n",
    "                if other_var != var and not self._is_descendant(var, other_var):\n",
    "                    consistency_loss += F.mse_loss(\n",
    "                        pred_intervened[other_var],\n",
    "                        pred_modified[other_var]\n",
    "                    )\n",
    "                    n_interventions += 1\n",
    "        \n",
    "        return consistency_loss / max(n_interventions, 1)\n",
    "    \n",
    "    def _is_descendant(self, ancestor: str, var: str) -> bool:\n",
    "        \"\"\"Check if var is a descendant of ancestor\"\"\"\n",
    "        visited = set()\n",
    "        stack = self.causal_graph.get_children(ancestor)\n",
    "        \n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if current == var:\n",
    "                return True\n",
    "            if current in visited:\n",
    "                continue\n",
    "            visited.add(current)\n",
    "            stack.extend(self.causal_graph.get_children(current))\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "def create_synthetic_causal_data(n_samples: int = 1000):\n",
    "    \"\"\"Create synthetic data with known causal structure\"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    e1 = np.random.normal(0, 0.5, n_samples)\n",
    "    e2 = np.random.normal(0, 0.3, n_samples)\n",
    "    e3 = np.random.normal(0, 0.4, n_samples)\n",
    "    \n",
    "    actions = np.random.uniform(-1, 1, (n_samples, 2))\n",
    "    \n",
    "    X1 = e1\n",
    "    X2 = 0.7 * X1 + 0.5 * actions[:, 0] + e2\n",
    "    X3 = 0.8 * X2 + 0.3 * X1 + e3\n",
    "    \n",
    "    data['X1'] = X1.reshape(-1, 1)\n",
    "    data['X2'] = X2.reshape(-1, 1)\n",
    "    data['X3'] = X3.reshape(-1, 1)\n",
    "    \n",
    "    return data, actions\n",
    "\n",
    "\n",
    "print(\"ðŸ” Testing Causal Discovery...\")\n",
    "\n",
    "states_data, actions_data = create_synthetic_causal_data(1000)\n",
    "\n",
    "data_matrix = np.hstack([states_data['X1'], states_data['X2'], states_data['X3']])\n",
    "var_names = ['X1', 'X2', 'X3']\n",
    "\n",
    "discovery = CausalDiscovery(alpha=0.05)\n",
    "discovered_graph = discovery.pc_algorithm(data_matrix, var_names)\n",
    "\n",
    "print(\"Discovered Causal Structure:\")\n",
    "discovered_graph.visualize()\n",
    "\n",
    "true_graph = CausalGraph(var_names)\n",
    "true_graph.add_edge('X1', 'X2')\n",
    "true_graph.add_edge('X1', 'X3')\n",
    "true_graph.add_edge('X2', 'X3')\n",
    "\n",
    "print(\"\\nTrue Causal Structure:\")\n",
    "true_graph.visualize()\n",
    "\n",
    "print(\"\\nâœ… Causal Discovery Complete!\")\n",
    "print(\"Note: Discovery accuracy depends on data size and statistical tests.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe02fc",
   "metadata": {},
   "source": [
    "# Part IV: Quantum Reinforcement Learning\n",
    "\n",
    "## Theoretical Foundations\n",
    "\n",
    "### Introduction to Quantum Computing for RL\n",
    "\n",
    "Quantum Reinforcement Learning (QRL) leverages quantum mechanical phenomena to enhance reinforcement learning algorithms. This emerging field promises exponential speedups for certain RL problems and enables exploration of vast state spaces that are intractable for classical computers.\n",
    "\n",
    "**Key Quantum Phenomena:**\n",
    "- **Superposition**: Quantum states can exist in multiple states simultaneously\n",
    "- **Entanglement**: Quantum systems can be correlated in non-classical ways\n",
    "- **Interference**: Quantum amplitudes can interfere constructively or destructively\n",
    "- **Quantum Parallelism**: Process multiple inputs simultaneously\n",
    "\n",
    "### Quantum Computing Fundamentals\n",
    "\n",
    "#### 1. Quantum State Representation\n",
    "\n",
    "**Qubit State:**\n",
    "$$|\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle$$\n",
    "\n",
    "Where $|\\alpha|^2 + |\\beta|^2 = 1$ and $\\alpha, \\beta \\in \\mathbb{C}$.\n",
    "\n",
    "**Multi-qubit System:**\n",
    "$$|\\psi\\rangle = \\sum_{i=0}^{2^n-1} \\alpha_i |i\\rangle$$\n",
    "\n",
    "For $n$ qubits with $\\sum_{i=0}^{2^n-1} |\\alpha_i|^2 = 1$.\n",
    "\n",
    "#### 2. Quantum Operations\n",
    "\n",
    "**Quantum Gates:**\n",
    "- **Pauli-X**: $X = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}$ (Bit flip)\n",
    "- **Pauli-Y**: $Y = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}$\n",
    "- **Pauli-Z**: $Z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$ (Phase flip)\n",
    "- **Hadamard**: $H = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}$ (Superposition)\n",
    "\n",
    "**Rotation Gates:**\n",
    "$$R_x(\\theta) = \\begin{pmatrix} \\cos(\\theta/2) & -i\\sin(\\theta/2) \\\\ -i\\sin(\\theta/2) & \\cos(\\theta/2) \\end{pmatrix}$$\n",
    "\n",
    "$$R_y(\\theta) = \\begin{pmatrix} \\cos(\\theta/2) & -\\sin(\\theta/2) \\\\ \\sin(\\theta/2) & \\cos(\\theta/2) \\end{pmatrix}$$\n",
    "\n",
    "#### 3. Quantum Measurement\n",
    "\n",
    "**Born Rule:**\n",
    "$$P(|i\\rangle) = |\\langle i | \\psi \\rangle|^2$$\n",
    "\n",
    "The probability of measuring state $|i\\rangle$ from state $|\\psi\\rangle$.\n",
    "\n",
    "### Quantum Reinforcement Learning Framework\n",
    "\n",
    "#### 1. Quantum MDP (QMDP)\n",
    "\n",
    "**Quantum State Space:**\n",
    "States are represented as quantum states in Hilbert space $\\mathcal{H}$:\n",
    "$$|\\psi_s\\rangle \\in \\mathcal{H}, \\quad \\langle\\psi_s|\\psi_s\\rangle = 1$$\n",
    "\n",
    "**Quantum Action Space:**\n",
    "Actions correspond to unitary operations:\n",
    "$$\\mathcal{A} = \\{U_a : U_a^\\dagger U_a = I\\}$$\n",
    "\n",
    "**Quantum Transition Dynamics:**\n",
    "$$|\\psi_{t+1}\\rangle = U_{a_t} |\\psi_t\\rangle \\otimes |\\text{env}_t\\rangle$$\n",
    "\n",
    "#### 2. Quantum Value Functions\n",
    "\n",
    "**Quantum Q-Function:**\n",
    "$$Q(|\\psi\\rangle, U_a) = \\langle\\psi| U_a^\\dagger \\hat{R} U_a |\\psi\\rangle + \\gamma \\mathbb{E}[V(|\\psi'\\rangle)]$$\n",
    "\n",
    "Where $\\hat{R}$ is the reward operator.\n",
    "\n",
    "**Quantum Bellman Equation:**\n",
    "$$\\hat{V}|\\psi\\rangle = \\max_{U_a} \\left(\\hat{R}U_a|\\psi\\rangle + \\gamma \\sum_{|\\psi'\\rangle} P(|\\psi'\\rangle||\\psi\\rangle, U_a) \\hat{V}|\\psi'\\rangle\\right)$$\n",
    "\n",
    "#### 3. Quantum Policy Representation\n",
    "\n",
    "**Parameterized Quantum Circuit (PQC):**\n",
    "$$|\\psi(\\theta)\\rangle = U_L(\\theta_L) \\cdots U_2(\\theta_2) U_1(\\theta_1) |\\psi_0\\rangle$$\n",
    "\n",
    "Where each $U_i(\\theta_i)$ is a parameterized unitary gate.\n",
    "\n",
    "**Quantum Policy:**\n",
    "$$\\pi_\\theta(a|s) = |\\langle a | U(\\theta) |s \\rangle|^2$$\n",
    "\n",
    "### Variational Quantum Algorithms for RL\n",
    "\n",
    "#### 1. Variational Quantum Eigensolver (VQE) for Value Functions\n",
    "\n",
    "**Objective:**\n",
    "$$\\theta^* = \\arg\\min_\\theta \\langle\\psi(\\theta)| \\hat{H} |\\psi(\\theta)\\rangle$$\n",
    "\n",
    "Where $\\hat{H}$ encodes the RL problem structure.\n",
    "\n",
    "**Gradient Calculation:**\n",
    "$$\\nabla_\\theta f(\\theta) = \\frac{1}{2}[f(\\theta + \\pi/2) - f(\\theta - \\pi/2)]$$\n",
    "\n",
    "#### 2. Quantum Approximate Optimization Algorithm (QAOA)\n",
    "\n",
    "**QAOA Ansatz:**\n",
    "$$|\\psi(\\gamma, \\beta)\\rangle = \\prod_{p=1}^P U_B(\\beta_p) U_C(\\gamma_p) |\\psi_0\\rangle$$\n",
    "\n",
    "Where:\n",
    "- $U_C(\\gamma) = \\exp(-i\\gamma \\hat{H}_C)$ (Cost Hamiltonian)\n",
    "- $U_B(\\beta) = \\exp(-i\\beta \\hat{H}_B)$ (Mixer Hamiltonian)\n",
    "\n",
    "### Quantum Advantage in RL\n",
    "\n",
    "#### 1. Exponential State Space\n",
    "\n",
    "**Classical Scaling:**\n",
    "Memory: $O(2^n)$ for $n$-qubit states\n",
    "Operations: $O(2^{2n})$ for general operations\n",
    "\n",
    "**Quantum Scaling:**\n",
    "Memory: $O(n)$ qubits\n",
    "Operations: $O(poly(n))$ for many quantum algorithms\n",
    "\n",
    "#### 2. Quantum Speedups\n",
    "\n",
    "**Grover's Algorithm for RL:**\n",
    "- Search optimal actions in $O(\\sqrt{N})$ instead of $O(N)$\n",
    "- Applicable to unstructured action spaces\n",
    "\n",
    "**Quantum Walk for Exploration:**\n",
    "- Quadratic speedup over classical random walk\n",
    "- Enhanced exploration capabilities\n",
    "\n",
    "**Shor's Algorithm Applications:**\n",
    "- Factoring in cryptographic environments\n",
    "- Period finding in periodic MDPs\n",
    "\n",
    "### Quantum Machine Learning Integration\n",
    "\n",
    "#### 1. Quantum Neural Networks (QNNs)\n",
    "\n",
    "**Quantum Perceptron:**\n",
    "$$f(x) = \\langle 0^{\\otimes n} | U^\\dagger(\\theta) M U(\\theta) |x\\rangle$$\n",
    "\n",
    "Where $U(\\theta)$ is a parameterized quantum circuit and $M$ is a measurement operator.\n",
    "\n",
    "**Quantum Convolutional Neural Networks:**\n",
    "- Quantum convolution using local unitaries\n",
    "- Translation equivariance in quantum feature maps\n",
    "\n",
    "#### 2. Quantum Kernel Methods\n",
    "\n",
    "**Quantum Feature Map:**\n",
    "$$\\Phi(x) = |\\phi(x)\\rangle = U_\\phi(x)|0\\rangle^{\\otimes n}$$\n",
    "\n",
    "**Quantum Kernel:**\n",
    "$$K(x_i, x_j) = |\\langle\\phi(x_i)|\\phi(x_j)\\rangle|^2$$\n",
    "\n",
    "Potentially exponential advantage in feature space dimension.\n",
    "\n",
    "### Advanced QRL Techniques\n",
    "\n",
    "#### 1. Quantum Actor-Critic\n",
    "\n",
    "**Quantum Actor:**\n",
    "$$\\pi_\\theta(a|s) = \\text{Tr}[\\Pi_a U_\\theta(s) \\rho_s U_\\theta(s)^\\dagger]$$\n",
    "\n",
    "Where $\\Pi_a$ is the projector onto action $a$.\n",
    "\n",
    "**Quantum Critic:**\n",
    "$$V_\\phi(s) = \\text{Tr}[\\hat{V}_\\phi \\rho_s]$$\n",
    "\n",
    "**Quantum Policy Gradient:**\n",
    "$$\\nabla_\\theta J(\\theta) = \\sum_{s,a} \\rho^\\pi(s) \\nabla_\\theta \\pi_\\theta(a|s) Q^\\pi(s,a)$$\n",
    "\n",
    "#### 2. Quantum Experience Replay\n",
    "\n",
    "**Quantum Superposition of Experiences:**\n",
    "$$|\\text{memory}\\rangle = \\frac{1}{\\sqrt{N}} \\sum_{i=1}^N |s_i, a_i, r_i, s_i'\\rangle$$\n",
    "\n",
    "**Quantum Sampling:**\n",
    "Use quantum interference to bias sampling towards important experiences.\n",
    "\n",
    "#### 3. Quantum Multi-Agent RL\n",
    "\n",
    "**Entangled Agent States:**\n",
    "$$|\\psi_{\\text{agents}}\\rangle = \\frac{1}{\\sqrt{2}}(|\\psi_1\\rangle \\otimes |\\psi_2\\rangle + |\\psi_1'\\rangle \\otimes |\\psi_2'\\rangle)$$\n",
    "\n",
    "**Quantum Communication:**\n",
    "Agents share quantum information through entanglement.\n",
    "\n",
    "### Quantum Error Correction in QRL\n",
    "\n",
    "#### 1. Noisy Intermediate-Scale Quantum (NISQ) Era\n",
    "\n",
    "**Noise Models:**\n",
    "- Decoherence: $\\rho(t) = e^{-\\Gamma t} \\rho(0)$\n",
    "- Gate errors: Imperfect unitary operations\n",
    "- Measurement errors: Probabilistic bit flips\n",
    "\n",
    "**Error Mitigation:**\n",
    "- Zero noise extrapolation\n",
    "- Error amplification and cancellation\n",
    "- Probabilistic error cancellation\n",
    "\n",
    "#### 2. Fault-Tolerant QRL\n",
    "\n",
    "**Quantum Error Correction Codes:**\n",
    "- Surface codes for topological protection\n",
    "- Stabilizer codes for syndrome detection\n",
    "- Logical qubit operations\n",
    "\n",
    "### Applications and Use Cases\n",
    "\n",
    "#### 1. Quantum Chemistry RL\n",
    "- Molecular dynamics simulation\n",
    "- Drug discovery optimization\n",
    "- Catalyst design\n",
    "\n",
    "#### 2. Quantum Finance\n",
    "- Portfolio optimization with quantum speedup\n",
    "- Risk analysis using quantum simulation\n",
    "- Quantum Monte Carlo for derivatives pricing\n",
    "\n",
    "#### 3. Quantum Cryptography RL\n",
    "- Quantum key distribution protocols\n",
    "- Post-quantum cryptography\n",
    "- Quantum-safe communications\n",
    "\n",
    "#### 4. Quantum Optimization\n",
    "- Traffic flow optimization\n",
    "- Supply chain management\n",
    "- Resource allocation problems\n",
    "\n",
    "### Current Limitations and Challenges\n",
    "\n",
    "#### 1. Hardware Limitations\n",
    "- Limited qubit count and coherence time\n",
    "- High error rates in current quantum devices\n",
    "- Connectivity constraints in quantum architectures\n",
    "\n",
    "#### 2. Algorithmic Challenges\n",
    "- Barren plateaus in quantum optimization\n",
    "- Classical simulation for algorithm development\n",
    "- Quantum advantage verification\n",
    "\n",
    "#### 3. Practical Implementation\n",
    "- Quantum software development complexity\n",
    "- Integration with classical systems\n",
    "- Scalability to real-world problems\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "#### 1. Near-term Applications\n",
    "- Hybrid classical-quantum algorithms\n",
    "- NISQ-era quantum advantage demonstrations\n",
    "- Quantum-enhanced machine learning\n",
    "\n",
    "#### 2. Long-term Vision\n",
    "- Fault-tolerant quantum RL systems\n",
    "- Universal quantum learning machines\n",
    "- Quantum artificial general intelligence\n",
    "\n",
    "#### 3. Theoretical Advances\n",
    "- Quantum learning theory foundations\n",
    "- Quantum-classical complexity separations\n",
    "- Novel quantum algorithms for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df59bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class QuantumState:\n",
    "    \"\"\"Quantum state representation\"\"\"\n",
    "    \n",
    "    def __init__(self, amplitudes: np.ndarray):\n",
    "        self.amplitudes = amplitudes / np.linalg.norm(amplitudes)\n",
    "        self.n_qubits = int(np.log2(len(amplitudes)))\n",
    "    \n",
    "    @classmethod\n",
    "    def zero_state(cls, n_qubits: int):\n",
    "        \"\"\"Create |0...0> state\"\"\"\n",
    "        amplitudes = np.zeros(2**n_qubits)\n",
    "        amplitudes[0] = 1.0\n",
    "        return cls(amplitudes)\n",
    "    \n",
    "    @classmethod\n",
    "    def uniform_superposition(cls, n_qubits: int):\n",
    "        \"\"\"Create uniform superposition state\"\"\"\n",
    "        amplitudes = np.ones(2**n_qubits) / np.sqrt(2**n_qubits)\n",
    "        return cls(amplitudes)\n",
    "    \n",
    "    def probability(self, basis_state: int) -> float:\n",
    "        \"\"\"Probability of measuring basis_state\"\"\"\n",
    "        return abs(self.amplitudes[basis_state])**2\n",
    "    \n",
    "    def measure(self) -> int:\n",
    "        \"\"\"Measure state and return basis state\"\"\"\n",
    "        probabilities = [abs(amp)**2 for amp in self.amplitudes]\n",
    "        return np.random.choice(len(probabilities), p=probabilities)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"QuantumState({self.amplitudes})\"\n",
    "\n",
    "\n",
    "class QuantumGate:\n",
    "    \"\"\"Quantum gate operations\"\"\"\n",
    "    \n",
    "    def __init__(self, matrix: np.ndarray):\n",
    "        self.matrix = matrix.astype(complex)\n",
    "    \n",
    "    @classmethod\n",
    "    def pauli_x(cls):\n",
    "        \"\"\"Pauli-X (NOT) gate\"\"\"\n",
    "        return cls(np.array([[0, 1], [1, 0]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def pauli_y(cls):\n",
    "        \"\"\"Pauli-Y gate\"\"\"\n",
    "        return cls(np.array([[0, -1j], [1j, 0]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def pauli_z(cls):\n",
    "        \"\"\"Pauli-Z gate\"\"\"\n",
    "        return cls(np.array([[1, 0], [0, -1]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def hadamard(cls):\n",
    "        \"\"\"Hadamard gate\"\"\"\n",
    "        return cls(np.array([[1, 1], [1, -1]]) / np.sqrt(2))\n",
    "    \n",
    "    @classmethod\n",
    "    def rotation_x(cls, theta: float):\n",
    "        \"\"\"Rotation around X-axis\"\"\"\n",
    "        c = np.cos(theta/2)\n",
    "        s = np.sin(theta/2)\n",
    "        return cls(np.array([[c, -1j*s], [-1j*s, c]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def rotation_y(cls, theta: float):\n",
    "        \"\"\"Rotation around Y-axis\"\"\"\n",
    "        c = np.cos(theta/2)\n",
    "        s = np.sin(theta/2)\n",
    "        return cls(np.array([[c, -s], [s, c]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def rotation_z(cls, theta: float):\n",
    "        \"\"\"Rotation around Z-axis\"\"\"\n",
    "        return cls(np.array([[np.exp(-1j*theta/2), 0], \n",
    "                           [0, np.exp(1j*theta/2)]]))\n",
    "    \n",
    "    @classmethod\n",
    "    def cnot(cls):\n",
    "        \"\"\"Controlled-NOT gate\"\"\"\n",
    "        return cls(np.array([[1, 0, 0, 0],\n",
    "                           [0, 1, 0, 0],\n",
    "                           [0, 0, 0, 1],\n",
    "                           [0, 0, 1, 0]]))\n",
    "    \n",
    "    def apply(self, state: QuantumState) -> QuantumState:\n",
    "        \"\"\"Apply gate to quantum state\"\"\"\n",
    "        new_amplitudes = self.matrix @ state.amplitudes\n",
    "        return QuantumState(new_amplitudes)\n",
    "    \n",
    "    def tensor(self, other: 'QuantumGate') -> 'QuantumGate':\n",
    "        \"\"\"Tensor product with another gate\"\"\"\n",
    "        return QuantumGate(np.kron(self.matrix, other.matrix))\n",
    "\n",
    "\n",
    "class QuantumCircuit:\n",
    "    \"\"\"Quantum circuit implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.gates = []\n",
    "        self.parameters = []\n",
    "    \n",
    "    def add_gate(self, gate: QuantumGate, qubits: List[int]):\n",
    "        \"\"\"Add gate to specific qubits\"\"\"\n",
    "        self.gates.append((gate, qubits))\n",
    "    \n",
    "    def add_parameterized_gate(self, gate_type: str, qubit: int, param_idx: int):\n",
    "        \"\"\"Add parameterized gate\"\"\"\n",
    "        self.gates.append((gate_type, qubit, param_idx))\n",
    "    \n",
    "    def execute(self, initial_state: QuantumState, \n",
    "                parameters: np.ndarray = None) -> QuantumState:\n",
    "        \"\"\"Execute circuit on initial state\"\"\"\n",
    "        current_state = initial_state\n",
    "        \n",
    "        for gate_info in self.gates:\n",
    "            if isinstance(gate_info[0], QuantumGate):\n",
    "                gate, qubits = gate_info\n",
    "                if len(qubits) == 1:\n",
    "                    full_gate = self._expand_gate(gate, qubits[0])\n",
    "                else:\n",
    "                    full_gate = gate\n",
    "                \n",
    "                current_state = full_gate.apply(current_state)\n",
    "            \n",
    "            else:\n",
    "                gate_type, qubit, param_idx = gate_info\n",
    "                param_value = parameters[param_idx] if parameters is not None else 0\n",
    "                \n",
    "                if gate_type == 'rx':\n",
    "                    gate = QuantumGate.rotation_x(param_value)\n",
    "                elif gate_type == 'ry':\n",
    "                    gate = QuantumGate.rotation_y(param_value)\n",
    "                elif gate_type == 'rz':\n",
    "                    gate = QuantumGate.rotation_z(param_value)\n",
    "                \n",
    "                full_gate = self._expand_gate(gate, qubit)\n",
    "                current_state = full_gate.apply(current_state)\n",
    "        \n",
    "        return current_state\n",
    "    \n",
    "    def _expand_gate(self, gate: QuantumGate, target_qubit: int) -> QuantumGate:\n",
    "        \"\"\"Expand single-qubit gate to full system\"\"\"\n",
    "        identity = QuantumGate(np.eye(2))\n",
    "        \n",
    "        if self.n_qubits == 1:\n",
    "            return gate\n",
    "        \n",
    "        gates = []\n",
    "        for i in range(self.n_qubits):\n",
    "            if i == target_qubit:\n",
    "                gates.append(gate)\n",
    "            else:\n",
    "                gates.append(identity)\n",
    "        \n",
    "        result = gates[0]\n",
    "        for i in range(1, len(gates)):\n",
    "            result = result.tensor(gates[i])\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class VariationalQuantumCircuit:\n",
    "    \"\"\"Variational quantum circuit for quantum machine learning\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int, n_layers: int):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.n_parameters = 3 * n_qubits * n_layers  # 3 rotations per qubit per layer\n",
    "        \n",
    "        self.parameters = np.random.uniform(0, 2*np.pi, self.n_parameters)\n",
    "    \n",
    "    def create_circuit(self) -> QuantumCircuit:\n",
    "        \"\"\"Create the variational circuit structure\"\"\"\n",
    "        circuit = QuantumCircuit(self.n_qubits)\n",
    "        param_idx = 0\n",
    "        \n",
    "        for layer in range(self.n_layers):\n",
    "            for qubit in range(self.n_qubits):\n",
    "                circuit.add_parameterized_gate('rx', qubit, param_idx)\n",
    "                param_idx += 1\n",
    "                circuit.add_parameterized_gate('ry', qubit, param_idx)\n",
    "                param_idx += 1\n",
    "                circuit.add_parameterized_gate('rz', qubit, param_idx)\n",
    "                param_idx += 1\n",
    "            \n",
    "            if layer < self.n_layers - 1:\n",
    "                for qubit in range(self.n_qubits - 1):\n",
    "                    circuit.add_gate(QuantumGate.cnot(), [qubit, qubit + 1])\n",
    "                if self.n_qubits > 2:\n",
    "                    circuit.add_gate(QuantumGate.cnot(), [self.n_qubits - 1, 0])\n",
    "        \n",
    "        return circuit\n",
    "    \n",
    "    def forward(self, input_state: QuantumState) -> QuantumState:\n",
    "        \"\"\"Forward pass through the circuit\"\"\"\n",
    "        circuit = self.create_circuit()\n",
    "        return circuit.execute(input_state, self.parameters)\n",
    "    \n",
    "    def measure_expectation(self, observable: QuantumGate, \n",
    "                          input_state: QuantumState) -> float:\n",
    "        \"\"\"Measure expectation value of observable\"\"\"\n",
    "        output_state = self.forward(input_state)\n",
    "        expectation = np.real(\n",
    "            np.conj(output_state.amplitudes) @ observable.matrix @ output_state.amplitudes\n",
    "        )\n",
    "        return expectation\n",
    "    \n",
    "    def gradient(self, observable: QuantumGate, input_state: QuantumState,\n",
    "                param_idx: int) -> float:\n",
    "        \"\"\"Parameter-shift rule for gradient calculation\"\"\"\n",
    "        original_param = self.parameters[param_idx]\n",
    "        \n",
    "        self.parameters[param_idx] = original_param + np.pi/2\n",
    "        expectation_plus = self.measure_expectation(observable, input_state)\n",
    "        \n",
    "        self.parameters[param_idx] = original_param - np.pi/2\n",
    "        expectation_minus = self.measure_expectation(observable, input_state)\n",
    "        \n",
    "        self.parameters[param_idx] = original_param\n",
    "        \n",
    "        return 0.5 * (expectation_plus - expectation_minus)\n",
    "\n",
    "\n",
    "class QuantumQLearning:\n",
    "    \"\"\"Quantum Q-Learning implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int, n_actions: int, n_layers: int = 3,\n",
    "                 learning_rate: float = 0.1, gamma: float = 0.95):\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_actions = n_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.q_circuits = {}\n",
    "        for action in range(n_actions):\n",
    "            self.q_circuits[action] = VariationalQuantumCircuit(n_qubits, n_layers)\n",
    "        \n",
    "        self.q_observable = QuantumGate.pauli_z()\n",
    "    \n",
    "    def state_to_quantum(self, state: np.ndarray) -> QuantumState:\n",
    "        \"\"\"Encode classical state to quantum state\"\"\"\n",
    "        if len(state) <= 2**self.n_qubits:\n",
    "            amplitudes = np.zeros(2**self.n_qubits)\n",
    "            amplitudes[:len(state)] = state\n",
    "            amplitudes = amplitudes / np.linalg.norm(amplitudes)\n",
    "            return QuantumState(amplitudes)\n",
    "        else:\n",
    "            state_index = int(np.sum(state * [2**i for i in range(len(state))]))\n",
    "            state_index = state_index % (2**self.n_qubits)\n",
    "            amplitudes = np.zeros(2**self.n_qubits)\n",
    "            amplitudes[state_index] = 1.0\n",
    "            return QuantumState(amplitudes)\n",
    "    \n",
    "    def get_q_values(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Get Q-values for all actions\"\"\"\n",
    "        quantum_state = self.state_to_quantum(state)\n",
    "        q_values = np.zeros(self.n_actions)\n",
    "        \n",
    "        for action in range(self.n_actions):\n",
    "            q_values[action] = self.q_circuits[action].measure_expectation(\n",
    "                self.q_observable, quantum_state\n",
    "            )\n",
    "        \n",
    "        return q_values\n",
    "    \n",
    "    def select_action(self, state: np.ndarray, epsilon: float = 0.1) -> int:\n",
    "        \"\"\"Epsilon-greedy action selection\"\"\"\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            q_values = self.get_q_values(state)\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    def update(self, state: np.ndarray, action: int, reward: float,\n",
    "               next_state: np.ndarray, done: bool):\n",
    "        \"\"\"Update quantum Q-function\"\"\"\n",
    "        quantum_state = self.state_to_quantum(state)\n",
    "        \n",
    "        current_q = self.q_circuits[action].measure_expectation(\n",
    "            self.q_observable, quantum_state\n",
    "        )\n",
    "        \n",
    "        if done:\n",
    "            target_q = reward\n",
    "        else:\n",
    "            next_q_values = self.get_q_values(next_state)\n",
    "            target_q = reward + self.gamma * np.max(next_q_values)\n",
    "        \n",
    "        td_error = target_q - current_q\n",
    "        \n",
    "        for param_idx in range(self.q_circuits[action].n_parameters):\n",
    "            gradient = self.q_circuits[action].gradient(\n",
    "                self.q_observable, quantum_state, param_idx\n",
    "            )\n",
    "            \n",
    "            self.q_circuits[action].parameters[param_idx] += (\n",
    "                self.learning_rate * td_error * gradient\n",
    "            )\n",
    "\n",
    "\n",
    "class QuantumActorCritic:\n",
    "    \"\"\"Quantum Actor-Critic implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int, n_actions: int, n_layers: int = 3):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_actions = n_actions\n",
    "        \n",
    "        self.actor_circuit = VariationalQuantumCircuit(n_qubits, n_layers)\n",
    "        self.critic_circuit = VariationalQuantumCircuit(n_qubits, n_layers)\n",
    "        \n",
    "        self.policy_observables = [\n",
    "            QuantumGate.pauli_z() for _ in range(n_actions)\n",
    "        ]\n",
    "        self.value_observable = QuantumGate.pauli_z()\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        self.gamma = 0.95\n",
    "    \n",
    "    def state_to_quantum(self, state: np.ndarray) -> QuantumState:\n",
    "        \"\"\"Convert classical state to quantum state\"\"\"\n",
    "        amplitudes = np.zeros(2**self.n_qubits)\n",
    "        state_norm = np.linalg.norm(state)\n",
    "        if state_norm > 0:\n",
    "            state = state / state_norm\n",
    "        \n",
    "        for i, val in enumerate(state[:2**self.n_qubits]):\n",
    "            amplitudes[i] = val\n",
    "        \n",
    "        amplitudes = amplitudes / np.linalg.norm(amplitudes)\n",
    "        return QuantumState(amplitudes)\n",
    "    \n",
    "    def get_action_probabilities(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Get action probabilities from quantum actor\"\"\"\n",
    "        quantum_state = self.state_to_quantum(state)\n",
    "        \n",
    "        expectations = np.zeros(self.n_actions)\n",
    "        for action in range(self.n_actions):\n",
    "            expectations[action] = self.actor_circuit.measure_expectation(\n",
    "                self.policy_observables[action], quantum_state\n",
    "            )\n",
    "        \n",
    "        exp_vals = np.exp(expectations)\n",
    "        probabilities = exp_vals / np.sum(exp_vals)\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def get_value(self, state: np.ndarray) -> float:\n",
    "        \"\"\"Get state value from quantum critic\"\"\"\n",
    "        quantum_state = self.state_to_quantum(state)\n",
    "        return self.critic_circuit.measure_expectation(\n",
    "            self.value_observable, quantum_state\n",
    "        )\n",
    "    \n",
    "    def select_action(self, state: np.ndarray) -> int:\n",
    "        \"\"\"Sample action from quantum policy\"\"\"\n",
    "        probabilities = self.get_action_probabilities(state)\n",
    "        return np.random.choice(self.n_actions, p=probabilities)\n",
    "    \n",
    "    def update(self, state: np.ndarray, action: int, reward: float,\n",
    "               next_state: np.ndarray, done: bool):\n",
    "        \"\"\"Update actor and critic\"\"\"\n",
    "        quantum_state = self.state_to_quantum(state)\n",
    "        \n",
    "        current_value = self.get_value(state)\n",
    "        if done:\n",
    "            target_value = reward\n",
    "        else:\n",
    "            next_value = self.get_value(next_state)\n",
    "            target_value = reward + self.gamma * next_value\n",
    "        \n",
    "        td_error = target_value - current_value\n",
    "        \n",
    "        for param_idx in range(self.critic_circuit.n_parameters):\n",
    "            gradient = self.critic_circuit.gradient(\n",
    "                self.value_observable, quantum_state, param_idx\n",
    "            )\n",
    "            self.critic_circuit.parameters[param_idx] += (\n",
    "                self.learning_rate * td_error * gradient\n",
    "            )\n",
    "        \n",
    "        for param_idx in range(self.actor_circuit.n_parameters):\n",
    "            gradient = self.actor_circuit.gradient(\n",
    "                self.policy_observables[action], quantum_state, param_idx\n",
    "            )\n",
    "            self.actor_circuit.parameters[param_idx] += (\n",
    "                self.learning_rate * td_error * gradient\n",
    "            )\n",
    "\n",
    "\n",
    "class QuantumEnvironment:\n",
    "    \"\"\"Simple quantum-inspired environment\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int = 2):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.state_dim = 2**n_qubits\n",
    "        self.n_actions = 4  # Four possible quantum gates\n",
    "        \n",
    "        self.target_state = QuantumState.uniform_superposition(n_qubits)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self) -> np.ndarray:\n",
    "        \"\"\"Reset environment\"\"\"\n",
    "        self.current_state = QuantumState.zero_state(self.n_qubits)\n",
    "        self.steps = 0\n",
    "        return self.current_state.amplitudes.real\n",
    "    \n",
    "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n",
    "        \"\"\"Environment step\"\"\"\n",
    "        if action == 0:  # Hadamard on first qubit\n",
    "            gate = QuantumGate.hadamard()\n",
    "        elif action == 1:  # Pauli-X on first qubit\n",
    "            gate = QuantumGate.pauli_x()\n",
    "        elif action == 2:  # Rotation-Y\n",
    "            gate = QuantumGate.rotation_y(np.pi/4)\n",
    "        else:  # Rotation-Z\n",
    "            gate = QuantumGate.rotation_z(np.pi/4)\n",
    "        \n",
    "        if self.n_qubits == 1:\n",
    "            self.current_state = gate.apply(self.current_state)\n",
    "        else:\n",
    "            full_gate = self._expand_gate_to_system(gate, 0)\n",
    "            self.current_state = full_gate.apply(self.current_state)\n",
    "        \n",
    "        fidelity = abs(np.vdot(\n",
    "            self.current_state.amplitudes,\n",
    "            self.target_state.amplitudes\n",
    "        ))**2\n",
    "        \n",
    "        reward = fidelity\n",
    "        self.steps += 1\n",
    "        done = self.steps >= 10 or fidelity > 0.95\n",
    "        \n",
    "        return self.current_state.amplitudes.real, reward, done, {}\n",
    "    \n",
    "    def _expand_gate_to_system(self, gate: QuantumGate, target_qubit: int) -> QuantumGate:\n",
    "        \"\"\"Expand single-qubit gate to multi-qubit system\"\"\"\n",
    "        identity = QuantumGate(np.eye(2))\n",
    "        \n",
    "        gates = []\n",
    "        for i in range(self.n_qubits):\n",
    "            if i == target_qubit:\n",
    "                gates.append(gate)\n",
    "            else:\n",
    "                gates.append(identity)\n",
    "        \n",
    "        result = gates[0]\n",
    "        for i in range(1, len(gates)):\n",
    "            result = result.tensor(gates[i])\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "print(\"ðŸš€ Testing Quantum Reinforcement Learning...\")\n",
    "\n",
    "env = QuantumEnvironment(n_qubits=2)\n",
    "state_dim = env.state_dim\n",
    "n_actions = env.n_actions\n",
    "\n",
    "print(f\"State dimension: {state_dim}\")\n",
    "print(f\"Number of actions: {n_actions}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Testing Quantum Q-Learning...\")\n",
    "qql_agent = QuantumQLearning(\n",
    "    n_qubits=2,\n",
    "    n_actions=n_actions,\n",
    "    n_layers=2,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(50):  # Reduced for demo\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = qql_agent.select_action(state, epsilon=0.1)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        qql_agent.update(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    episode_rewards.append(total_reward)\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        print(f\"Episode {episode}, Reward: {total_reward:.3f}\")\n",
    "\n",
    "print(f\"\\nQuantum Q-Learning Results:\")\n",
    "print(f\"Average reward (last 10 episodes): {np.mean(episode_rewards[-10:]):.3f}\")\n",
    "\n",
    "print(\"\\nðŸŽ­ Testing Quantum Actor-Critic...\")\n",
    "qac_agent = QuantumActorCritic(\n",
    "    n_qubits=2,\n",
    "    n_actions=n_actions,\n",
    "    n_layers=2\n",
    ")\n",
    "\n",
    "episode_rewards_ac = []\n",
    "for episode in range(30):  # Reduced for demo\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = qac_agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        qac_agent.update(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    episode_rewards_ac.append(total_reward)\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        print(f\"Episode {episode}, Reward: {total_reward:.3f}\")\n",
    "\n",
    "print(f\"\\nQuantum Actor-Critic Results:\")\n",
    "print(f\"Average reward (last 10 episodes): {np.mean(episode_rewards_ac[-10:]):.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Quantum RL Implementation Complete!\")\n",
    "print(\"Note: This is a simplified implementation for educational purposes.\")\n",
    "print(\"Production quantum RL would use specialized quantum computing frameworks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed7f62",
   "metadata": {},
   "source": [
    "# Part V: Integration and Advanced Applications\n",
    "\n",
    "## Synthesis of Advanced RL Paradigms\n",
    "\n",
    "The four paradigms we've exploredâ€”World Models, Multi-Agent RL, Causal RL, and Quantum RLâ€”represent the cutting edge of reinforcement learning research. Each addresses fundamental limitations of traditional RL approaches:\n",
    "\n",
    "### Paradigm Integration Matrix\n",
    "\n",
    "| Aspect | World Models | Multi-Agent RL | Causal RL | Quantum RL |\n",
    "|--------|-------------|----------------|-----------|------------|\n",
    "| **Sample Efficiency** | âœ“ Via planning | âœ“ Via sharing | âœ“ Via causal structure | âœ“ Via superposition |\n",
    "| **Interpretability** | âœ“ Via explicit models | âœ“ Via agent interaction | âœ“ Via causal graphs | â— Via quantum states |\n",
    "| **Scalability** | â— Model complexity | âœ“ Distributed learning | â— Structure discovery | â— Quantum advantage |\n",
    "| **Robustness** | â— Model uncertainty | âœ“ Via diversity | âœ“ Via interventions | â— Quantum decoherence |\n",
    "\n",
    "### Hybrid Approaches\n",
    "\n",
    "#### 1. Causal World Models\n",
    "Combining causal structure discovery with world model learning:\n",
    "```python\n",
    "class CausalWorldModel:\n",
    "    def __init__(self, causal_graph, dynamics_model):\n",
    "        self.causal_graph = causal_graph\n",
    "        self.dynamics_model = dynamics_model\n",
    "    \n",
    "    def predict_intervention(self, state, action, intervention):\n",
    "        # Use causal graph to modify dynamics\n",
    "        return self.dynamics_model.predict_with_intervention(\n",
    "            state, action, intervention, self.causal_graph\n",
    "        )\n",
    "```\n",
    "\n",
    "#### 2. Multi-Agent Causal RL\n",
    "Agents learning shared causal structures:\n",
    "```python\n",
    "class MultiAgentCausalRL:\n",
    "    def __init__(self, agents, shared_causal_graph):\n",
    "        self.agents = agents\n",
    "        self.shared_graph = shared_causal_graph\n",
    "    \n",
    "    def collective_structure_learning(self, experiences):\n",
    "        # Pool experiences for better causal discovery\n",
    "        return update_shared_causal_structure(experiences)\n",
    "```\n",
    "\n",
    "#### 3. Quantum Multi-Agent Systems\n",
    "Leveraging quantum entanglement for coordination:\n",
    "```python\n",
    "class QuantumMultiAgentSystem:\n",
    "    def __init__(self, n_agents, n_qubits):\n",
    "        self.entangled_state = create_entangled_state(n_agents, n_qubits)\n",
    "    \n",
    "    def quantum_coordination(self, local_observations):\n",
    "        return quantum_communication_protocol(\n",
    "            local_observations, self.entangled_state\n",
    "        )\n",
    "```\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "### 1. Autonomous Vehicle Networks\n",
    "- **World Models**: Environmental prediction and planning\n",
    "- **Multi-Agent**: Vehicle coordination and traffic optimization\n",
    "- **Causal RL**: Understanding cause-effect in traffic patterns\n",
    "- **Quantum RL**: Optimization of large-scale traffic systems\n",
    "\n",
    "### 2. Financial Trading Systems\n",
    "- **World Models**: Market dynamics modeling\n",
    "- **Multi-Agent**: Multi-market trading strategies\n",
    "- **Causal RL**: Understanding causal relationships in market movements\n",
    "- **Quantum RL**: Portfolio optimization with quantum advantage\n",
    "\n",
    "### 3. Healthcare and Drug Discovery\n",
    "- **World Models**: Patient trajectory modeling\n",
    "- **Multi-Agent**: Multi-specialist treatment planning\n",
    "- **Causal RL**: Understanding treatment causality\n",
    "- **Quantum RL**: Molecular interaction simulation\n",
    "\n",
    "### 4. Climate and Environmental Management\n",
    "- **World Models**: Climate system modeling\n",
    "- **Multi-Agent**: Multi-region policy coordination\n",
    "- **Causal RL**: Climate intervention analysis\n",
    "- **Quantum RL**: Large-scale environmental optimization\n",
    "\n",
    "## Research Frontiers\n",
    "\n",
    "### 1. Theoretical Foundations\n",
    "- **Sample Complexity**: Unified bounds across paradigms\n",
    "- **Convergence Guarantees**: Multi-paradigm learning stability\n",
    "- **Transfer Learning**: Cross-paradigm knowledge transfer\n",
    "- **Meta-Learning**: Learning to choose appropriate paradigms\n",
    "\n",
    "### 2. Algorithmic Advances\n",
    "- **Hybrid Architectures**: Seamless paradigm integration\n",
    "- **Adaptive Switching**: Dynamic paradigm selection\n",
    "- **Federated Learning**: Distributed multi-paradigm training\n",
    "- **Continual Learning**: Lifelong multi-paradigm adaptation\n",
    "\n",
    "### 3. Implementation Challenges\n",
    "- **Computational Efficiency**: Scalable implementations\n",
    "- **Hardware Acceleration**: Specialized computing architectures\n",
    "- **Software Frameworks**: Unified development platforms\n",
    "- **Validation Methods**: Multi-paradigm evaluation metrics\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "### Near-Term (2-5 years)\n",
    "1. **Practical Hybrid Systems**: Working implementations combining 2-3 paradigms\n",
    "2. **Industry Applications**: Deployment in specific domains\n",
    "3. **Standardization**: Common interfaces and evaluation protocols\n",
    "4. **Education**: Curriculum integration and training programs\n",
    "\n",
    "### Medium-Term (5-10 years)\n",
    "1. **Theoretical Unification**: Mathematical frameworks spanning all paradigms\n",
    "2. **Quantum Advantage**: Demonstrated speedups in real applications\n",
    "3. **Autonomous Systems**: Self-improving multi-paradigm agents\n",
    "4. **Societal Integration**: Widespread adoption across industries\n",
    "\n",
    "### Long-Term (10+ years)\n",
    "1. **Artificial General Intelligence**: Multi-paradigm foundations for AGI\n",
    "2. **Quantum-Classical Convergence**: Seamless quantum-classical computing\n",
    "3. **Causal Discovery Automation**: Fully automated causal structure learning\n",
    "4. **Multi-Agent Societies**: Complex artificial societies with emergent behavior\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This comprehensive exploration of advanced Deep Reinforcement Learning paradigms demonstrates the rich landscape of modern RL research. Each paradigm offers unique advantages:\n",
    "\n",
    "- **World Models** provide sample efficiency through learned dynamics\n",
    "- **Multi-Agent RL** enables coordination and emergence in complex systems\n",
    "- **Causal RL** offers interpretability and robustness through causal understanding\n",
    "- **Quantum RL** promises exponential advantages through quantum computation\n",
    "\n",
    "The future of reinforcement learning lies not in choosing a single paradigm, but in their thoughtful integration. By combining the strengths of each approach while mitigating their individual limitations, we can build AI systems that are:\n",
    "\n",
    "- **More Sample Efficient**: Learning faster with less data\n",
    "- **More Interpretable**: Providing clear reasoning for decisions\n",
    "- **More Robust**: Handling distribution shifts and uncertainties\n",
    "- **More Scalable**: Operating in complex, real-world environments\n",
    "\n",
    "The implementations provided in this notebook serve as stepping stones toward more sophisticated systems. While simplified for educational purposes, they demonstrate the core concepts that will drive the next generation of AI systems.\n",
    "\n",
    "As we advance toward artificial general intelligence, these paradigms will play crucial roles in creating AI systems that can understand, reason about, and operate effectively in our complex world. The journey from today's specialized RL agents to tomorrow's general AI systems will be paved with innovations across all these dimensions.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Paradigm Diversity**: Multiple approaches are needed for different aspects of intelligence\n",
    "2. **Integration Benefits**: Hybrid systems outperform single-paradigm approaches\n",
    "3. **Practical Applications**: Real-world deployment requires careful paradigm selection\n",
    "4. **Ongoing Research**: Many open questions remain in each paradigm\n",
    "5. **Future Potential**: The combination of these paradigms may enable breakthrough capabilities\n",
    "\n",
    "The field of reinforcement learning continues to evolve rapidly, and staying at the forefront requires understanding both the fundamental principles and the cutting-edge advances represented by these paradigms. This notebook provides a foundation for further exploration and implementation of these exciting directions in AI research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8fa49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b83c0ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9dddb6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}