# CA9: Advanced Policy Gradient Methods - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø¬Ø±Ø§

## ğŸ“‹ ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨

- [Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ](#Ù†ØµØ¨-Ùˆ-Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ)
- [Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§](#Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ-Ø§Ø¬Ø±Ø§)
- [Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„](#Ø§Ø¬Ø±Ø§ÛŒ-Ú©Ø§Ù…Ù„)
- [Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹](#Ø§Ø¬Ø±Ø§ÛŒ-Ø³Ø±ÛŒØ¹)
- [Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡](#Ø§Ø¬Ø±Ø§ÛŒ-Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡)
- [Ù†ØªØ§ÛŒØ¬ Ùˆ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§](#Ù†ØªØ§ÛŒØ¬-Ùˆ-Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§)
- [Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ](#Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ)

## ğŸš€ Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ

### 1. ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Virtual Environment

```bash
cd /Users/tahamajs/Documents/uni/DRL/CAs/Solutions/CA09_Advanced_Policy_Gradients
python3 -m venv venv
source venv/bin/activate
```

### 2. Ù†ØµØ¨ Dependencies

```bash
pip install -r requirements.txt
```

### 3. ØªØ³Øª Setup

```bash
python3 test_setup.py
```

## ğŸ“œ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§

### 1. `run.sh` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Bash Ú©Ø§Ù…Ù„

```bash
chmod +x run.sh
./run.sh
```

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:**

- Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù‡Ù…Ù‡ agent Ù‡Ø§
- ØªÙˆÙ„ÛŒØ¯ Ù‡Ù…Ù‡ visualization Ù‡Ø§
- Ø§Ø¬Ø±Ø§ÛŒ training examples
- Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„

### 2. `final_run.py` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Python Ù†Ù‡Ø§ÛŒÛŒ

```bash
python3 final_run.py
```

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:**

- Ø§Ø¬Ø±Ø§ÛŒ REINFORCE Ùˆ Baseline REINFORCE
- ØªÙˆÙ„ÛŒØ¯ visualization Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
- Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„

### 3. `quick_run.py` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø³Ø±ÛŒØ¹

```bash
python3 quick_run.py
```

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:**

- Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ REINFORCE
- ØªÙˆÙ„ÛŒØ¯ visualization Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
- Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹

### 4. `run_all.py` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ú©Ø§Ù…Ù„ Python

```bash
python3 run_all.py
```

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:**

- Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ù‡ algorithm Ù‡Ø§
- ØªÙˆÙ„ÛŒØ¯ Ù‡Ù…Ù‡ visualization Ù‡Ø§
- hyperparameter tuning

## ğŸ¯ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„

### Ø±ÙˆØ´ 1: Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Bash

```bash
# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ environment
source venv/bin/activate

# Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„
./run.sh
```

### Ø±ÙˆØ´ 2: Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Python

```bash
# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ environment
source venv/bin/activate

# Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„
python3 final_run.py
```

## âš¡ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹

Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹ Ùˆ ØªÙˆÙ„ÛŒØ¯ visualization Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:

```bash
source venv/bin/activate
python3 quick_run.py
```

## ğŸ”§ Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡

### 1. Ø§Ø¬Ø±Ø§ÛŒ Agent Ù‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡

#### REINFORCE

```python
from agents.reinforce import REINFORCEAgent
import gymnasium as gym

env = gym.make("CartPole-v1")
agent = REINFORCEAgent(
    state_dim=env.observation_space.shape[0],
    action_dim=env.action_space.n
)

# Ø¢Ù…ÙˆØ²Ø´
for episode in range(100):
    state, _ = env.reset()
    episode_rewards = []

    for step in range(200):
        action, log_prob = agent.select_action(state)
        next_state, reward, terminated, truncated, _ = env.step(action)

        agent.store_reward(reward)
        episode_rewards.append(reward)
        state = next_state

        if terminated or truncated:
            break

    agent.update_policy()
    print(f"Episode {episode + 1}: Reward = {sum(episode_rewards)}")

env.close()
```

#### Baseline REINFORCE

```python
from agents.baseline_reinforce import BaselineREINFORCEAgent
import gymnasium as gym

env = gym.make("CartPole-v1")
agent = BaselineREINFORCEAgent(
    state_dim=env.observation_space.shape[0],
    action_dim=env.action_space.n
)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø´Ø§Ø¨Ù‡ REINFORCE
```

#### Actor-Critic

```python
from agents.actor_critic import ActorCriticAgent
import gymnasium as gym

env = gym.make("CartPole-v1")
agent = ActorCriticAgent(
    state_dim=env.observation_space.shape[0],
    action_dim=env.action_space.n
)

# Ø¢Ù…ÙˆØ²Ø´ Actor-Critic
```

#### PPO

```python
from agents.ppo import PPOAgent
import gymnasium as gym

env = gym.make("CartPole-v1")
agent = PPOAgent(
    state_dim=env.observation_space.shape[0],
    action_dim=env.action_space.n
)

# Ø¢Ù…ÙˆØ²Ø´ PPO
```

#### Continuous Control

```python
from agents.continuous_control import ContinuousPPOAgent
import gymnasium as gym

env = gym.make("Pendulum-v1")
agent = ContinuousPPOAgent(
    state_dim=env.observation_space.shape[0],
    action_dim=env.action_space.shape[0]
)

# Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ù¾ÛŒÙˆØ³ØªÙ‡
```

### 2. Ø§Ø¬Ø±Ø§ÛŒ Visualization Ù‡Ø§

#### Policy Gradient Visualizer

```python
from utils.policy_gradient_visualizer import PolicyGradientVisualizer

visualizer = PolicyGradientVisualizer()

# Ø§ÛŒØ¬Ø§Ø¯ visualization Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
results = visualizer.demonstrate_policy_gradient_intuition()
visualizer.compare_value_vs_policy_methods()
visualizer.create_advanced_visualizations()
```

#### Training Examples

```python
from training_examples import (
    plot_policy_gradient_convergence_analysis,
    comprehensive_policy_gradient_comparison,
    policy_gradient_curriculum_learning,
    entropy_regularization_study,
    create_comprehensive_visualization_suite
)

# ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ
fig1 = plot_policy_gradient_convergence_analysis("convergence_analysis.png")

# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹
results = comprehensive_policy_gradient_comparison("comprehensive_comparison.png")

# Curriculum Learning
curriculum_results = policy_gradient_curriculum_learning("curriculum_learning.png")

# Entropy Regularization
entropy_results = entropy_regularization_study("entropy_regularization.png")

# Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ú©Ø§Ù…Ù„ visualization Ù‡Ø§
create_comprehensive_visualization_suite("visualizations/")
```

### 3. Hyperparameter Tuning

```python
from utils.hyperparameter_tuning import HyperparameterTuner

tuner = HyperparameterTuner("CartPole-v1")

# ØªÙ†Ø¸ÛŒÙ… learning rates
lr_results = tuner.tune_learning_rates()

# ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ PPO
ppo_results = tuner.tune_ppo_parameters()
```

## ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ùˆ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§

### Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ

#### `visualizations/`

- `policy_gradient_intuition.png` - Ø¯Ø±Ú© policy gradient
- `value_vs_policy_comparison.png` - Ù…Ù‚Ø§ÛŒØ³Ù‡ value-based vs policy-based
- `convergence_analysis.png` - ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ
- `comprehensive_comparison.png` - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§
- `curriculum_learning.png` - ØªØ­Ù„ÛŒÙ„ curriculum learning
- `entropy_regularization.png` - Ù…Ø·Ø§Ù„Ø¹Ù‡ entropy regularization
- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§

#### `results/`

- `final_execution_report.md` - Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø§Ø¬Ø±Ø§
- `quick_execution_report.md` - Ú¯Ø²Ø§Ø±Ø´ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹
- Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬

#### `logs/`

- Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ø± component
- Ø§Ø·Ù„Ø§Ø¹Ø§Øª debug Ùˆ error Ù‡Ø§

### Ù†ØªØ§ÛŒØ¬ Ú©Ù„ÛŒØ¯ÛŒ

#### Performance Metrics

- **REINFORCE**: Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† reward Ø¢Ø®Ø±ÛŒÙ† 10 episode
- **Baseline REINFORCE**: Ø¨Ù‡Ø¨ÙˆØ¯ variance Ùˆ stability
- **Actor-Critic**: Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±
- **PPO**: Ø¹Ù…Ù„Ú©Ø±Ø¯ state-of-the-art
- **Continuous Control**: Ú©Ù†ØªØ±Ù„ Ù¾ÛŒÙˆØ³ØªÙ‡ Ù…ÙˆÙÙ‚

#### Visualizations

- Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ
- Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§
- ØªØ­Ù„ÛŒÙ„ variance
- Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ 3D Ùˆ Ø§Ù†ÛŒÙ…ÛŒØ´Ù†

## ğŸ” Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬

#### 1. Ø®Ø·Ø§ÛŒ Import

```bash
ModuleNotFoundError: No module named 'torch'
```

**Ø±Ø§Ù‡ Ø­Ù„:**

```bash
source venv/bin/activate
pip install -r requirements.txt
```

#### 2. Ø®Ø·Ø§ÛŒ IndentationError

```bash
IndentationError: expected an indented block
```

**Ø±Ø§Ù‡ Ø­Ù„:** ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Python Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ indentation Ø±Ø§ Ø§ØµÙ„Ø§Ø­ Ú©Ù†ÛŒØ¯.

#### 3. Ø®Ø·Ø§ÛŒ Environment

```bash
Environment test failed
```

**Ø±Ø§Ù‡ Ø­Ù„:**

```bash
pip install gymnasium
```

#### 4. Ø®Ø·Ø§ÛŒ Visualization

```bash
Matplotlib backend error
```

**Ø±Ø§Ù‡ Ø­Ù„:**

```bash
pip install matplotlib
export MPLBACKEND=Agg  # Ø¨Ø±Ø§ÛŒ server environments
```

### Debug Mode

Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ debug:

```bash
python3 -c "
import sys
sys.path.append('.')
from test_setup import main
main()
"
```

## ğŸ“ˆ Performance Tips

### 1. GPU Support

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

### 2. Memory Management

```python
torch.cuda.empty_cache()  # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† GPU memory
```

### 3. Parallel Training

```python
# Ø¨Ø±Ø§ÛŒ environments Ù…ØªØ¹Ø¯Ø¯
from multiprocessing import Pool
```

## ğŸ¯ Next Steps

### 1. Experimentation

- ØªØ³Øª Ø±ÙˆÛŒ environments Ù…Ø®ØªÙ„Ù
- ØªÙ†Ø¸ÛŒÙ… hyperparameters
- Ù…Ù‚Ø§ÛŒØ³Ù‡ performance

### 2. Advanced Features

- Multi-agent training
- Hierarchical policies
- Meta-learning

### 3. Research Extensions

- Offline RL
- Safe RL
- Robust RL

## ğŸ“ Support

Ø¨Ø±Ø§ÛŒ Ù…Ø´Ú©Ù„Ø§Øª Ùˆ Ø³ÙˆØ§Ù„Ø§Øª:

1. Ø¨Ø±Ø±Ø³ÛŒ logs Ø¯Ø± Ù¾ÙˆØ´Ù‡ `logs/`
2. Ø§Ø¬Ø±Ø§ÛŒ `test_setup.py` Ø¨Ø±Ø§ÛŒ diagnostic
3. Ø¨Ø±Ø±Ø³ÛŒ documentation Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ markdown

---

**Ù†Ú©ØªÙ‡:** Ù‡Ù…Ù‡ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ØŒ Ø§Ø¨ØªØ¯Ø§ `test_setup.py` Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯ ØªØ§ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¯Ø±Ø³Øª Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

