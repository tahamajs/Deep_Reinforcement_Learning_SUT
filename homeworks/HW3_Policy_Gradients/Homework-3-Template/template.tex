\documentclass[12pt]{article}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=1.5cm, right=1.5cm]{geometry}
\usepackage{amsmath, amsfonts, amssymb, mathtools}
\usepackage{fancyhdr, setspace, parskip}
\usepackage{graphicx, caption, subfig, array, multirow}
\usepackage{hyperref, enumitem, cancel}
\usepackage[T1]{fontenc}
\usepackage{tgtermes}
\usepackage[dvipsnames]{xcolor}
\usepackage{tocloft}
\usepackage{titlesec}
\usepackage{lipsum}  

\definecolor{DarkBlue}{RGB}{10, 0, 80}

% Hyperlink setup
\hypersetup{
    colorlinks=true,
    linkcolor=DarkBlue,
    filecolor=BrickRed,      
    urlcolor=RoyalBlue,
}


% Header and footer customization
\fancyhead{}
\fancyhead[L]{
{\fontfamily{lmss}{\color{DarkBlue}
\textbf{\leftmark}
}}
}
\fancyhead[R]{
{\fontfamily{ppl}\selectfont {\color{DarkBlue}
{Deep RL [Spring 2025]}
}}
}

\fancyfoot{}
\fancyfoot[C]{
{\fontfamily{lmss}{\color{BrickRed}
\textbf{\thepage}
}}
}

\renewcommand{\sectionmark}[1]{ \markboth{\thesection\quad #1}{} }

\renewcommand{\headrule}{{\color{BrickRed}\hrule width\headwidth height 0.5pt}}
\renewcommand{\footrulewidth}{0pt}


% Table of Contents customizations
\renewcommand{\cftsecafterpnum}{\vskip6pt}
\renewcommand{\cftsubsecafterpnum}{\vskip3pt}
\renewcommand{\cftsubsubsecafterpnum}{\vskip3pt}
\renewcommand{\cftsecfont}{\sffamily\large}
\renewcommand{\cftsubsecfont}{\sffamily}
\renewcommand{\cftsubsubsecfont}{\sffamily}
% \renewcommand{\cftsecdotsep}{1}
\renewcommand{\cftsubsecdotsep}{1}
\renewcommand{\cftsubsubsecdotsep}{1}


% Section title styles
\titleformat*{\section}{\LARGE\bfseries\color{DarkBlue}}
\titleformat*{\subsection}{\Large\bfseries\color{DarkBlue}}
\titleformat*{\subsubsection}{\large\bfseries\color{DarkBlue}}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}

% Start of the document
\pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\pagenumbering{gobble}
\thispagestyle{plain}

\begin{center}

\vspace*{-1.5cm}
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/cover-std.png}
\end{figure}

{
\fontfamily{ppl}

{\color{DarkBlue} {\fontsize{30}{50} \textbf{
Deep Reinforcement Learning
}}}

{\color{DarkBlue} {\Large
Professor Mohammad Hossein Rohban
}}
}


\vspace{20pt}

{
\fontfamily{lmss}


{\color{RedOrange}
{\Large
Homework 3:
}\\
}
{\color{BrickRed}
\rule{12cm}{0.5pt}

{\Huge
Policy-Based Methods
}
\rule{12cm}{0.5pt}
}

\vspace{10pt}

{\color{RoyalPurple} { \small By:} } \\
\vspace{10pt}

{\color{Blue} { \LARGE Taha Majidi } } \\
\vspace{5pt}
{\color{RoyalBlue} { \Large 401123456 } }


\vspace*{\fill}
\begin{center}
\begin{tabular}{ccc}
    \includegraphics[width=0.14\linewidth]{figs/sharif-logo.png} & \includegraphics[width=0.14\linewidth]{figs/riml-logo.png} & \includegraphics[width=0.14\linewidth]{figs/dlr-logo.png} \\
\end{tabular}
\end{center}

\vspace*{-.25cm}

{\color{YellowOrange} {
\rule{10cm}{0.5pt} \\
\vspace{2pt}
\large Spring 2025}
}}
\vspace*{-1cm}

\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\pagenumbering{gobble}
\thispagestyle{plain}
{\fontfamily{lmss}\selectfont {\color{BrickRed} \textbf{\tableofcontents} }}

{\fontfamily{lmss}\selectfont {\color{DarkBlue}

\newpage

\subsection*{Grading}

The grading will be based on the following criteria, with a total of 100 points:

\[
\begin{array}{|l|l|}
\hline
\textbf{Task} & \textbf{Points} \\
\hline
\text{Task 1: Policy Search: REINFORCE vs. GA} & 20 \\
\text{Task 2: REINFORCE: Baseline vs. No Baseline} & 25 \\
\text{Task 3: REINFORCE in a continuous action space} & 20 \\
\text{Task 4:Policy Gradient Drawbacks} & 25 \\
\hline
\text{Clarity and Quality of Code} & 5 \\
\text{Clarity and Quality of Report} & 5 \\
\hline
\text{Bonus 1: Writing your report in Latex } & 10 \\
\hline
\end{array}
\]

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\pagenumbering{arabic}

{\fontfamily{lmss}\selectfont {\color{DarkBlue}

\section{Task 1: Policy Search: REINFORCE vs. GA [20]}

\subsection{Question 1:}
How do these two methods differ in terms of their effectiveness for solving reinforcement learning tasks? 

\subsection{Question 2:}
Discuss the key differences in their \textbf{performance}, \textbf{convergence rates}, and \textbf{stability}. 

\subsection{Question 3:}
Additionally, explore how each method handles exploration and exploitation, and suggest situations where one might be preferred over the other. 

\newpage

\section{Task 2: REINFORCE: Baseline vs. No Baseline [25]}

\subsection{Question 1:}

How are the observation and action spaces defined in the CartPole environment?
\vspace*{0.3cm}

\subsection{Question 2:}

What is the role of the discount factor $(\gamma)$ in reinforcement learning, and what happens when $\gamma$=0 or $\gamma$=1?
\vspace*{0.3cm}

\subsection{Question 3:}

Why is a baseline introduced in the REINFORCE algorithm, and how does it contribute to training stability?
\vspace*{0.3cm}

\subsection{Question 4:}

What are the primary challenges associated with policy gradient methods like REINFORCE?
\vspace*{0.3cm}

\subsection{Question 5:}

Based on the results, how does REINFORCE with a baseline compare to REINFORCE without a baseline in terms of performance?
\vspace*{0.3cm}

\subsection{Question 6:}

Explain how variance affects policy gradient methods, particularly in the context of estimating gradients from sampled trajectories.

\newpage

\section{Task 3: REINFORCE in a continuous action space [20]}

\subsection{Question 1:}

How are the observation and action spaces defined in the MountainCarContinuous environment?
\vspace*{0.3cm}

\subsection{Question 2:}

How could an agent reach the goal in the MountainCarContinuous environment while using the least amount of energy? Explain a scenario describing the agent's behavior during an episode with most optimal policy.
\vspace*{0.3cm}

\subsection{Question 3:}

What strategies can be employed to reduce catastrophic forgetting in continuous action space environments like MountainCarContinuous?

(Hint: experience replay or target networks)
\vspace*{0.3cm}

\newpage

\section{Task 4: Policy Gradient Drawbacks [25]}

\subsection{Question 1:}
\textbf{Which algorithm performs better in the Frozen Lake environment? Why?}
\newline
Compare the performance of Deep Q-Network (DQN) and Policy Gradient (REINFORCE) in terms of training stability, convergence speed, and overall success rate. Based on your observations, which algorithm achieves better results in this environment?

\subsection{Question 2:}
\textbf{ What challenges does the Frozen Lake environment introduce for reinforcement learning?}
\newline
Explain the specific difficulties that arise in this environment. How do these challenges affect the learning process for both DQN and Policy Gradient methods?

\subsection{Question 3:}
\textbf{For environments with unlimited interactions and low-cost sampling, which algorithm is more suitable?}
\newline
In scenarios where the agent can sample an unlimited number of interactions without computational constraints, which approach—DQN or Policy Gradient—is more advantageous? Consider factors such as sample efficiency, function approximation, and stability of learning.

}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

{\fontfamily{lmss}\selectfont {\color{DarkBlue}

\begin{thebibliography}{9}

\bibitem{CoverImage}
Cover image designed by freepik. Available: \href{https://www.freepik.com/free-vector/cute-artificial-intelligence-robot-isometric-icon_16717130.htm}{https://www.freepik.com/free-vector/cute-artificial-intelligence-robot-isometric-icon\_16717130.htm}

\bibitem{PolicySearch}
Policy Search. Available: 
\url{https://amfarahmand.github.io/IntroRL/lectures/lec06.pdf}

\bibitem{CartPole}
CartPole environment from OpenAI Gym. Available: \url{https://www.gymlibrary.dev/environments/classic_control/cart_pole/}

\bibitem{MountainCar}
Mountain Car Continuous environment from OpenAI Gym. Available: \url{https://www.gymlibrary.dev/environments/classic_control/cart_pole/}

\bibitem{FrozenLake}
FrozenLake environment from OpenAI Gym. Available: \url{https://www.gymlibrary.dev/environments/toy_text/frozen_lake/}

\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
