# Workshop on Model-Based Reinforcement Learning
This week, we draw our attention to **Model-Based Reinforcement Learning (MBRL)**.
We'll go through topics such as **Stochastic Optimization**, **Cross-Entropy Method (CEM)**, **Monte Carlo Tree Search (MCTS)**, **Trajectory Optimization**, **Uncertainty in Model-Based RL**, **Model-Based Policy Learning**, and more.

You can find more useful resources for Model-Based RL [here](https://github.com/opendilab/awesome-model-based-RL/).


## Dyna-Q
In this notebook we explore the **Dyna-Q** algorithm on the `Example 8.1: Dyna Maze` from [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html) by [Richard S. Sutton](http://incompleteideas.net/index.html) and [Andrew G. Barto](http://www-anw.cs.umass.edu/%7Ebarto/) with a few minor changes.

| Random Policy | Optimal Policy |
| :-----------: | :------------: |
| ![Random Agent](https://github.com/DeepRLCourse/Workshop-5-Material/blob/main/assets/random_policy.gif) | ![Dyna-Q Agent](https://github.com/DeepRLCourse/Workshop-5-Material/blob/main/assets/optimal_policy.gif) |

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepRLCourse/Workshop-5-Material/blob/main/DynaQ.ipynb)
[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/DeepRLCourse/Workshop-5-Material/main/DynaQ.ipynb)


## Monte Carlo Tree Search
In this notebook we explore the **Monte Carlo Tree Search (MCTS)** algorithm on [Tic Tac Toe](https://pettingzoo.farama.org/environments/classic/tictactoe/) environment from [PettingZoo](https://pettingzoo.farama.org/).

| Two Random Agents Playing Tic Tac Toe |
| :-----------------------------------: |
| ![XO](https://github.com/DeepRLCourse/Workshop-5-Material/raw/main/assets/TicTacToe.gif) |

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepRLCourse/Workshop-5-Material/blob/main/MCTS.ipynb)
[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/DeepRLCourse/Workshop-5-Material/main/MCTS.ipynb)


## Cross Entropy Method
In this notebook we explore the **Cross Entropy Method (CEM)** on the [Mountain Car Continuous](https://gymnasium.farama.org/environments/classic_control/mountain_car_continuous/)  environment from [Gymnasium](https://gymnasium.farama.org/).

| CEM Agent Solving Mountain Car Continuous |
| :---------------------------------------: |
| ![CEM](https://github.com/DeepRLCourse/Workshop-5-Material/raw/main/assets/CEM.gif) |

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepRLCourse/Workshop-5-Material/blob/main/CEM.ipynb)
[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/DeepRLCourse/Workshop-5-Material/main/CEM.ipynb)

