{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d682ca85",
   "metadata": {},
   "source": [
    "<!-- Centered layout with a university logo -->\n",
    "<div align=\"center\">\n",
    "\n",
    "  <!-- University Logo -->\n",
    "  <img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=\"180\" height=\"180\" style=\"margin-bottom: 10px;\">\n",
    "  \n",
    "  <!-- Assignment Title -->\n",
    "  <h1></h1>\n",
    "  <h1 style=\"color:#0F5298; font-size: 40px; font-weight: bold; margin-bottom: 5px;\">Deep Reinforcement Learning</h1>\n",
    "  <h2 style=\"color:#0F5298; font-size: 32px; font-weight: normal; margin-top: 0px;\">Assignment 10 - Multi-Agent Reinforcement Learning</h2>\n",
    "\n",
    "  <!-- Department and University -->\n",
    "  <h3 style=\"color:#696880; font-size: 24px; margin-top: 20px;\">Computer Engineering Department</h3>\n",
    "  <h3 style=\"color:#696880; font-size: 22px; margin-top: -5px;\">Sharif University of Technology</h3>\n",
    "\n",
    "  <!-- Semester -->\n",
    "  <h3 style=\"color:#696880; font-size: 22px; margin-top: 20px;\">Spring 2025</h3>\n",
    "\n",
    "  <!-- Authors -->\n",
    "  <h3 style=\"color:green; font-size: 22px; margin-top: 20px;\">Full name: [FULL_NAME]</h3>\n",
    "  <h3 style=\"color:green; font-size: 22px; margin-top: 20px;\">Student ID: [STUDENT_ID]</h3>\n",
    "\n",
    "  <!-- Horizontal Line for Separation -->\n",
    "  <hr style=\"border: 1px solid #0F5298; width: 80%; margin-top: 30px;\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d128e3",
   "metadata": {},
   "source": [
    "## Setup & Overview  \n",
    "In this notebook, we explore Multi-Agent Reinforcement Learning (MARL) through various algorithms and environments.  \n",
    "We implement and compare several approaches:\n",
    "- **Independent Q-Learning** (IQL) - Each agent learns independently\n",
    "- **QMIX** - Value decomposition for cooperative settings\n",
    "- **MADDPG** - Multi-Agent Actor-Critic for mixed environments\n",
    "- **Communication Protocols** - CommNet and TarMAC\n",
    "- **Self-Play** - Training against past versions\n",
    "\n",
    "We'll work with classic game theory environments like Prisoner's Dilemma and Coordination Games, then move to more complex multi-agent scenarios.\n",
    "\n",
    "Follow the instructions carefully and complete the sections marked with **TODO**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a9b10",
   "metadata": {},
   "source": [
    "## Setup and Environment\n",
    "\n",
    "In the upcoming cells, we import necessary libraries, set up utility functions for reproducibility and plotting, and define the basic components of our multi-agent experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque, defaultdict\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
