# ğŸ” Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Debugging Ø¨Ø±Ø§ÛŒ HW3

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… ØªØºÛŒÛŒØ±Ø§Øª debugging Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ HW3 Ø§Ø³Øª.

## ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡

### 1. `src/actor_critic.py`

**ØªØºÛŒÛŒØ±Ø§Øª:**

- âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† logging system Ø¨Ø§ ÙØ§ÛŒÙ„ `actor_critic_debug.log`
- âœ… Debugging Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª MLP networks
- âœ… Logging Ø¬Ø²Ø¦ÛŒØ§Øª initialization
- âœ… Debugging Ø¨Ø±Ø§ÛŒ sampling trajectories
- âœ… Logging Ø¢Ù…Ø§Ø± critic Ùˆ actor updates
- âœ… Ù†Ù…Ø§ÛŒØ´ loss Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² training

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡:**

- ğŸ—ï¸ Ø³Ø§Ø®ØªØ§Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§
- ğŸ“Š Ø¢Ù…Ø§Ø± trajectories (rewards, steps)
- ğŸ”„ Critic loss changes
- ğŸ­ Actor advantage statistics

### 2. `src/dqn.py`

**ØªØºÛŒÛŒØ±Ø§Øª:**

- âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† logging system Ø¨Ø§ ÙØ§ÛŒÙ„ `dqn_debug.log`
- âœ… Debugging Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Q-networks (CNN/MLP)
- âœ… Logging Ø¬Ø²Ø¦ÛŒØ§Øª agent initialization
- âœ… Debugging action selection (random vs greedy)
- âœ… Logging training progress Ùˆ loss changes
- âœ… Ù†Ù…Ø§ÛŒØ´ target network updates

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡:**

- ğŸ—ï¸ Ø³Ø§Ø®ØªØ§Ø± Q-networks
- ğŸ² Action selection statistics
- ğŸ“‰ Training loss progression
- ğŸ¯ Target network updates

### 3. `run_ac.py`

**ØªØºÛŒÛŒØ±Ø§Øª:**

- âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† logging system Ø¨Ø§ ÙØ§ÛŒÙ„ `run_ac_debug.log`
- âœ… Logging Ø¬Ø²Ø¦ÛŒØ§Øª training setup
- âœ… Debugging Ø¨Ø±Ø§ÛŒ Ù‡Ø± iteration
- âœ… Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± paths Ùˆ returns
- âœ… Logging performance metrics

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡:**

- ğŸš€ Training setup details
- ğŸ“Š Iteration statistics
- ğŸ“ˆ Path performance metrics

### 4. `run_dqn_lander.py`

**ØªØºÛŒÛŒØ±Ø§Øª:**

- âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† logging system Ø¨Ø§ ÙØ§ÛŒÙ„ `run_dqn_lander_debug.log`
- âœ… Logging Ø¬Ø²Ø¦ÛŒØ§Øª environment setup
- âœ… Debugging training loop progress
- âœ… Ù†Ù…Ø§ÛŒØ´ performance milestones
- âœ… Logging final training results

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡:**

- ğŸ® Environment configuration
- ğŸ“Š Training progress updates
- ğŸ¯ Major milestones
- ğŸ† Final performance metrics

## ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Log ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡

```
hw3/
â”œâ”€â”€ actor_critic_debug.log      # Actor-Critic debugging
â”œâ”€â”€ dqn_debug.log              # DQN debugging
â”œâ”€â”€ run_ac_debug.log           # AC training debugging
â””â”€â”€ run_dqn_lander_debug.log   # DQN training debugging
```

## ğŸš€ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### 1. Ø§Ø¬Ø±Ø§ÛŒ Actor-Critic Ø¨Ø§ Debugging

```bash
cd /Users/tahamajs/Documents/uni/DRL/Other_Assisments/homework/hw3
source /Users/tahamajs/Documents/uni/DRL/venv/bin/activate
python run_ac.py CartPole-v0 -n 100 -b 1000 --seed 1
```

### 2. Ø§Ø¬Ø±Ø§ÛŒ DQN Ø¨Ø§ Debugging

```bash
python run_dqn_lander.py LunarLander-v2 --num_timesteps 50000 --seed 1
```

### 3. Ù…Ø´Ø§Ù‡Ø¯Ù‡ Logs Ø¯Ø± Real-time

```bash
# Actor-Critic logs
tail -f actor_critic_debug.log

# DQN logs
tail -f dqn_debug.log

# Training logs
tail -f run_ac_debug.log
tail -f run_dqn_lander_debug.log
```

## ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Debugging Ù…ÙˆØ¬ÙˆØ¯

### Actor-Critic:

- ğŸ¯ Agent initialization parameters
- ğŸ—ï¸ Network architecture details
- ğŸš€ Trajectory sampling statistics
- ğŸ”„ Critic update progress
- ğŸ­ Actor advantage calculations
- ğŸ“ˆ Performance metrics per iteration

### DQN:

- ğŸ¤– Agent configuration
- ğŸ—ï¸ Q-network architecture (CNN/MLP)
- ğŸ² Action selection (epsilon-greedy)
- ğŸ“š Replay buffer statistics
- ğŸ“‰ Training loss progression
- ğŸ¯ Target network updates
- ğŸ“Š Episode performance

## ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Logging

### ØªØºÛŒÛŒØ± Ø³Ø·Ø­ Logging:

```python
# Ø¯Ø± Ù‡Ø± ÙØ§ÛŒÙ„ØŒ Ø§ÛŒÙ† Ø®Ø· Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯:
logging.basicConfig(level=logging.DEBUG)  # Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø¬Ø²Ø¦ÛŒØ§Øª
logging.basicConfig(level=logging.INFO)   # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ØªÙˆØ³Ø· (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
logging.basicConfig(level=logging.WARNING) # ÙÙ‚Ø· Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§
```

### ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Logging:

```python
logging.basicConfig(level=logging.CRITICAL)  # ÙÙ‚Ø· Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ
```

## ğŸ¯ Ù†Ú©Ø§Øª Ù…ÙÛŒØ¯

1. **ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Log Ø¨Ø²Ø±Ú¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯** - Ù…Ø±ØªØ¨Ø§Ù‹ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯:

   ```bash
   rm *.log
   ```

2. **Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹** - Ø³Ø·Ø­ logging Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯:

   ```python
   logging.basicConfig(level=logging.WARNING)
   ```

3. **Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚** - Ø§Ø² DEBUG level Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:

   ```python
   logging.basicConfig(level=logging.DEBUG)
   ```

4. **Ù…Ø´Ø§Ù‡Ø¯Ù‡ Real-time** - Ø§Ø² `tail -f` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
   ```bash
   tail -f run_ac_debug.log | grep "ğŸ“Š"
   ```

## ğŸ“ˆ Ù…Ø«Ø§Ù„ Ø®Ø±ÙˆØ¬ÛŒ Log

```
2025-10-04 02:20:00 - __main__ - INFO - ğŸš€ Starting Actor-Critic training:
2025-10-04 02:20:00 - __main__ - INFO -   ğŸ“‹ Experiment: ac_CartPole-v0
2025-10-04 02:20:00 - __main__ - INFO -   ğŸ® Environment: CartPole-v0
2025-10-04 02:20:00 - __main__ - INFO -   ğŸ”„ Iterations: 100
2025-10-04 02:20:00 - __main__ - INFO - ğŸ”§ Building MLP: scope=policy, input_shape=(?, 4), output_size=2, n_layers=2, size=64
2025-10-04 02:20:00 - __main__ - INFO - âœ… MLP built successfully: final_output_shape=(?, 2)
2025-10-04 02:20:01 - __main__ - INFO - ğŸš€ Starting new trajectory (animate=False)
2025-10-04 02:20:01 - __main__ - INFO - ğŸ Trajectory completed: steps=25, total_reward=25.000, avg_reward=1.000
```

## ğŸ” Troubleshooting

### Ù…Ø´Ú©Ù„: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Log Ø®Ø§Ù„ÛŒ Ù‡Ø³ØªÙ†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:** Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ logging level Ø¯Ø±Ø³Øª ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.

### Ù…Ø´Ú©Ù„: Logs Ø®ÛŒÙ„ÛŒ Ù¾Ø±Ø¬Ø²Ø¦ÛŒØ§Øª Ù‡Ø³ØªÙ†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:** Ø³Ø·Ø­ logging Ø±Ø§ Ø¨Ù‡ INFO ÛŒØ§ WARNING ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.

### Ù…Ø´Ú©Ù„: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Log Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:** Ø§Ø² rotation ÛŒØ§ compression Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…Ø±ØªØ¨Ø§Ù‹ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯.

---

## ğŸ“ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ

Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ÛŒ Ø¯Ø§Ø±ÛŒØ¯ ÛŒØ§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯ØŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ log Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

**Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† debugging system Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§:

- ğŸ” Ù…Ø´Ú©Ù„Ø§Øª training Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯
- ğŸ“Š Ø¹Ù…Ù„Ú©Ø±Ø¯ agent Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯
- ğŸ¯ Ù†Ù‚Ø§Ø· Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒØ¯
- ğŸ“ˆ Ù¾ÛŒØ´Ø±ÙØª training Ø±Ø§ Ø±ØµØ¯ Ú©Ù†ÛŒØ¯
